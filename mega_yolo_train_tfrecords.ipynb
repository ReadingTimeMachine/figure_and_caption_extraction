{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iC4Y4O7bneag"
   },
   "source": [
    "# Mega Yolo -- train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kado6I35Dzr1"
   },
   "source": [
    "## Some toggles for if you want to re-start from weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1638452980366,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "0bgHP_GnD2SN"
   },
   "outputs": [],
   "source": [
    "# Do you want to re-run from an already generated train/valid/test split?\n",
    "#  -- this is useful for feature testing and/or re-starting from weights\n",
    "re_run_from_splits = True\n",
    "\n",
    "# if restarting, how many previous log files do we want to look at?\n",
    "nRecent = 7 # for the 1st restart, this will be 1, for the 2nd, 2, etc\n",
    "\n",
    "# set to true if you are not re-running from the same dataset\n",
    "regenAnchors = False\n",
    " \n",
    "# use a saved weights file? Set to None if not and training will start anew\n",
    "#saved_weights_file = 'weights/savedWeights/training_1_model_l0.017813377.h5'\n",
    "saved_weights_file = None\n",
    "\n",
    "#fileStorage = 'binaries/' # binaries is where things are -- MAIN   \n",
    "#extraName = '' # append to training weights name\n",
    "\n",
    "# for feature collections\n",
    "#fileStorage = 'binaries_model1/' # binaries is where things are -- MAIN   \n",
    "#extraName = 'model1' # never use 8, this is our usual model?\n",
    "\n",
    "#fileStorage = 'binaries_model1_inverted/' # binaries is where things are -- MAIN   \n",
    "#extraName = 'model1_inverted'\n",
    "\n",
    "#fileStorage = 'binaries_model1_inverted_palletized/'\n",
    "#extraName = 'model1_inverted_palletized'\n",
    "\n",
    "# fileStorage = 'binaries_model2/'\n",
    "# extraName = 'model2'\n",
    "\n",
    "#fileStorage = 'binaries_model3/'\n",
    "#extraName = 'model3'\n",
    "\n",
    "#fileStorage = 'binaries_model4/'\n",
    "#extraName = 'model4'\n",
    "\n",
    "#fileStorage = 'binaries_model5/'\n",
    "#extraName = 'model5'\n",
    "\n",
    "#fileStorage = 'binaries_model5_maxTag125/'\n",
    "#extraName = 'model5_maxTag125'\n",
    "\n",
    "# fileStorage = 'binaries_model6/'\n",
    "# extraName = 'model6'\n",
    "\n",
    "# fileStorage = 'binaries_model8/'\n",
    "# extraName = 'model8'\n",
    "\n",
    "fileStorage = 'binaries_model8_tfrecord/'\n",
    "extraName = 'model8_tfrec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1638452980368,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "dLbPjO38y8NV"
   },
   "outputs": [],
   "source": [
    "# toggle for if on google collab or not\n",
    "import os\n",
    "thisDir = os.getcwd()\n",
    "onGoogle = False\n",
    "if 'content' in thisDir: onGoogle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27939,
     "status": "ok",
     "timestamp": 1638453008289,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "XsUy8h5AnlMU",
    "outputId": "bdb3a427-d219-4752-b923-1c5c33fdda17"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Mount Google Drive\n",
    "if onGoogle: # probably on google\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2935,
     "status": "ok",
     "timestamp": 1638453011220,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "gnmYH7-3neak",
    "outputId": "d8f5f748-88bb-49f1-9621-528affb73ea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on laptop\n"
     ]
    }
   ],
   "source": [
    "if onGoogle: # probably on google\n",
    "    # find config\n",
    "    # from pathlib import Path\n",
    "    # for path in Path('./').rglob('config.py'):\n",
    "    #     if path.name == 'config.py':\n",
    "    #         continue\n",
    "    #print(path)\n",
    "    if not os.path.exists(\"/content/gdrive/My Drive/Colab Notebooks/scienceDigitization/\"):\n",
    "        print(\"ERROR: path does not exist\")\n",
    "    os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/scienceDigitization/\")\n",
    "    import config\n",
    "\n",
    "    print('On google')\n",
    "    \n",
    "    classDirMain = './'\n",
    "    figCapMain = './'\n",
    "    \n",
    "    yoloWeightDir = classDirMain + 'classifications/'\n",
    "\n",
    "    weightsDir = classDirMain + 'classifications/'\n",
    "    logsDir = classDirMain + 'classifications/'\n",
    "\n",
    "    classDirMain = './classifications/'\n",
    "    classDirMainHOME = fileStorage \n",
    "    splitsDir = './classifications/'\n",
    "    logsDir = classDirMain\n",
    "    chksDir = classDirMain\n",
    "    saveFile = classDirMain + 'weights/testList.csv'\n",
    "else:\n",
    "    print('on laptop')\n",
    "    import config\n",
    "    classDirMain = config.save_binary_dir #+ fileStorage\n",
    "    #figCapMain = '/Users/jillnaiman/Dropbox/wwt_image_extraction/ClassifyingImages/'\n",
    "    #from sys import path; path.append('/Users/jillnaiman/scienceDigitization/')\n",
    "    # where are raw images?\n",
    "    images_pulled_dir = config.images_jpeg_dir #'/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/Pages/RandomSingleFromPDFIndexed/' ## what about Dropbox though????\n",
    "    yoloWeightDir = config.save_weights_dir\n",
    "    #weightsDir = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/mega_yolo/saved_weights/' # weights/\n",
    "    logsDir = config.save_weights_dir #'/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/mega_yolo/' # weights/\n",
    "    classDirMainHOME = fileStorage \n",
    "    # note -- we are generally not running locally, so this is really tmp storage\n",
    "    splitsDir = config.tmp_storage_dir #'/Users/jillnaiman/tmpModels/mega_yolo/'\n",
    "    weightsDir = splitsDir\n",
    "    logsDir = splitsDir\n",
    "    chksDir = splitsDir\n",
    "    saveFile = config.tmp_storage_dir + 'testList.csv'\n",
    "    # make if not there\n",
    "    if not os.path.exists(weightsDir+'weights/'):\n",
    "        os.makedirs(weightsDir+'weights/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1638453011221,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "H67BF_sLneah"
   },
   "outputs": [],
   "source": [
    "# # some parameters for different architectures of YOLO\n",
    "batch_size = 10\n",
    "num_epochs = 125 #150 #300\n",
    "\n",
    "#IMAGE_H, IMAGE_W = 512, 512\n",
    "image_size = config.IMAGE_H # assume width=height\n",
    "\n",
    "TRAIN_BATCH_SIZE = batch_size #10\n",
    "VAL_BATCH_SIZE   = batch_size #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1638453011221,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "i6twEUYmGrFa",
    "outputId": "4e9f9c12-3084-4101-c8e8-df1c5d71c718"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jillnaiman/Downloads/tmp/'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightsDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1638453011221,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "9GGT2mW9nean",
    "outputId": "d992623e-6dc0-4050-f840-8196b8c297fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/jillnaiman/MegaYolo/yolo_512x512_ann/',\n",
       " '/Users/jillnaiman/MegaYolo/binaries_model8_tfrecord/')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where annotations and features files\n",
    "#classDir_main_to = classDirMain + 'yolo_512x512_cap_ann/'\n",
    "#classDir_main_to_imgs = classDirMain + 'binaries/'#+ 'yolo_512x512/'\n",
    "classDir_main_to = classDirMain + config.ann_name + str(int(config.IMAGE_H)) + 'x' + str(int(config.IMAGE_W))  + '_ann/'\n",
    "\n",
    "classDir_main_to_imgs = classDirMain + fileStorage.split('/')[-2] + '/'\n",
    "classDir_main_to, classDir_main_to_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1638453011222,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "IVGN-eMPe0-c"
   },
   "outputs": [],
   "source": [
    "#!conda install numba --yes\n",
    "#logsDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 2341,
     "status": "ok",
     "timestamp": 1638453013547,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "vwhXD8HOneap"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "# make more better?\n",
    "#from numba import jit\n",
    "from time import perf_counter\n",
    "import sys\n",
    "\n",
    "# for v5\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1779,
     "status": "ok",
     "timestamp": 1638453015322,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "TpGXEVAfnear",
    "outputId": "1d71eaa5-40ff-4c42-ede3-410568a7a371"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('Tensorflow version : {}'.format(tf.__version__))\n",
    "#print('GPU : {}'.format(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "#from tensorflow.keras.layers import Concatenate, concatenate, Dropout, \\\n",
    "#   LeakyReLU, Reshape, Activation, Conv2D, Input, MaxPooling2D, \\\n",
    "#   BatchNormalization, Flatten, Dense, Lambda\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# my imports\n",
    "import pickle\n",
    "#from classification_utils import make_get_csv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import json\n",
    "#from classification_utils import train_test_valid_split\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "# for restart\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "import struct\n",
    "from datetime import date as DATE\n",
    "\n",
    "# get parse\n",
    "from mega_yolo_utils import build_model, train_test_valid_split, \\\n",
    "    process_box, process_layer, box_iou, compute_nms, iou, num_cluster, generator, \\\n",
    "    get_n_features\n",
    "from general_utils import parse_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUJLjHVTneav"
   },
   "source": [
    "## First, data setup\n",
    "\n",
    "In data pre-processing (`generate_features_only.py`) TF records files are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = glob.glob(classDir_main_to_imgs + 'train_*tfrecords')\n",
    "valid_list = glob.glob(classDir_main_to_imgs + 'valid_*tfrecords')\n",
    "#test_list = glob.glob(classDir_main_to_imgs + 'test_*tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 11:18:29.816391: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# get raw data\n",
    "train_raw_data = tf.data.TFRecordDataset(train_list)\n",
    "valid_raw_data = tf.data.TFRecordDataset(valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary describing the features.\n",
    "image_feature_description = {\n",
    "    'nbox': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'nfeatures': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'boxes': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_name': tf.io.FixedLenFeature([], tf.string),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't have access to anchors file and train/test/valid files -- read from splits.  Either way, get the labels from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = np.loadtxt(classDir_main_to_imgs + 'LABELS.csv', \n",
    "                    dtype=str, delimiter=',')\n",
    "CLASS = len(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have anchors already\n",
    "def _parse_just_boxes(example_proto):\n",
    "    image_features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    # parse the data\n",
    "    nboxes = image_features['nbox']\n",
    "    nfeatures = image_features['nfeatures']\n",
    "    boxes = tf.io.decode_raw(image_features['boxes'],tf.float32)\n",
    "    boxes = tf.reshape(boxes,[nboxes,5])  \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re_run_from_splits: regenAnchors = False\n",
    "\n",
    "if regenAnchors:\n",
    "#if True:\n",
    "    boxes = train_raw_data.map(lambda example_proto:_parse_just_boxes(example_proto))\n",
    "    saved_boxes = []\n",
    "    for ib,b in enumerate(boxes):\n",
    "        if ib%500 == 0: print('on', ib, 'of ? (probably 5000ish for full)')\n",
    "        saved_boxes.append(b.numpy())\n",
    "    # valid\n",
    "    boxes = valid_raw_data.map(lambda example_proto:_parse_just_boxes(example_proto))\n",
    "    for ib,b in enumerate(boxes):\n",
    "        if ib%500 == 0: print('on', ib, 'of ? (probably 5000*0.15ish for valid)')\n",
    "        saved_boxes.append(b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from saved:\n",
      "[[203. 118.]\n",
      " [ 19. 355.]\n",
      " [377. 373.]\n",
      " [ 24.   4.]\n",
      " [182.   9.]\n",
      " [199.  22.]\n",
      " [  6.  45.]\n",
      " [434.  16.]\n",
      " [334. 216.]]\n"
     ]
    }
   ],
   "source": [
    "# assume location of saved anchors:\n",
    "saveFileAnchors = classDirMain + 'weights/anchors.pickle'\n",
    "# hack for local debugging\n",
    "if '/Users/jillnaiman' in thisDir:\n",
    "    saveFileAnchors = splitsDir + 'anchors.pickle'\n",
    "\n",
    "if regenAnchors:\n",
    "#if True:\n",
    "    boxes = []\n",
    "    for bb in saved_boxes:\n",
    "        if len(bb) > 0:\n",
    "            for b in bb:\n",
    "                boxes.append([b[2]-b[0], b[3]-b[1]])\n",
    "    boxes = np.array(boxes)\n",
    "    \n",
    "    anchors = generator(boxes,k=num_cluster)\n",
    "    print('NEW ANCHORS:')\n",
    "    \n",
    "    # save!\n",
    "    with open(saveFileAnchors, 'wb') as ff:\n",
    "        pickle.dump(anchors, ff)\n",
    "else:\n",
    "    print('from saved:')\n",
    "    with open(saveFileAnchors, 'rb') as f:\n",
    "        anchors = pickle.load(f)    \n",
    "    \n",
    "print(anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have anchors already\n",
    "def _parse_image_function(example_proto,anchors,CLASS):\n",
    "    image_features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    # parse the data\n",
    "    nboxes = image_features['nbox']\n",
    "    nfeatures = image_features['nfeatures']\n",
    "    boxes = tf.io.decode_raw(image_features['boxes'],tf.float32)\n",
    "    boxes = tf.reshape(boxes,[nboxes,5])\n",
    "    images_raw = image_features['image_raw']\n",
    "    image = tf.io.decode_raw(images_raw,tf.float32)\n",
    "    image = tf.reshape(image,[config.IMAGE_H,config.IMAGE_W,nfeatures])\n",
    "    # process boxes -- wrap in a tf.py_function\n",
    "    y1,y2,y3 = tf.py_function(process_box,\n",
    "                              (boxes[:,:4], boxes[:,4],anchors,CLASS),\n",
    "                              (tf.float32,tf.float32,tf.float32))   \n",
    "    return image, y1,y2,y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "in user code:\n\n    /var/folders/t5/9xgccmv92hnfvjwd62mk8zqh0000gn/T/ipykernel_49094/719601195.py:1 None  *\n        anchors,CLASS))\n\n    NameError: name 'anchors' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t5/9xgccmv92hnfvjwd62mk8zqh0000gn/T/ipykernel_49094/719601195.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_dataset = train_raw_data.map(lambda example_proto:_parse_image_function(example_proto,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                                               anchors,CLASS))\n",
      "\u001b[0;32m~/anaconda3/envs/Paper1/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     \"\"\"\n\u001b[1;32m   1804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/anaconda3/envs/Paper1/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4206\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4207\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4208\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4209\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paper1/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3523\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3524\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paper1/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m   3051\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3052\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3053\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paper1/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m~/anaconda3/envs/Paper1/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paper1/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paper1/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paper1/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3516\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3517\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3518\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3519\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3520\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paper1/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3451\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3453\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3454\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3455\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paper1/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: in user code:\n\n    /var/folders/t5/9xgccmv92hnfvjwd62mk8zqh0000gn/T/ipykernel_49094/719601195.py:1 None  *\n        anchors,CLASS))\n\n    NameError: name 'anchors' is not defined\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_raw_data.map(lambda example_proto:_parse_image_function(example_proto,\n",
    "                                                                              anchors,CLASS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "***HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54410,
     "status": "ok",
     "timestamp": 1638453069726,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "EoCivx-Jneav",
    "outputId": "62107197-3fe1-4018-da1b-0020ae21c597"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5515"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab labels\n",
    "annotations = glob.glob(classDir_main_to + '*')\n",
    "len(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFWzDaooBb6A"
   },
   "source": [
    "Parse annotations -- **NOTE: this can take a while!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1638453069727,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "jRvZyeZiGrFe"
   },
   "outputs": [],
   "source": [
    "#tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2506111,
     "status": "ok",
     "timestamp": 1638455575835,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "N34O8BwTneay",
    "outputId": "34b01934-f30d-4986-d455-0a1695687c1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on  0  of  5515\n",
      "on  200  of  5515\n",
      "on  400  of  5515\n",
      "on  600  of  5515\n",
      "on  800  of  5515\n",
      "on  1000  of  5515\n",
      "on  1200  of  5515\n",
      "on  1400  of  5515\n",
      "on  1600  of  5515\n",
      "on  1800  of  5515\n",
      "on  2000  of  5515\n",
      "on  2200  of  5515\n",
      "on  2400  of  5515\n",
      "on  2600  of  5515\n",
      "on  2800  of  5515\n",
      "on  3000  of  5515\n",
      "on  3200  of  5515\n",
      "on  3400  of  5515\n",
      "on  3600  of  5515\n",
      "on  3800  of  5515\n",
      "on  4000  of  5515\n",
      "on  4200  of  5515\n",
      "on  4400  of  5515\n",
      "on  4600  of  5515\n",
      "on  4800  of  5515\n",
      "on  5000  of  5515\n",
      "on  5200  of  5515\n",
      "on  5400  of  5515\n",
      "    Elapsed wall clock time = 2506.05 seconds.\n"
     ]
    }
   ],
   "source": [
    "##### what about anchors -- do we want to regenerate? Generally keep this as True...\n",
    "#####regenAnchors = True\n",
    "# ... unless we are re-running from a previous split\n",
    "if re_run_from_splits: regenAnchors = False\n",
    "#if regenAnchorsAnyway: regenAnchors = True\n",
    "\n",
    "if regenAnchors:\n",
    "    bboxes = []\n",
    "    \n",
    "\n",
    "# this parsing does some loading on collab that I'm not 100% sure about, but seems necessary\n",
    "#   to load into memory, so keep it and figure it out later\n",
    "def load_parse_data_split(X_full):\n",
    "    Y_full_str = np.array([]) # have to loop and give best guesses for the pages that have multiple images/classes in them\n",
    "    slabels = np.array([])\n",
    "    for ii, X in enumerate(X_full):\n",
    "        if ii%200 == 0: print('on ', ii, ' of ', len(X_full))\n",
    "        tree = ET.parse(X)\n",
    "        tags = np.array([])\n",
    "        for elem in tree.iter(): \n",
    "            if 'object' in elem.tag or 'part' in elem.tag:                  \n",
    "                box = np.zeros((5))\n",
    "                for attr in list(elem):\n",
    "                    if 'name' in attr.tag:\n",
    "                        if attr.text is not None:\n",
    "                            tags = np.append(tags,attr.text)\n",
    "                            slabels = np.append(slabels,attr.text)\n",
    "                        #print(tags, slabels)\n",
    "                    if regenAnchors:\n",
    "                        if 'bndbox' in attr.tag and 'bndboxOrig' not in attr.tag:\n",
    "                            for dim in list(attr):\n",
    "                                if 'xmin' in dim.tag:\n",
    "                                    box[0] = int(round(float(dim.text)))\n",
    "                                if 'ymin' in dim.tag:\n",
    "                                    box[1] = int(round(float(dim.text)))\n",
    "                                if 'xmax' in dim.tag:\n",
    "                                    box[2] = int(round(float(dim.text)))\n",
    "                                if 'ymax' in dim.tag:\n",
    "                                    box[3] = int(round(float(dim.text)))\n",
    "                if regenAnchors and len(box)>0: bboxes.append(np.asarray(box))\n",
    "        if len(tags) > 0:\n",
    "            #print(tags)\n",
    "            modeClass = stats.mode(tags).mode[0] # most frequent class that pops up on this page\n",
    "            Y_full_str = np.append(Y_full_str, modeClass) # class in string\n",
    "        else:\n",
    "            Y_full_str = np.append(Y_full_str, 'none')\n",
    "    return Y_full_str,slabels\n",
    "\n",
    "# NEXT: do a quick test run-through of the data generator for train/test splits\n",
    "X_full = np.array(annotations)\n",
    "\n",
    "start_time = perf_counter( )\n",
    "Y_full_str,slabels = load_parse_data_split(X_full)\n",
    "stop_time = perf_counter( )\n",
    "print('    Elapsed wall clock time = %g seconds.' % (stop_time - start_time) )\n",
    "    \n",
    "# also do regeneration of anchors\n",
    "if regenAnchors: bboxes = np.array(bboxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUWutM847jyy"
   },
   "source": [
    "Get anchors, if that is what you wanna do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1638455575835,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "pCrtynsPIMXP",
    "outputId": "5507476c-e555-43d9-979c-52beb713773f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./classifications/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classDirMain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1048,
     "status": "ok",
     "timestamp": 1638455576866,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "Dvtr6msG7jyy",
    "outputId": "06cc7a7e-7d7a-4f16-8d25-604736542e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from saved:\n",
      "[[195.  21.]\n",
      " [203.   7.]\n",
      " [ 51.   5.]\n",
      " [313. 199.]\n",
      " [359. 391.]\n",
      " [435.  16.]\n",
      " [399. 307.]\n",
      " [204. 114.]\n",
      " [ 15. 355.]]\n"
     ]
    }
   ],
   "source": [
    "# assume location of saved anchors:\n",
    "saveFileAnchors = classDirMain + 'weights/anchors.pickle'\n",
    "# hack for local debugging\n",
    "if '/Users/jillnaiman' in thisDir:\n",
    "    saveFileAnchors = splitsDir + 'anchors.pickle'\n",
    "\n",
    "if regenAnchors:\n",
    "    boxes = []\n",
    "    for b in bboxes:\n",
    "        boxes.append([b[2]-b[0], b[3]-b[1]])\n",
    "    boxes = np.array(boxes)\n",
    "    \n",
    "    anchors = generator(boxes,k=num_cluster)\n",
    "    print('NEW ANCHORS:')\n",
    "    \n",
    "    # save!\n",
    "    with open(saveFileAnchors, 'wb') as ff:\n",
    "        pickle.dump(anchors, ff)\n",
    "else:\n",
    "    print('from saved:')\n",
    "    with open(saveFileAnchors, 'rb') as f:\n",
    "        anchors = pickle.load(f)    \n",
    "    \n",
    "print(anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1638455576867,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "Z1G0r3vYnea0",
    "outputId": "c3d63b7f-1c43-4cb8-89b9-53b4dfefd38d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['figure', 'figure caption', 'math formula', 'table']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS = np.unique(slabels).tolist()\n",
    "CLASS = len(LABELS)\n",
    "##if use_only_one_class: CLASS = 1\n",
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1638455576867,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "yZJXzsfVnea2"
   },
   "outputs": [],
   "source": [
    "# strings to integers\n",
    "\n",
    "if not re_run_from_splits:\n",
    "    Y_full = []\n",
    "    labels = np.arange(len(LABELS))\n",
    "\n",
    "    for i in range(len(Y_full_str)):\n",
    "        try:\n",
    "            Y_full.append( labels[np.array(LABELS) == Y_full_str[i]][0] +1 ) # 0 means unlabeled data\n",
    "        except:\n",
    "            Y_full.append( 0 ) # 0 means unlabeled data\n",
    "\n",
    "        if len(labels[np.array(LABELS) == Y_full_str[i]]) > 1:\n",
    "            import sys\n",
    "            sys.exit()\n",
    "\n",
    "    Y_full = np.array(Y_full)\n",
    "else:\n",
    "    labels = np.arange(0,len(LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1638455576867,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "0R42fLapLPI-",
    "outputId": "ece84189-cd6c-49dc-84cf-51d1d11721fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), ['figure', 'figure caption', 'math formula', 'table'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wKLOv6xBb6D"
   },
   "source": [
    "Create splits one way or the other.  Using the function makes sure the classes are evenly split as there can be un-even classes (for example, there might be way more figures/figure captions than tables).  Note: each instance is tagged as having one class but this is just the most frequent type on that page -- pages can sometimes have multiple types.\n",
    "\n",
    "Or, load from previous file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "executionInfo": {
     "elapsed": 6176,
     "status": "ok",
     "timestamp": 1638455583040,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "nIG98zeHnea6",
    "outputId": "6613f570-864f-4339-e669-9ffde7ba26b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/summary/summary_iterator.py:31: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# splits\n",
    "train_per = 0.75\n",
    "valid_per = 0.15\n",
    "test_per = 0.10\n",
    "if not re_run_from_splits:\n",
    "    # note: y_* aren't actually used anywhere\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = train_test_valid_split(X_full, Y_full, \n",
    "                                                                  train_size = train_per, valid_size = valid_per, test_size = test_per, \n",
    "                                                                  textClassification=True, asInts=False)\n",
    "\n",
    "    print('We have AT LEAST', len(X_train), 'training,', len(X_valid), 'validation,', len(X_test), 'test instances.')\n",
    "    \n",
    "    # write files for splits\n",
    "    np.savetxt(splitsDir + 'train.csv', X_train, fmt='%s', delimiter=',')\n",
    "    np.savetxt(splitsDir + 'test.csv', X_test, fmt='%s', delimiter=',')\n",
    "    np.savetxt(splitsDir + 'valid.csv', X_valid, fmt='%s', delimiter=',')\n",
    "else: # read from files\n",
    "    X_train = np.loadtxt(splitsDir + 'train.csv', dtype=str, delimiter=',')\n",
    "    X_test = np.loadtxt(splitsDir + 'test.csv', dtype=str, delimiter=',')\n",
    "    X_valid = np.loadtxt(splitsDir + 'valid.csv', dtype=str, delimiter=',')\n",
    "    if '/Users/jillnaiman' in thisDir: # probably should update if we have copied from google to local\n",
    "        Xtmp = []\n",
    "        for i in range(len(X_train)):\n",
    "            Xtmp.append(classDir_main_to+X_train[i].split('/')[-1])\n",
    "        X_train = Xtmp\n",
    "        Xtmp = []\n",
    "        for i in range(len(X_valid)):\n",
    "            Xtmp.append(classDir_main_to+X_valid[i].split('/')[-1])\n",
    "        X_valid = Xtmp\n",
    "        Xtmp = []\n",
    "        for i in range(len(X_test)):\n",
    "            Xtmp.append(classDir_main_to+X_test[i].split('/')[-1])\n",
    "        X_test = Xtmp\n",
    "        \n",
    "    # if rerun, do it!\n",
    "    logFiles = glob.glob(logsDir+'logs/training_1'+extraName+'/events*')\n",
    "    logFiles.sort()\n",
    "    #nRecent = 7\n",
    "    logFile = logFiles[-nRecent:] # most N recent\n",
    "    loss = []; val_loss = []; step = []\n",
    "    for l in logFile:\n",
    "        for summary in summary_iterator(l):\n",
    "            #print(summary)\n",
    "            if summary.step > 0: # only after start\n",
    "                ent = summary.summary.value[0]\n",
    "                if ent.tag == 'loss':\n",
    "                    loss.append(struct.unpack('f', ent.tensor.tensor_content)[0])\n",
    "                elif ent.tag == 'val_loss':\n",
    "                    val_loss.append(struct.unpack('f', ent.tensor.tensor_content)[0])\n",
    "                else:\n",
    "                    print('not sure:', ent)\n",
    "                step.append(summary.step)\n",
    "    step = np.unique(step).tolist()\n",
    "\n",
    "    # plot\n",
    "    stop = min([len(step),len(loss)])\n",
    "    if len(step[:stop]) > 0: # only plot if we have something\n",
    "        fig,ax = plt.subplots(figsize=(10,5))\n",
    "        ax.plot(step[:stop],loss[:stop],label='Training Loss')\n",
    "        stop = min([len(step),len(val_loss)])\n",
    "        ax.plot(step[:stop],val_loss[:stop], label='Validation Loss')\n",
    "        ax.set_xlabel('Epoch number')\n",
    "        ax.set_title('Loss for prior run')\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    # also, check for new annotations, add to new lists\n",
    "    X_all = X_train.copy()\n",
    "    if type(X_all) is not list: X_all = X_all.tolist()\n",
    "    X_all.extend(X_valid.copy())\n",
    "    X_all.extend(X_test.copy())\n",
    "    if len(X_train)+len(X_valid)+len(X_test) < len(annotations): # we have new annotations from last run!\n",
    "        # pick out new annotations\n",
    "        X_new = []; Y_new_str = []\n",
    "        for a,yfs in zip(annotations,Y_full_str):\n",
    "            if a not in X_all:\n",
    "                X_new.append(a); Y_new_str.append(yfs)\n",
    "\n",
    "        Y_new = []\n",
    "        labels = np.arange(len(LABELS))\n",
    "\n",
    "        for i in range(len(Y_new_str)):\n",
    "            try:\n",
    "                Y_new.append( labels[np.array(LABELS) == Y_new_str[i]][0] +1 ) # 0 means unlabeled data\n",
    "            except:\n",
    "                Y_new.append( 0 ) # 0 means unlabeled data\n",
    "\n",
    "            if len(labels[np.array(LABELS) == Y_new_str[i]]) > 1:\n",
    "                import sys\n",
    "                sys.exit()\n",
    "\n",
    "        Y_new = np.array(Y_new)\n",
    "        X_new = np.array(X_new)\n",
    "\n",
    "        # resplit\n",
    "        # note: y_* aren't actually used anywhere\n",
    "        X_train_new, y_train_new, X_valid_new, \\\n",
    "        y_valid_new, X_test_new, y_test_new = train_test_valid_split(X_new, Y_new, \n",
    "                                                                    train_size = train_per, \n",
    "                                                                      valid_size = valid_per, test_size = test_per, \n",
    "                                                                    textClassification=True, asInts=False)\n",
    "\n",
    "        print('We have', len(X_train_new), 'training,', len(X_valid_new), 'validation,', len(X_test_new), 'test NEW instances.')\n",
    "        # add\n",
    "        if type(X_train) is not list: X_train = X_train.tolist()\n",
    "        if type(X_valid) is not list: X_valid = X_valid.tolist()\n",
    "        if type(X_test) is not list: X_test = X_test.tolist()\n",
    "        X_train.extend(X_train_new)\n",
    "        X_valid.extend(X_valid_new)\n",
    "        X_test.extend(X_test_new)\n",
    "        print('We have', len(X_train), 'training,', len(X_valid), 'validation,', len(X_test), 'test TOTAL instances.')\n",
    "        # move old\n",
    "        shutil.copyfile(splitsDir + 'train.csv', splitsDir + 'train_old.csv')\n",
    "        shutil.copyfile(splitsDir + 'valid.csv', splitsDir + 'valid_old.csv')\n",
    "        shutil.copyfile(splitsDir + 'test.csv', splitsDir + 'test_old.csv')\n",
    "        # write files for \"filled in\" splits\n",
    "        np.savetxt(splitsDir + 'train.csv', X_train, fmt='%s', delimiter=',')\n",
    "        np.savetxt(splitsDir + 'test.csv', X_test, fmt='%s', delimiter=',')\n",
    "        np.savetxt(splitsDir + 'valid.csv', X_valid, fmt='%s', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRyluqn6vvaW"
   },
   "source": [
    "Steps per epoch -- training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1638455583041,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "SdEYPW-tvvaW",
    "outputId": "a3200ccd-6da9-4ef2-9607-6f126abf1459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch = training: 413 , validation: 82\n"
     ]
    }
   ],
   "source": [
    "#steps = len(X_train) // batch_size\n",
    "#print(len(X_train)//batch_size)\n",
    "# can do larger with augmentation\n",
    "\n",
    "#aug_fac = 2 # 2 or 3\n",
    "\n",
    "aug_fac = 1 # 2 or 3\n",
    "\n",
    "\n",
    "steps_training = (len(X_train)//batch_size)*aug_fac\n",
    "# factor of 2 from: https://stackoverflow.com/questions/49922252/choosing-number-of-steps-per-epoch\n",
    "\n",
    "steps_val = (len(X_valid)//batch_size)*aug_fac\n",
    "\n",
    "print('Steps per epoch = training:', steps_training, ', validation:', steps_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sExlEUTwIYBy"
   },
   "source": [
    "Save also the names of the test instances to use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1638455583308,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "y4LLclWnIQ49",
    "outputId": "acc77e47-d7fa-475c-9c50-901e91374442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, saved tests!\n"
     ]
    }
   ],
   "source": [
    "# save test list in an extra place... this is a bit redundant since its saved another place too\n",
    "#if not re_run_from_splits:\n",
    "np.savetxt(saveFile, X_test, delimiter=',',fmt='%s')\n",
    "print('Hey, saved tests!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gQi6kS8nea8"
   },
   "source": [
    "# 1. Define YOLO model\n",
    "\n",
    "For v5, see: https://github.com/jahongir7174/YOLOv5-tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoBEY7n67jy1"
   },
   "source": [
    "For creating the model -- how many features are we using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43600,
     "status": "ok",
     "timestamp": 1638455626905,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "ymfe7jyL7jy1",
    "outputId": "e90adedb-f1d4-4033-fe4b-ce65beafe6c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = get_n_features(classDir_main_to_imgs)\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 4704,
     "status": "ok",
     "timestamp": 1638455631604,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "KRQsM_X7XC-V"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "version = 'l' # large version\n",
    "model = build_model(n_features, anchors, version, len(LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXdkSQK9Emky"
   },
   "source": [
    "Build YOLOv5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1638455631605,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "0Vnf5mjn7jy2",
    "outputId": "67c42020-eff8-492d-be13-1c5f9786528b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512, 512, 1  0           []                               \n",
      "                                2)]                                                               \n",
      "                                                                                                  \n",
      " tf.nn.space_to_depth (TFOpLamb  (None, 256, 256, 48  0          ['input_1[0][0]']                \n",
      " da)                            )                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 64  27648       ['tf.nn.space_to_depth[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 257, 257, 64  0          ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 128, 12  73728       ['zero_padding2d[0][0]']         \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128, 128, 12  512        ['conv2d_1[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_1[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 64  8192        ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 64  256        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 64  4096        ['activation_2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 64  256        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 128, 128, 64  36864       ['activation_3[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 128, 128, 64  256        ['conv2d_4[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_4[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 128, 128, 64  0          ['activation_2[0][0]',           \n",
      " da)                            )                                 'activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 128, 128, 64  4096        ['tf.__operators__.add[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 128, 128, 64  256        ['conv2d_5[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_5[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 128, 128, 64  36864       ['activation_5[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 128, 128, 64  256        ['conv2d_6[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 128, 128, 64  0          ['tf.__operators__.add[0][0]',   \n",
      " mbda)                          )                                 'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 128, 128, 64  4096        ['tf.__operators__.add_1[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 128, 128, 64  256        ['conv2d_7[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 128, 128, 64  36864       ['activation_7[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 128, 128, 64  8192        ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 128, 128, 64  256        ['conv2d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 128, 128, 64  256        ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 128, 128, 64  0          ['tf.__operators__.add_1[0][0]', \n",
      " mbda)                          )                                 'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128, 128, 12  0           ['activation_9[0][0]',           \n",
      "                                8)                                'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 128, 128, 12  16384       ['concatenate[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 128, 128, 12  512        ['conv2d_10[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_10[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 129, 129, 12  0          ['activation_10[0][0]']          \n",
      " D)                             8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 64, 64, 256)  294912      ['zero_padding2d_1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 64, 64, 128)  32768       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 64, 64, 128)  512        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 64, 128)  16384       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 64, 64, 128)  512        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 64, 128)  147456      ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 64, 64, 128)  512        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 64, 64, 128)  0          ['activation_12[0][0]',          \n",
      " mbda)                                                            'activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 64, 128)  16384       ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 64, 64, 128)  512        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 64, 64, 128)  147456      ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 64, 64, 128)  512        ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 64, 64, 128)  0          ['tf.__operators__.add_3[0][0]', \n",
      " mbda)                                                            'activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 64, 64, 128)  16384       ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 64, 64, 128)  512        ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 64, 64, 128)  147456      ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 64, 64, 128)  512        ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 64, 64, 128)  0          ['tf.__operators__.add_4[0][0]', \n",
      " mbda)                                                            'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 64, 64, 128)  16384       ['tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 64, 64, 128)  512        ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 64, 64, 128)  147456      ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 64, 64, 128)  512        ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 64, 64, 128)  0          ['tf.__operators__.add_5[0][0]', \n",
      " mbda)                                                            'activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 64, 64, 128)  16384       ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 64, 64, 128)  512        ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 64, 64, 128)  147456      ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 64, 64, 128)  512        ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 64, 64, 128)  0          ['tf.__operators__.add_6[0][0]', \n",
      " mbda)                                                            'activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 64, 64, 128)  16384       ['tf.__operators__.add_7[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 64, 64, 128)  512        ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 64, 64, 128)  147456      ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 64, 64, 128)  512        ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 64, 64, 128)  0          ['tf.__operators__.add_7[0][0]', \n",
      " mbda)                                                            'activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 64, 64, 128)  16384       ['tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 64, 64, 128)  512        ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 64, 64, 128)  147456      ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 64, 64, 128)  512        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  (None, 64, 64, 128)  0          ['tf.__operators__.add_8[0][0]', \n",
      " mbda)                                                            'activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 64, 64, 128)  16384       ['tf.__operators__.add_9[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 64, 64, 128)  512        ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 64, 64, 128)  147456      ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 64, 64, 128)  512        ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 64, 64, 128)  0          ['tf.__operators__.add_9[0][0]', \n",
      " ambda)                                                           'activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 64, 64, 128)  16384       ['tf.__operators__.add_10[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 64, 64, 128)  512        ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 64, 64, 128)  147456      ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 64, 64, 128)  32768       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 64, 64, 128)  512        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 64, 64, 128)  512        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 64, 64, 128)  0          ['tf.__operators__.add_10[0][0]',\n",
      " ambda)                                                           'activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 256)  0           ['activation_31[0][0]',          \n",
      "                                                                  'tf.__operators__.add_11[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 64, 64, 256)  65536       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadding2  (None, 65, 65, 256)  0          ['activation_32[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 32, 32, 512)  1179648     ['zero_padding2d_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 32, 32, 256)  131072      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 32, 32, 256)  65536       ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (TFOpL  (None, 32, 32, 256)  0          ['activation_34[0][0]',          \n",
      " ambda)                                                           'activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 32, 32, 256)  65536       ['tf.__operators__.add_12[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (TFOpL  (None, 32, 32, 256)  0          ['tf.__operators__.add_12[0][0]',\n",
      " ambda)                                                           'activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 32, 32, 256)  65536       ['tf.__operators__.add_13[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (TFOpL  (None, 32, 32, 256)  0          ['tf.__operators__.add_13[0][0]',\n",
      " ambda)                                                           'activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 32, 32, 256)  65536       ['tf.__operators__.add_14[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (TFOpL  (None, 32, 32, 256)  0          ['tf.__operators__.add_14[0][0]',\n",
      " ambda)                                                           'activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 32, 32, 256)  65536       ['tf.__operators__.add_15[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (TFOpL  (None, 32, 32, 256)  0          ['tf.__operators__.add_15[0][0]',\n",
      " ambda)                                                           'activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 32, 32, 256)  65536       ['tf.__operators__.add_16[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (TFOpL  (None, 32, 32, 256)  0          ['tf.__operators__.add_16[0][0]',\n",
      " ambda)                                                           'activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 32, 32, 256)  65536       ['tf.__operators__.add_17[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (TFOpL  (None, 32, 32, 256)  0          ['tf.__operators__.add_17[0][0]',\n",
      " ambda)                                                           'activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 32, 32, 256)  65536       ['tf.__operators__.add_18[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (TFOpL  (None, 32, 32, 256)  0          ['tf.__operators__.add_18[0][0]',\n",
      " ambda)                                                           'activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 32, 32, 256)  65536       ['tf.__operators__.add_19[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 32, 32, 256)  131072      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (TFOpL  (None, 32, 32, 256)  0          ['tf.__operators__.add_19[0][0]',\n",
      " ambda)                                                           'activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 32, 32, 512)  0           ['activation_53[0][0]',          \n",
      "                                                                  'tf.__operators__.add_20[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 32, 32, 512)  262144      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_3 (ZeroPadding2  (None, 33, 33, 512)  0          ['activation_54[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 16, 16, 1024  4718592     ['zero_padding2d_3[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 16, 16, 1024  4096       ['conv2d_55[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 16, 16, 1024  0           ['batch_normalization_55[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 16, 16, 512)  524288      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " tf.nn.max_pool2d (TFOpLambda)  (None, 16, 16, 512)  0           ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.max_pool2d_1 (TFOpLambda  (None, 16, 16, 512)  0          ['activation_56[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.max_pool2d_2 (TFOpLambda  (None, 16, 16, 512)  0          ['activation_56[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 16, 16, 2048  0           ['activation_56[0][0]',          \n",
      "                                )                                 'tf.nn.max_pool2d[0][0]',       \n",
      "                                                                  'tf.nn.max_pool2d_1[0][0]',     \n",
      "                                                                  'tf.nn.max_pool2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 16, 16, 1024  2097152     ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 16, 16, 1024  4096       ['conv2d_57[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 16, 16, 1024  0           ['batch_normalization_57[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 16, 16, 512)  524288      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 16, 16, 512)  262144      ['activation_58[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 16, 16, 512)  2359296     ['activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 16, 16, 512)  262144      ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 16, 16, 512)  2359296     ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 16, 16, 512)  262144      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 16, 16, 512)  524288      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 16, 16, 512)  2359296     ['activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 16, 16, 1024  0           ['activation_65[0][0]',          \n",
      "                                )                                 'activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 16, 16, 1024  1048576     ['concatenate_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 16, 16, 1024  4096       ['conv2d_66[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 16, 16, 1024  0           ['batch_normalization_66[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 16, 16, 512)  524288      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 32, 32, 512)  0           ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 32, 32, 1024  0           ['up_sampling2d[0][0]',          \n",
      "                                )                                 'activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 32, 32, 256)  262144      ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 32, 32, 256)  65536       ['activation_68[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 32, 32, 256)  65536       ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_71[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 32, 32, 256)  65536       ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 32, 32, 256)  262144      ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 32, 32, 512)  0           ['activation_75[0][0]',          \n",
      "                                                                  'activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 32, 32, 512)  262144      ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 32, 32, 256)  131072      ['activation_76[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0          ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 64, 64, 512)  0           ['up_sampling2d_1[0][0]',        \n",
      "                                                                  'activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 64, 64, 128)  65536       ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 64, 64, 128)  512        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 64, 64, 128)  16384       ['activation_78[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 64, 64, 128)  512        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 64, 64, 128)  147456      ['activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 64, 64, 128)  512        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 64, 64, 128)  16384       ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 64, 64, 128)  512        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 64, 64, 128)  147456      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 64, 64, 128)  512        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 64, 64, 128)  16384       ['activation_82[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 64, 64, 128)  512        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 64, 64, 128)  65536       ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 64, 64, 128)  147456      ['activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 64, 64, 128)  512        ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 64, 64, 128)  512        ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 64, 64, 256)  0           ['activation_85[0][0]',          \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 64, 64, 256)  65536       ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadding2  (None, 65, 65, 256)  0          ['activation_86[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 32, 32, 256)  589824      ['zero_padding2d_4[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 32, 32, 512)  0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 32, 32, 256)  131072      ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 32, 32, 256)  65536       ['activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 32, 32, 256)  65536       ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_91[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 32, 32, 256)  65536       ['activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 32, 32, 256)  131072      ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 32, 32, 256)  589824      ['activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_95[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_94[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_95 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " activation_94 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 32, 32, 512)  0           ['activation_95[0][0]',          \n",
      "                                                                  'activation_94[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 32, 32, 512)  262144      ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_96[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_96 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadding2  (None, 33, 33, 512)  0          ['activation_96[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 16, 16, 512)  2359296     ['zero_padding2d_5[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_97[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_97 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 16, 16, 1024  0           ['activation_97[0][0]',          \n",
      "                                )                                 'activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 16, 16, 512)  524288      ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_98[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_98 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 16, 16, 512)  262144      ['activation_98[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_99[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_99 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, 16, 16, 512)  2359296     ['activation_99[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 16, 16, 512)  2048       ['conv2d_100[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_100 (Activation)    (None, 16, 16, 512)  0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, 16, 16, 512)  262144      ['activation_100[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, 16, 16, 512)  2048       ['conv2d_101[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_101 (Activation)    (None, 16, 16, 512)  0           ['batch_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, 16, 16, 512)  2359296     ['activation_101[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, 16, 16, 512)  2048       ['conv2d_102[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_102 (Activation)    (None, 16, 16, 512)  0           ['batch_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, 16, 16, 512)  262144      ['activation_102[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, 16, 16, 512)  2048       ['conv2d_103[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_103 (Activation)    (None, 16, 16, 512)  0           ['batch_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)            (None, 16, 16, 512)  524288      ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, 16, 16, 512)  2359296     ['activation_103[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, 16, 16, 512)  2048       ['conv2d_105[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, 16, 16, 512)  2048       ['conv2d_104[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_105 (Activation)    (None, 16, 16, 512)  0           ['batch_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " activation_104 (Activation)    (None, 16, 16, 512)  0           ['batch_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 16, 16, 1024  0           ['activation_105[0][0]',         \n",
      "                                )                                 'activation_104[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, 16, 16, 1024  1048576     ['concatenate_12[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, 16, 16, 1024  4096       ['conv2d_106[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_106 (Activation)    (None, 16, 16, 1024  0           ['batch_normalization_106[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " p5_4 (Conv2D)                  (None, 16, 16, 27)   27675       ['activation_106[0][0]']         \n",
      "                                                                                                  \n",
      " p4_4 (Conv2D)                  (None, 32, 32, 27)   13851       ['activation_96[0][0]']          \n",
      "                                                                                                  \n",
      " p3_4 (Conv2D)                  (None, 64, 64, 27)   6939        ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 46,729,809\n",
      "Trainable params: 46,668,241\n",
      "Non-trainable params: 61,568\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1638455631606,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "6tXmyitL7jy2"
   },
   "outputs": [],
   "source": [
    "# plot if you wanna\n",
    "#tf.keras.utils.plot_model(model_v5, \"yolo_v5.png\", show_shapes=True, show_layer_names=True, expand_nested=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AS4ZcPQg7jy2"
   },
   "source": [
    "For optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1638455631606,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "IWLTDSz77jy2"
   },
   "outputs": [],
   "source": [
    "LRrate = 0.004\n",
    "#LRrate = 0.002\n",
    "\n",
    "class CosineLR(tf.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self,steps):\n",
    "        super().__init__()\n",
    "        self.lr = LRrate * batch_size / 64\n",
    "        self.warmup_init = LRrate/10.\n",
    "        self.warmup_step = steps\n",
    "        self.decay_steps = tf.cast((num_epochs - 1) * self.warmup_step, tf.float32)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        linear_warmup = tf.cast(step, dtype=tf.float32) / self.warmup_step * (self.lr - self.warmup_init)\n",
    "        cosine_lr = 0.5 * self.lr * (1 + tf.cos(math.pi * tf.cast(step, tf.float32) / self.decay_steps))\n",
    "        return tf.where(step < self.warmup_step, self.warmup_init + linear_warmup, cosine_lr)\n",
    "\n",
    "    def get_config(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1638455631885,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "JpreDZDZvvaW"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(CosineLR(steps_training), 0.937)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1638455631885,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "_l3BLK6XDRms"
   },
   "outputs": [],
   "source": [
    "# load weights if you wanna\n",
    "if saved_weights_file is not None:\n",
    "    weightsFiles = glob.glob(weightsDir + 'weights/' + '*h5')\n",
    "    # OR\n",
    "    if saved_weights_file is not None:\n",
    "      weightsFiles = [classDirMain+saved_weights_file]\n",
    "    model.load_weights(weightsFiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1638455631886,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "3MAgw3DHD_nA",
    "outputId": "bcaf2526-7c06-4d2e-d2b1-1c829fa38ec3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000625"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(weightsFiles)\n",
    "optimizer.learning_rate.lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6Y0CbKb0T76"
   },
   "source": [
    "For saving checkpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1638455631886,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "REcMXF7W0T76"
   },
   "outputs": [],
   "source": [
    "# for saving model\n",
    "#save_model_name = chksDir + 'checkpoints/'+'model' + str(DATE.today().year).zfill(4) + str(DATE.today().month).zfill(2) + str(DATE.today().day).zfill(2) +'.h5'\n",
    "#checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(save_model_name, save_best_only=True)\n",
    "# today = str(DATE.today().year).zfill(4) + str(DATE.today().month).zfill(2) + str(DATE.today().day).zfill(2)\n",
    "# if not os.path.exists(chksDir + 'checkpoints/'+today):\n",
    "#     os.mkdir(chksDir + 'checkpoints/'+today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1638455631886,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "h2o2DlWC0T77"
   },
   "outputs": [],
   "source": [
    "#model2 = tf.saved_model.load(save_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1638455631887,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "gBbSfeKP0T77"
   },
   "outputs": [],
   "source": [
    "# if restart_from_checkpoints:\n",
    "#     if saved_model_file is None:\n",
    "#         files = glob.glob(chksDir + 'checkpoints/*')\n",
    "#         files.sort()\n",
    "#         model = tf.saved_model.load(files[-1])\n",
    "#         fname = files[-1]\n",
    "#     else:\n",
    "#         model = tf.saved_model.load(chksDir + 'checkpoints/' +saved_model_file)\n",
    "#         fname = chksDir + 'checkpoints/' +saved_model_file\n",
    "#     print('Loading model from', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKk7HxgC7jy3"
   },
   "source": [
    "# For processing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1638455631887,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "KFOuGj5l0T77",
    "outputId": "0c1dbc6c-9373-473f-b9a5-875440d50132"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./classifications/'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classDirMain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1638455631887,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "qqdxpzdoBb6H",
    "outputId": "a62d0dbb-8966-42a6-ef3a-cde4fe98d590"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./classifications/binaries_model8/', './classifications/yolo_512x512_ann/')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classDir_main_to_imgs, classDir_main_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1638455631888,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "-L428Dy7VxBV"
   },
   "outputs": [],
   "source": [
    "#import mega_yolo_utils\n",
    "#reload(mega_yolo_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1638455631888,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "RiM8WUcKGrFn"
   },
   "outputs": [],
   "source": [
    "from mega_yolo_utils import augmentation_generator, csv_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1638455631888,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "ewFdU9-77jy3"
   },
   "outputs": [],
   "source": [
    "splitsDirIn = None\n",
    "if onGoogle: splitsDirIn = classDirMain\n",
    "train_gen_csv = csv_gen('train', splitsDir=splitsDirIn)\n",
    "valid_gen_csv = csv_gen('valid',splitsDir=splitsDirIn)\n",
    "test_gen_csv = csv_gen('test',splitsDir=splitsDirIn)\n",
    "\n",
    "# def csv_gen(split):\n",
    "#     ftrain = open(splitsDir+'train.csv','r')\n",
    "#     fvalid = open(splitsDir+'valid.csv','r')\n",
    "#     ftest = open(splitsDir+'test.csv','r')    \n",
    "#     while True:\n",
    "#     #for i in range(100000):\n",
    "#         if b'train' in bytes(split, encoding='utf8'): # NOTE, must be bytes here!!!\n",
    "#             line = ftrain.readline()\n",
    "#             if line == \"\": # if EOF => loop back to start\n",
    "#                 ftrain.seek(0)\n",
    "#                 line = ftrain.readline()\n",
    "#         elif b'valid' in bytes(split, encoding='utf8'):\n",
    "#             line = fvalid.readline()\n",
    "#             if line == \"\": # if EOF => loop back to start\n",
    "#                 fvalid.seek(0)\n",
    "#                 line = fvalid.readline()\n",
    "#         elif b'test' in bytes(split, encoding='utf8'):\n",
    "#             line = ftest.readline()\n",
    "#             if line == \"\": # if EOF => loop back to start\n",
    "#                 ftest.seek(0)\n",
    "#                 line = ftest.readline()\n",
    "#                 # make sure if we are evaluating with the test set \n",
    "#                 #  we don't loop back to the start of the file\n",
    "#                 break \n",
    "#         else:\n",
    "#             print('NOPE!')\n",
    "#             sys.exit()\n",
    "#         yield line\n",
    "        \n",
    "# train_gen_csv = csv_gen('train')\n",
    "# valid_gen_csv = csv_gen('valid')\n",
    "# test_gen_csv = csv_gen('test')\n",
    "\n",
    "def dataset_gen(split, batch_size):\n",
    "    while True:\n",
    "        true_boxes = []; imgs = []; files = []\n",
    "        \n",
    "        while len(files) < batch_size:\n",
    "            if type(split) == str:\n",
    "                if b'train' in bytes(split, encoding='utf8'): # NOTE, must be bytes here!!!\n",
    "                    line = next(train_gen_csv)\n",
    "                elif b'valid' in bytes(split, encoding='utf8'):\n",
    "                    line = next(valid_gen_csv)\n",
    "                elif b'test' in bytes(split, encoding='utf8'):\n",
    "                    line = next(test_gen_csv)\n",
    "            else:\n",
    "                if b'train' in split: # NOTE, must be bytes here!!!\n",
    "                    line = next(train_gen_csv)\n",
    "                elif b'valid' in split:\n",
    "                    line = next(valid_gen_csv)\n",
    "                elif b'test' in split:\n",
    "                    line = next(test_gen_csv)\n",
    "            \n",
    "            files.append(line.strip())\n",
    "\n",
    "        # parse and get full names\n",
    "        try:\n",
    "            imgs_name, bbox = parse_annotation(files, LABELS, \n",
    "                                               feature_dir=classDir_main_to_imgs,\n",
    "                                               annotation_dir=classDir_main_to)\n",
    "        except:\n",
    "            print('error parsing:', imgs_name)\n",
    "        # do a debug check\n",
    "        for im in imgs_name:\n",
    "            if '.npz' not in im:\n",
    "                print('no np file')\n",
    "                import sys; sys.exit()\n",
    "        \n",
    "        # read in and keep images -- npy files\n",
    "        for im in imgs_name:\n",
    "            b = np.load(im)['arr_0']\n",
    "            \n",
    "            ########### DEBUGGING ##########\n",
    "            #b = b[:,:,:3]\n",
    "            ################################\n",
    "            \n",
    "            # convert 0-1\n",
    "            b = b/255.0\n",
    "            imgs.append(b)\n",
    "        \n",
    "        # finally, format for output\n",
    "        y_true1, y_true2, y_true3 = [],[],[]\n",
    "        for b in bbox:\n",
    "            y1,y2,y3= process_box(b[:,:4], b[:,4].astype('int'),anchors,CLASS)\n",
    "            y_true1.append(y1); y_true2.append(y2); y_true3.append(y3)\n",
    "        # if there is no box, do something different\n",
    "        if len(bbox) == 0:\n",
    "            # fake a box\n",
    "            b = np.array([[111.,  59., 403., 364. ,  4.]])\n",
    "            y1,y2,y3= process_box(b[:,:4], b[:,4].astype('int'),anchors,CLASS)\n",
    "            y1[:] = 0; y2[:]=0;y3[:]=0\n",
    "            y_true1.append(y1); y_true2.append(y2); y_true3.append(y3)        \n",
    "        img = tf.cast(np.array(imgs), tf.float32)        \n",
    "        yield img, tf.cast(y_true1, tf.float32), tf.cast(y_true2, tf.float32), tf.cast(y_true3, tf.float32)\n",
    "        \n",
    "\n",
    "def dataset_gen_for_aug(split, batch_size): # for training/validation datasets\n",
    "    while True:\n",
    "        true_boxes = []; imgs = []; files = []\n",
    "        \n",
    "        while len(files) < batch_size:\n",
    "            if type(split) == str:\n",
    "                if b'train' in bytes(split, encoding='utf8'): # NOTE, must be bytes here!!!\n",
    "                    line = next(train_gen_csv)\n",
    "                elif b'valid' in bytes(split, encoding='utf8'):\n",
    "                    line = next(valid_gen_csv)\n",
    "                elif b'test' in bytes(split, encoding='utf8'):\n",
    "                    line = next(test_gen_csv)\n",
    "            else:\n",
    "                if b'train' in split: # NOTE, must be bytes here!!!\n",
    "                    line = next(train_gen_csv)\n",
    "                elif b'valid' in split:\n",
    "                    line = next(valid_gen_csv)\n",
    "                elif b'test' in split:\n",
    "                    line = next(test_gen_csv)\n",
    "            \n",
    "            files.append(line.strip())\n",
    "\n",
    "        # parse and get full names\n",
    "        imgs_name, bbox = parse_annotation(files, LABELS, \n",
    "                                           feature_dir=classDir_main_to_imgs,\n",
    "                                            annotation_dir=classDir_main_to)\n",
    "        # do a debug check\n",
    "        for im in imgs_name:\n",
    "            if '.npz' not in im:\n",
    "                print('no np file')\n",
    "                import sys; sys.exit()\n",
    "        \n",
    "        # read in and keep images -- npy files\n",
    "        for im in imgs_name:\n",
    "            b = np.load(im)['arr_0']\n",
    "            # convert 0-1\n",
    "            b = b/255.0\n",
    "            imgs.append(b)\n",
    "                \n",
    "        img = tf.cast(np.array(imgs), tf.float32)        \n",
    "        yield img, tf.cast(bbox, tf.float32)\n",
    "        \n",
    "\n",
    "def get_dataset(split, labels, batch_size, use_aug=True):\n",
    "    if use_aug and ('test' not in split.lower()):\n",
    "        dataset = tf.data.Dataset.from_generator(dataset_gen_for_aug, args=[split, batch_size],\n",
    "                                                 output_types = (tf.float32, tf.float32))\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_generator(dataset_gen, args=[split, batch_size],\n",
    "                                             output_types = (tf.float32, tf.float32, \n",
    "                                                             tf.float32, tf.float32))\n",
    "                                             \n",
    "    dataset = dataset.prefetch(10)\n",
    "    \n",
    "    # maybe?\n",
    "    iterator = iter(dataset)\n",
    "\n",
    "    #return dataset\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1638455632229,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "iCHTV-qu7jy4"
   },
   "outputs": [],
   "source": [
    "# grab data!\n",
    "train_dataset = None\n",
    "train_dataset= get_dataset('train', LABELS, TRAIN_BATCH_SIZE)\n",
    "\n",
    "val_dataset = None\n",
    "val_dataset= get_dataset('valid', LABELS,VAL_BATCH_SIZE,use_aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1638455632230,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "lsQQuI7dzZJw"
   },
   "outputs": [],
   "source": [
    "#next(valid_gen_csv)\n",
    "#next(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1638455632230,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "OfxcXCqPyXZj"
   },
   "outputs": [],
   "source": [
    "#val_dataset= get_dataset('valid', LABELS, VAL_BATCH_SIZE,use_aug=True)\n",
    "#next(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvgdY6ly7jy4"
   },
   "source": [
    "Including Augmentation like a boss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1638455632230,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "nm5833D_7jy5"
   },
   "outputs": [],
   "source": [
    "aug_train_dataset = augmentation_generator(train_dataset, anchors, CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5doQu9r7jy5"
   },
   "source": [
    "For calculating the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1638455632751,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "oWeoMEdE7jy5"
   },
   "outputs": [],
   "source": [
    "class ComputeLoss(object):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_loss(y_pred, y_true, anchors):\n",
    "        grid_size = tf.shape(y_pred)[1:3]\n",
    "        ratio = tf.cast(tf.constant([image_size, image_size]) / grid_size, tf.float32)\n",
    "        batch_size = tf.cast(tf.shape(y_pred)[0], tf.float32)\n",
    "\n",
    "        x_y_offset, pred_boxes, pred_conf, pred_prob = process_layer(y_pred, anchors,CLASS)\n",
    "\n",
    "        object_mask = y_true[..., 4:5]\n",
    "\n",
    "        def cond(idx, _):\n",
    "            return tf.less(idx, tf.cast(batch_size, tf.int32))\n",
    "\n",
    "        def body(idx, mask):\n",
    "            valid_true_boxes = tf.boolean_mask(y_true[idx, ..., 0:4],\n",
    "                                               tf.cast(object_mask[idx, ..., 0], 'bool'))\n",
    "            iou = box_iou(pred_boxes[idx], valid_true_boxes)\n",
    "            return idx + 1, mask.write(idx, tf.cast(tf.reduce_max(iou, axis=-1) < 0.2, tf.float32))\n",
    "\n",
    "        ignore_mask = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "        \n",
    "        #print('here1.1')\n",
    "        #print(cond, body, ignore_mask)\n",
    "\n",
    "        _, ignore_mask = tf.while_loop(cond=cond, body=body, loop_vars=[0, ignore_mask])\n",
    "        \n",
    "        #print('here1.2')\n",
    "        ignore_mask = ignore_mask.stack()\n",
    "        ignore_mask = tf.expand_dims(ignore_mask, -1)\n",
    "\n",
    "        true_xy = y_true[..., 0:2] / ratio[::-1] - x_y_offset\n",
    "        pred_xy = pred_boxes[..., 0:2] / ratio[::-1] - x_y_offset\n",
    "\n",
    "        true_tw_th = y_true[..., 2:4] / anchors\n",
    "        pred_tw_th = pred_boxes[..., 2:4] / anchors\n",
    "        true_tw_th = tf.where(tf.equal(true_tw_th, 0), tf.ones_like(true_tw_th), true_tw_th)\n",
    "        pred_tw_th = tf.where(tf.equal(pred_tw_th, 0), tf.ones_like(pred_tw_th), pred_tw_th)\n",
    "        true_tw_th = tf.math.log(tf.clip_by_value(true_tw_th, 1e-9, 1e+9))\n",
    "        pred_tw_th = tf.math.log(tf.clip_by_value(pred_tw_th, 1e-9, 1e+9))\n",
    "\n",
    "        box_loss_scale = y_true[..., 2:3] * y_true[..., 3:4]\n",
    "        box_loss_scale = 2. - box_loss_scale / tf.cast(image_size ** 2, tf.float32)\n",
    "\n",
    "        xy_loss = tf.reduce_sum(tf.square(true_xy - pred_xy) * object_mask * box_loss_scale)\n",
    "        wh_loss = tf.reduce_sum(tf.square(true_tw_th - pred_tw_th) * object_mask * box_loss_scale)\n",
    "\n",
    "        conf_pos_mask = object_mask\n",
    "        conf_neg_mask = (1 - object_mask) * ignore_mask\n",
    "        conf_loss_pos = conf_pos_mask * tf.nn.sigmoid_cross_entropy_with_logits(labels=object_mask, logits=pred_conf)\n",
    "        conf_loss_neg = conf_neg_mask * tf.nn.sigmoid_cross_entropy_with_logits(labels=object_mask, logits=pred_conf)\n",
    "        # try this\n",
    "        #conf_loss_pos = conf_pos_mask * -tf.reduce_sum(object_mask*tf.math.log(tf.clip_by_value(pred_conf,1e-10,1.0)))\n",
    "        #conf_loss_neg = conf_neg_mask * -tf.reduce_sum(object_mask*tf.math.log(tf.clip_by_value(pred_conf,1e-10,1.0)))\n",
    "\n",
    "\n",
    "        conf_loss = tf.reduce_sum((conf_loss_pos + conf_loss_neg))\n",
    "\n",
    "        true_conf = y_true[..., 5:]\n",
    "\n",
    "        class_loss = object_mask * tf.nn.sigmoid_cross_entropy_with_logits(true_conf, pred_prob)\n",
    "        #class_loss = object_mask * -tf.reduce_sum(true_conf*tf.math.log(tf.clip_by_value(pred_conf,1e-10,1.0)))\n",
    "        #class_loss = object_mask * tf.losses.categorical_crossentropy(true_conf, pred_prob)\n",
    "        #tf.losses.sparse_softmax_cross_entropy(y, logits)\n",
    "        class_loss = tf.reduce_sum(class_loss) # sum across all -- 1 number for loss\n",
    "\n",
    "        if np.isnan(xy_loss):\n",
    "          print('xy_loss is NaN')\n",
    "        if np.isnan(wh_loss):\n",
    "          print('wh_loss is NaN')\n",
    "        if np.isnan(conf_loss):\n",
    "          print('conf_loss is NaN')#, conf_loss_pos, conf_loss_neg)\n",
    "        if np.isnan(class_loss):\n",
    "          print('class_loss is NaN')\n",
    "\n",
    "        if np.isnan(xy_loss + wh_loss + conf_loss + class_loss):\n",
    "          print('--- object mask ---')\n",
    "          print(object_mask.numpy().shape, pred_conf.numpy().shape, true_conf.numpy().shape)\n",
    "          print(object_mask.numpy().max(), object_mask.numpy().min())\n",
    "          print(object_mask)\n",
    "          print(' ')\n",
    "          print('--------')\n",
    "        #else:\n",
    "        #  print(object_mask.numpy().max(), object_mask.numpy().min())\n",
    "\n",
    "        return xy_loss + wh_loss + conf_loss + class_loss\n",
    "\n",
    "    def __call__(self, y_pred, y_true):\n",
    "        loss = 0.\n",
    "        anchor_group = [anchors[6:9], anchors[3:6], anchors[0:3]]\n",
    "\n",
    "        for i in range(len(y_pred)):\n",
    "            loss += self.compute_loss(y_pred[i], y_true[i], anchor_group[i])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1638455632752,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "XZZsr5247jy6"
   },
   "outputs": [],
   "source": [
    "loss_object = ComputeLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1638455632752,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "9lBB1U-k0T7-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1638455632752,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "ZbiMja467jy6"
   },
   "outputs": [],
   "source": [
    "def compute_loss(y_true, y_pred):\n",
    "    total_loss = loss_object(y_pred, y_true)\n",
    "    return tf.reduce_sum(total_loss) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1638455632753,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "fbZopKn57jy6"
   },
   "outputs": [],
   "source": [
    "def train_step(image, y_true):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(image, training=True)\n",
    "        loss = compute_loss(y_true, y_pred)\n",
    "    if not np.isnan(loss):\n",
    "        variables = model.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        #if np.isnan(loss):\n",
    "        #  print('nan')\n",
    "        #  print\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "    else: # this will stop if we have non-convergence \n",
    "        print('is NaN -- probably want to lower your learning rate!!!!')\n",
    "        import sys; sys.exit()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1638455632753,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "l1ftaeHUvvab"
   },
   "outputs": [],
   "source": [
    "# save weights\n",
    "def save_best_weights(model, name, val_loss_avg):\n",
    "    # delete existing weights file\n",
    "    files = glob.glob(os.path.join(weightsDir + 'weights/', name + '*'))\n",
    "    for file in files:\n",
    "        os.remove(file)\n",
    "    # create new weights file\n",
    "    name = name + '_model_' +version + str(val_loss_avg) + '.h5'\n",
    "    path_name = os.path.join(weightsDir +'weights/', name)\n",
    "    model.save_weights(path_name)\n",
    "    \n",
    "    \n",
    "# log (tensorboard)\n",
    "def log_loss(loss, val_loss, step):\n",
    "    tf.summary.scalar('loss', loss, step)\n",
    "    tf.summary.scalar('val_loss', val_loss, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1638455632754,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "C19AoZV9loKh",
    "outputId": "9db600e0-59d8-486f-e8bb-0a0a5e120ccc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./classifications/yolo_512x512_ann/'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classDir_main_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1638455632754,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "omK8Zjfc7jy6"
   },
   "outputs": [],
   "source": [
    "# training\n",
    "def train(epochs, model, train_dataset, val_dataset, steps_per_epoch_train, \n",
    "          steps_per_epoch_val, optimizer, train_name = 'train'):\n",
    "    '''\n",
    "    Train YOLO model for n epochs.\n",
    "    Eval loss on training and validation dataset.\n",
    "    Log training loss and validation loss for tensorboard.\n",
    "    Save best weights during training (according to validation loss).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - epochs : integer, number of epochs to train the model.\n",
    "    - model : YOLO model.\n",
    "    - train_dataset : YOLO ground truth and image generator from training dataset.\n",
    "    - val_dataset : YOLO ground truth and image generator from validation dataset.\n",
    "    - steps_per_epoch_train : integer, number of batch to complete one epoch for train_dataset.\n",
    "    - steps_per_epoch_val : integer, number of batch to complete one epoch for val_dataset.\n",
    "    - train_name : string, training name used to log loss and save weights.\n",
    "    \n",
    "    Notes :\n",
    "    - train_dataset and val_dataset generate YOLO ground truth tensors : detector_mask,\n",
    "      matching_true_boxes, class_one_hot, true_boxes_grid. Shape of these tensors (batch size, tensor shape).\n",
    "    - steps per epoch = number of images in dataset // batch size of dataset\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    - loss history : [train_loss_history, val_loss_history] : list of average loss for each epoch.\n",
    "    '''\n",
    "    num_epochs1 = epochs\n",
    "    steps_per_epoch_train = steps_per_epoch_train\n",
    "    steps_per_epoch_val = steps_per_epoch_val\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    best_val_loss = 1e6\n",
    "    \n",
    "    # optimizer\n",
    "    #optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    \n",
    "    # log (tensorboard)\n",
    "    summary_writer = tf.summary.create_file_writer(os.path.join(logsDir+'logs/', train_name), \n",
    "                                                   flush_millis=20000)\n",
    "    summary_writer.set_as_default()\n",
    "    \n",
    "    # training\n",
    "    for epoch in range(num_epochs1):\n",
    "        epoch_loss = []\n",
    "        epoch_val_loss = []\n",
    "        epoch_val_sub_loss = []\n",
    "        print('Epoch {} :'.format(epoch))\n",
    "        # train\n",
    "        for batch_idx in range(steps_per_epoch_train):        \n",
    "            image, y_true_1, y_true_2, y_true_3 = next(train_dataset)\n",
    "            y_true = (y_true_1, y_true_2, y_true_3)\n",
    "            loss = train_step(image, y_true)\n",
    "            # check for nans\n",
    "            optOrig = optimizer.learning_rate.lr\n",
    "            while np.isnan(loss):\n",
    "              print('loss nan')\n",
    "              optimizer.learning_rate.lr *= 0.5\n",
    "              loss = train_step(image, y_true)\n",
    "            epoch_loss.append(loss)\n",
    "            print('-', end='')\n",
    "        print(' | ', end='')\n",
    "        # val\n",
    "        for batch_idx in range(steps_per_epoch_val): \n",
    "            image, y_true_1, y_true_2, y_true_3 = next(val_dataset)\n",
    "            y_true = (y_true_1, y_true_2, y_true_3)\n",
    "            loss = train_step(image, y_true)\n",
    "            epoch_val_loss.append(loss)\n",
    "            print('-', end='')\n",
    "\n",
    "        loss_avg = np.mean(np.array(epoch_loss))\n",
    "        val_loss_avg = np.mean(np.array(epoch_val_loss))\n",
    "        train_loss_history.append(loss_avg)\n",
    "        val_loss_history.append(val_loss_avg)\n",
    "        \n",
    "        # log\n",
    "        log_loss(loss_avg, val_loss_avg, epoch)\n",
    "        \n",
    "        # save\n",
    "        if val_loss_avg < best_val_loss:\n",
    "            save_best_weights(model, train_name, val_loss_avg)\n",
    "            best_val_loss = val_loss_avg\n",
    "            #tf.saved_model.save(model, chksDir + 'checkpoints/'+today)        \n",
    "        print(' loss = {:.4f}, val_loss = {:.4f}'.format(loss_avg, val_loss_avg))\n",
    "        \n",
    "    return [train_loss_history, val_loss_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 30543295,
     "status": "error",
     "timestamp": 1638486176039,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "l2FpED3Dvvac",
    "outputId": "f22e2867-6b4a-4571-94d1-2b9a5b1cd2ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 1248.1118, val_loss = 70.4698\n",
      "Epoch 1 :\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 45.5740, val_loss = 29.9030\n",
      "Epoch 2 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 27.9317, val_loss = 21.0205\n",
      "Epoch 3 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 21.4633, val_loss = 17.8319\n",
      "Epoch 4 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 18.4384, val_loss = 15.2870\n",
      "Epoch 5 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 16.3001, val_loss = 14.0304\n",
      "Epoch 6 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 15.0627, val_loss = 12.0146\n",
      "Epoch 7 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 13.2663, val_loss = 10.5298\n",
      "Epoch 8 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 11.9219, val_loss = 9.5759\n",
      "Epoch 9 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 10.8955, val_loss = 8.7724\n",
      "Epoch 10 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 10.1621, val_loss = 7.6921\n",
      "Epoch 11 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 9.1949, val_loss = 7.0505\n",
      "Epoch 12 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 8.4634, val_loss = 6.6984\n",
      "Epoch 13 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 8.1502, val_loss = 6.1214\n",
      "Epoch 14 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 7.5067, val_loss = 5.6582\n",
      "Epoch 15 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 7.0183, val_loss = 5.3483\n",
      "Epoch 16 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 6.9992, val_loss = 5.1377\n",
      "Epoch 17 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 6.7491, val_loss = 5.2978\n",
      "Epoch 18 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 6.4777, val_loss = 4.7418\n",
      "Epoch 19 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 6.1694, val_loss = 4.4927\n",
      "Epoch 20 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 6.0417, val_loss = 4.3680\n",
      "Epoch 21 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 6.0343, val_loss = 4.2173\n",
      "Epoch 22 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 5.7581, val_loss = 4.0994\n",
      "Epoch 23 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 5.4969, val_loss = 3.9718\n",
      "Epoch 24 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 5.4462, val_loss = 3.7055\n",
      "Epoch 25 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 5.3575, val_loss = 3.9045\n",
      "Epoch 26 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 4.9502, val_loss = 3.3405\n",
      "Epoch 27 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 4.9849, val_loss = 3.2992\n",
      "Epoch 28 :\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- loss = 4.8162, val_loss = 3.2626\n",
      "Epoch 29 :\n",
      "-----------------"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-60f949779889>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m results = train(num_epochs, model, aug_train_dataset, val_dataset, \n\u001b[0;32m----> 2\u001b[0;31m                steps_training, steps_val, optimizer,'training_1'+extraName)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#results = train(num_epochs, model, aug_train_dataset, val_dataset,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-686a16384a66>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, model, train_dataset, val_dataset, steps_per_epoch_train, steps_per_epoch_val, optimizer, train_name)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_true_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/gdrive/My Drive/Colab Notebooks/scienceDigitization/mega_yolo_utils.py\u001b[0m in \u001b[0;36maugmentation_generator\u001b[0;34m(yolo_dataset, anchors, CLASS, flipUpDown)\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m     '''\n\u001b[0;32m-> 1259\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myolo_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m         \u001b[0;31m# conversion tensor->numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    798\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    784\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2843\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2845\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2846\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7107\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: NameError: name 'glob' is not defined\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 275, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 649, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 992, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-37-612f85b8c85a>\", line 128, in dataset_gen_for_aug\n    annotation_dir=classDir_main_to)\n\n  File \"/content/gdrive/My Drive/Colab Notebooks/scienceDigitization/general_utils.py\", line 95, in parse_annotation\n    iname = glob(iname+'*')[0]\n\nNameError: name 'glob' is not defined\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "results = train(num_epochs, model, aug_train_dataset, val_dataset, \n",
    "               steps_training, steps_val, optimizer,'training_1'+extraName)\n",
    "\n",
    "# debug\n",
    "#results = train(num_epochs, model, aug_train_dataset, val_dataset, \n",
    "#               1, 1, optimizer,'training_1'+extraName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqGPwg0R7jy6"
   },
   "source": [
    "Plot diagnostics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 256,
     "status": "aborted",
     "timestamp": 1638486175177,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "68HC1xUF7jy6"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,14))\n",
    "ax.plot(results[0], label='Training Loss')\n",
    "ax.plot(results[1], label='Validation Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 256,
     "status": "aborted",
     "timestamp": 1638486175178,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "EjYMDlLo7jy7"
   },
   "outputs": [],
   "source": [
    "# imgs_name, bbox = parse_annotation([X_train[0]], LABELS, \n",
    "#                                    classDir_main_to_imgs=classDir_main_to_imgs,\n",
    "#                                        classDir_main_to_ann=classDir_main_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 256,
     "status": "aborted",
     "timestamp": 1638486175178,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "theCs-467jy8"
   },
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# reload(parse_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 257,
     "status": "aborted",
     "timestamp": 1638486175179,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "orYNx10Y7jy8"
   },
   "outputs": [],
   "source": [
    "#import general_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 257,
     "status": "aborted",
     "timestamp": 1638486175179,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "1OXBhSDS7jy8"
   },
   "outputs": [],
   "source": [
    "#reload(general_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 257,
     "status": "aborted",
     "timestamp": 1638486175179,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "tKhsRWNh7jy8"
   },
   "outputs": [],
   "source": [
    "#from general_utils import parse_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 258,
     "status": "aborted",
     "timestamp": 1638486175180,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "8eIrQ2HH5C8Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 258,
     "status": "aborted",
     "timestamp": 1638486175180,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "wXSKvTs95Pp6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "aborted",
     "timestamp": 1638486175181,
     "user": {
      "displayName": "Jill Naiman",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13328008118965652761"
     },
     "user_tz": 360
    },
    "id": "ihigRX4m5QaB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "mega_yolo_train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
