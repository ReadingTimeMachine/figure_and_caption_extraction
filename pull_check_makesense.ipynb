{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3318403e",
   "metadata": {},
   "source": [
    "# Pull images to classify with MakeSense.ai\n",
    "\n",
    "Randomly pulled, tracked, for use with [MakeSense.ai](https://www.makesense.ai/) as a possible annotation interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a85ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "68a7a2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # PMC PubLayNet\n",
    "# check_makesense = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/Annotations_pmcnoncom/MakeSenseAnnotations/'\n",
    "# save_makesense = check_makesense\n",
    "# PMC PubLayNet\n",
    "# ocr_results_dir = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/OCR_processing_pmcnoncom/'\n",
    "# images_jpeg_dir = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/Pages_pmcnoncom/RandomSingleFromPDFIndexed/'\n",
    "# check_json_dir = None\n",
    "\n",
    "# ScanBank\n",
    "check_makesense = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/Annotations_scanbank/MakeSenseAnnotations/'\n",
    "save_makesense = check_makesense\n",
    "# ScanBank\n",
    "ocr_results_dir = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/OCR_processing_scanbank/'\n",
    "images_jpeg_dir = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/Pages_scanbank/RandomSingleFromPDFIndexed/'\n",
    "check_json_dir = '/Users/jillnaiman/deepfigures-results/' # check for empty json files? set to None to skip\n",
    "\n",
    "\n",
    "# DEFAULTS\n",
    "# where to look for already completed MakeSense annotations\n",
    "#check_makesense = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/Annotations/MakeSenseAnnotations/'\n",
    "# # where to save new annotations\n",
    "# save_makesense = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/Annotations/MakeSenseAnnotations_test/'\n",
    "# check_makesense = ['/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/Annotations/MakeSenseAnnotations/',\n",
    "#                    '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/Annotations/MakeSenseAnnotations_test/']\n",
    "# # defaults\n",
    "# ocr_results_dir = None\n",
    "# images_jpeg_dir = None\n",
    "# check_json_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e692463f-bb95-4085-8532-697ed4ee58cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a winner!\n",
    "binary_dirs = 'binaries_model12_tfrecordz/'\n",
    "weightsFileDir = config.save_weights_dir +'saved_weights/'+'20211218_model12tfz/'\n",
    "weightsFile = 'training_1model12_tfrec_model_l0.019131713.h5'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afe74df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many you wanna grab?\n",
    "nRandom = 100\n",
    "\n",
    "# invert colors?\n",
    "invert_colors = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b13735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels for annotations:\n",
    "labels = ['figure', 'figure caption', 'table', 'math formula', 'sub fig caption', 'colorbar', 'NotSure', 'no label'] # no label is for nothing on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d500faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import post_processing_utils\n",
    "# from importlib import reload\n",
    "# reload(post_processing_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab1c88a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jillnaiman/anaconda3/envs/Paper1/lib/python3.7/site-packages/yt/utilities/logger.py:4: VisibleDeprecationWarning: The configuration file /Users/jillnaiman/.config/yt/ytrc is deprecated in favor of /Users/jillnaiman/.config/yt/yt.toml. Currently, both are present. Please manually remove the deprecated one to silence this warning.\n",
      "Deprecated since v4.0.0. This feature will be removed in v4.1.0\n",
      "  from yt.config import ytcfg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "\n",
    "from annotation_utils import get_all_ocr_files, collect_ocr_process_results\n",
    "from mega_yolo_utils import build_predict\n",
    "from feature_generation_utils import generate_single_feature\n",
    "from post_processing_utils import get_ocr_results,get_image_process_boxes, \\\n",
    "    clean_merge_heurstic_captions, clean_overlapping_squares, clean_found_overlap_with_ocr, \\\n",
    "    clean_merge_squares, clean_big_captions, clean_match_fig_cap, expand_found_boxes_fig_cap, \\\n",
    "    expand_found_area_above_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcc97912",
   "metadata": {},
   "outputs": [],
   "source": [
    "if images_jpeg_dir is None: images_jpeg_dir = config.images_jpeg_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "708ef1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save labels\n",
    "# save feature list\n",
    "with open(save_makesense +'saved_labels.pickle', 'wb') as ff:\n",
    "    pickle.dump([labels], ff)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca9db05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/OCR_processing_scanbank/full_ocr_newPDFs_TIFF_take1.pickle',\n",
       " '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/BenchMarks/OCR_processing_scanbank/full_ocr_newPDFs_TIFF_take2.pickle']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocrFiles = get_all_ocr_files(ocr_results_dir=ocr_results_dir)\n",
    "ocrFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b53ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import annotation_utils\n",
    "# reload(annotation_utils)\n",
    "# from annotation_utils import collect_ocr_process_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a070de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retreiving OCR data, this can take a moment...\n",
      "##### OCR retrieval FILE: on 1 of 2  ##### \n",
      "--- OCR retrieval: on 0 of 700 ---\n",
      "##### OCR retrieval FILE: on 2 of 2  ##### \n",
      "--- OCR retrieval: on 0 of 700 ---\n"
     ]
    }
   ],
   "source": [
    "print('retreiving OCR data, this can take a moment...')\n",
    "ws1, paragraphs1, squares1, html1, rotations1,colorbars1 = collect_ocr_process_results(ocrFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199c5b98-6719-4906-a580-6b9ff0971811",
   "metadata": {},
   "source": [
    "## Generally start here for same dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fae5d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all dones already\n",
    "\n",
    "# generate donesfile from list\n",
    "if type(check_makesense) != list:\n",
    "    lfiles = glob(check_makesense+'labels*csv')\n",
    "else:\n",
    "    lfiles = glob(check_makesense[0]+'labels*csv')\n",
    "    for c in check_makesense[1:]:\n",
    "        lfiles.extend(glob(c+'labels*csv'))\n",
    "\n",
    "l2 = glob(save_makesense+'labels*csv')\n",
    "lfiles.extend(l2)\n",
    "filenames = []; labelss = []; xmins = []; ymins=[]; xmaxs=[]; ymaxs=[]; widths=[]\n",
    "fnameSave = []; heights = []\n",
    "for il,l in enumerate(lfiles):\n",
    "    d = pd.read_csv(l, names = ['label','xmin','ymin','xmax','ymax', 'fname','x','y'])\n",
    "    #d = d.drop_duplicates(subset='fname')\n",
    "    for idd, dd in enumerate(d['fname'].values):\n",
    "        fn = dd[:dd.rfind('.')+1]\n",
    "        if fn[-1] == '.': fn = fn[:-1]\n",
    "        filenames.append(fn)\n",
    "        fnameSave.append(dd)\n",
    "    if il == 0:\n",
    "        dfTmp = d.copy()\n",
    "    else:\n",
    "        dfTmp = dfTmp.append(d)\n",
    "# get unique\n",
    "fnameSave,uind = np.unique(fnameSave,return_index=True)\n",
    "# loop and grab\n",
    "for idd, dd in enumerate(fnameSave):\n",
    "    mask = dfTmp['fname'] == dd\n",
    "    labelss.append(dfTmp.loc[mask]['label'].values); xmins.append(dfTmp.loc[mask]['xmin'].values)\n",
    "    ymins.append(dfTmp.loc[mask]['ymin'].values); \n",
    "    # widths and heights!!\n",
    "    xmaxs.append(dfTmp.loc[mask]['xmax'].values+dfTmp.loc[mask]['xmin'].values); \n",
    "    ymaxs.append(dfTmp.loc[mask]['ymax'].values+dfTmp.loc[mask]['ymin'].values)\n",
    "    widths.append(dfTmp.loc[mask]['x'].values[0]); heights.append(dfTmp.loc[mask]['y'].values[0])\n",
    "dones = pd.DataFrame({'filename':np.array(filenames)[uind], 'labels':labelss, 'xmin':xmins, \n",
    "                      'ymin':ymins, 'xmax':xmaxs,'ymax':ymaxs, 'width':widths, 'height':heights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4204bc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>labels</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1721_1_100316_p105</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[2231, 2231]</td>\n",
       "      <td>[2888, 2888]</td>\n",
       "      <td>[2359, 2359]</td>\n",
       "      <td>[3053, 3053]</td>\n",
       "      <td>2550</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1721_1_100316_p107</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[2231, 2231]</td>\n",
       "      <td>[2888, 2888]</td>\n",
       "      <td>[2359, 2359]</td>\n",
       "      <td>[3053, 3053]</td>\n",
       "      <td>2550</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1721_1_100316_p109</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[2231, 2231]</td>\n",
       "      <td>[2888, 2888]</td>\n",
       "      <td>[2359, 2359]</td>\n",
       "      <td>[3053, 3053]</td>\n",
       "      <td>2550</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1721_1_100316_p114</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[2231, 2231]</td>\n",
       "      <td>[2888, 2888]</td>\n",
       "      <td>[2359, 2359]</td>\n",
       "      <td>[3053, 3053]</td>\n",
       "      <td>2550</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1721_1_100316_p12</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[2231, 2231]</td>\n",
       "      <td>[2888, 2888]</td>\n",
       "      <td>[2359, 2359]</td>\n",
       "      <td>[3053, 3053]</td>\n",
       "      <td>2550</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>1721_1_97289_p340</td>\n",
       "      <td>[figure, figure]</td>\n",
       "      <td>[792, 792]</td>\n",
       "      <td>[293, 293]</td>\n",
       "      <td>[1848, 1848]</td>\n",
       "      <td>[3043, 3043]</td>\n",
       "      <td>2550</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>1721_1_97289_p373</td>\n",
       "      <td>[figure, figure_caption, figure, figure_caption]</td>\n",
       "      <td>[858, 1482, 858, 1482]</td>\n",
       "      <td>[448, 308, 448, 308]</td>\n",
       "      <td>[1926, 1794, 1926, 1794]</td>\n",
       "      <td>[1142, 387, 1142, 387]</td>\n",
       "      <td>2550</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>1721_1_97289_p440</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[2231, 2231]</td>\n",
       "      <td>[2888, 2888]</td>\n",
       "      <td>[2359, 2359]</td>\n",
       "      <td>[3053, 3053]</td>\n",
       "      <td>2550</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>1721_1_97289_p474</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[2231, 2231]</td>\n",
       "      <td>[2888, 2888]</td>\n",
       "      <td>[2359, 2359]</td>\n",
       "      <td>[3053, 3053]</td>\n",
       "      <td>2550</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>1721_1_97289_p58</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[2231, 2231]</td>\n",
       "      <td>[2888, 2888]</td>\n",
       "      <td>[2359, 2359]</td>\n",
       "      <td>[3053, 3053]</td>\n",
       "      <td>2550</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename                                            labels  \\\n",
       "0    1721_1_100316_p105                              [no_label, no_label]   \n",
       "1    1721_1_100316_p107                              [no_label, no_label]   \n",
       "2    1721_1_100316_p109                              [no_label, no_label]   \n",
       "3    1721_1_100316_p114                              [no_label, no_label]   \n",
       "4     1721_1_100316_p12                              [no_label, no_label]   \n",
       "..                  ...                                               ...   \n",
       "927   1721_1_97289_p340                                  [figure, figure]   \n",
       "928   1721_1_97289_p373  [figure, figure_caption, figure, figure_caption]   \n",
       "929   1721_1_97289_p440                              [no_label, no_label]   \n",
       "930   1721_1_97289_p474                              [no_label, no_label]   \n",
       "931    1721_1_97289_p58                              [no_label, no_label]   \n",
       "\n",
       "                       xmin                  ymin                      xmax  \\\n",
       "0              [2231, 2231]          [2888, 2888]              [2359, 2359]   \n",
       "1              [2231, 2231]          [2888, 2888]              [2359, 2359]   \n",
       "2              [2231, 2231]          [2888, 2888]              [2359, 2359]   \n",
       "3              [2231, 2231]          [2888, 2888]              [2359, 2359]   \n",
       "4              [2231, 2231]          [2888, 2888]              [2359, 2359]   \n",
       "..                      ...                   ...                       ...   \n",
       "927              [792, 792]            [293, 293]              [1848, 1848]   \n",
       "928  [858, 1482, 858, 1482]  [448, 308, 448, 308]  [1926, 1794, 1926, 1794]   \n",
       "929            [2231, 2231]          [2888, 2888]              [2359, 2359]   \n",
       "930            [2231, 2231]          [2888, 2888]              [2359, 2359]   \n",
       "931            [2231, 2231]          [2888, 2888]              [2359, 2359]   \n",
       "\n",
       "                       ymax  width  height  \n",
       "0              [3053, 3053]   2550    3300  \n",
       "1              [3053, 3053]   2550    3300  \n",
       "2              [3053, 3053]   2550    3300  \n",
       "3              [3053, 3053]   2550    3300  \n",
       "4              [3053, 3053]   2550    3300  \n",
       "..                      ...    ...     ...  \n",
       "927            [3043, 3043]   2550    3300  \n",
       "928  [1142, 387, 1142, 387]   2550    3300  \n",
       "929            [3053, 3053]   2550    3300  \n",
       "930            [3053, 3053]   2550    3300  \n",
       "931            [3053, 3053]   2550    3300  \n",
       "\n",
       "[932 rows x 8 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6bca7cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(932, 932)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donefiles = dones['filename'].values\n",
    "len(donefiles), len(np.unique(donefiles))\n",
    "# debug\n",
    "#donefiles = ['ofx163.1581.PMC5630905_p1.jpeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e467a48-abc0-4cae-9ddc-fb805676e18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already classified:\n",
      "figure 406.0\n",
      "figure caption 296.0\n",
      "table 132.0\n",
      "math formula 412.0\n",
      "sub fig caption 0.0\n",
      "colorbar 0.0\n",
      "NotSure 0.0\n",
      "no label 1230.0\n"
     ]
    }
   ],
   "source": [
    "# count how many done per class\n",
    "labels_done_count = np.zeros(len(labels))\n",
    "for i in range(len(dones)):\n",
    "    for l in dones.iloc[i]['labels']:\n",
    "        indd = labels.index(l.replace('_',' '))\n",
    "        labels_done_count[indd] += 1\n",
    "print('Already classified:')\n",
    "for i in range(len(labels)):\n",
    "    print(labels[i], labels_done_count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c7d9edae-0a81-4394-903d-5ec2532f1539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1721_1_100316_p105', '1721_1_100316_p107', '1721_1_100316_p109',\n",
       "       '1721_1_100316_p114', '1721_1_100316_p12'], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donefiles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "01707145-317e-4d95-ac2c-15b0b7ad3691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also, get list of error'd out scanbanks\n",
    "if check_json_dir is not None:\n",
    "    sbcheck = []\n",
    "    for i in range(len(donefiles)):\n",
    "        sbcheck.append(donefiles[i].split('_p')[0])\n",
    "    #sbcheck = np.unique(sbcheck).tolist()\n",
    "\n",
    "    # check for json file\n",
    "    #no_json = []\n",
    "    #for f in sbcheck:\n",
    "    #    f+'/'+pdfbase+'deepfigures-results.json'\n",
    "    donefiles = donefiles.tolist()\n",
    "    for f in sbcheck:\n",
    "        fc = check_json_dir + f\n",
    "        ff = glob(fc+'/*')[0]\n",
    "        if not os.path.isfile(ff + '/' + f + 'deepfigures-results.json'):\n",
    "            donefiles.append(f)\n",
    "            p\n",
    "    donefiles = np.unique(donefiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8ca28144-e36f-4e59-8b5c-6125cff7637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#donefiles[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "341015a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "ws, paragraphs, squares, html, rotations,colorbars = [],[],[],[],[],[]\n",
    "for w,p,s,h,r,c in zip(ws1,paragraphs1, squares1, html1, rotations1,colorbars1):\n",
    "    if w.split('.jpeg')[0] not in donefiles:\n",
    "        ws.append(w); paragraphs.append(p);squares.append(s)\n",
    "        html.append(h); rotations.append(r); colorbars.append(c)\n",
    "df = pd.DataFrame({'ws':ws, 'paragraphs':paragraphs, 'squares':squares, \n",
    "                   'hocr':html, 'rotation':rotations, 'colorbars':colorbars})#, 'pdfwords':pdfwords})\n",
    "df = df.drop_duplicates(subset='ws')\n",
    "df = df.set_index('ws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "033f331c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b57975a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if nRandom < len(ws):\n",
    "    # grab randomly\n",
    "    ind = np.random.choice(range(len(df)),nRandom,replace=False)\n",
    "    #ws = np.array(ws)[ind]\n",
    "else:\n",
    "    #ws = np.array(ws)\n",
    "    ind = np.arange(0,len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "26f8cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout = df.iloc[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bd567e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>squares</th>\n",
       "      <th>hocr</th>\n",
       "      <th>rotation</th>\n",
       "      <th>colorbars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1721_1_12188_p30.jpeg</th>\n",
       "      <td>[(2341, 1968, 3, 285), (2337, 926, 6, 397), (2...</td>\n",
       "      <td>[[[416, 742], [2352, 742], [2352, 2610], [416,...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721_1_97289_p239.jpeg</th>\n",
       "      <td>[(379, 294, 1918, 41), (379, 294, 1918, 41), (...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721_1_27399_p194.jpeg</th>\n",
       "      <td>[(2275, 157, 20, 33), (2304, 158, 19, 35), (14...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td>[90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721_1_15820_p2.jpeg</th>\n",
       "      <td>[(1073, 318, 399, 40), (462, 538, 72, 36), (56...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721_1_41319_p97.jpeg</th>\n",
       "      <td>[(991, 262, 18, 36), (1075, 261, 569, 48), (10...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               paragraphs  \\\n",
       "ws                                                                          \n",
       "1721_1_12188_p30.jpeg   [(2341, 1968, 3, 285), (2337, 926, 6, 397), (2...   \n",
       "1721_1_97289_p239.jpeg  [(379, 294, 1918, 41), (379, 294, 1918, 41), (...   \n",
       "1721_1_27399_p194.jpeg  [(2275, 157, 20, 33), (2304, 158, 19, 35), (14...   \n",
       "1721_1_15820_p2.jpeg    [(1073, 318, 399, 40), (462, 538, 72, 36), (56...   \n",
       "1721_1_41319_p97.jpeg   [(991, 262, 18, 36), (1075, 261, 569, 48), (10...   \n",
       "\n",
       "                                                                  squares  \\\n",
       "ws                                                                          \n",
       "1721_1_12188_p30.jpeg   [[[416, 742], [2352, 742], [2352, 2610], [416,...   \n",
       "1721_1_97289_p239.jpeg                                                 []   \n",
       "1721_1_27399_p194.jpeg                                                 []   \n",
       "1721_1_15820_p2.jpeg                                                   []   \n",
       "1721_1_41319_p97.jpeg                                                  []   \n",
       "\n",
       "                                                                     hocr  \\\n",
       "ws                                                                          \n",
       "1721_1_12188_p30.jpeg   <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "1721_1_97289_p239.jpeg  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "1721_1_27399_p194.jpeg  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "1721_1_15820_p2.jpeg    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "1721_1_41319_p97.jpeg   <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...   \n",
       "\n",
       "                                                                 rotation  \\\n",
       "ws                                                                          \n",
       "1721_1_12188_p30.jpeg   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1721_1_97289_p239.jpeg  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1721_1_27399_p194.jpeg  [90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "1721_1_15820_p2.jpeg    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1721_1_41319_p97.jpeg   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                       colorbars  \n",
       "ws                                \n",
       "1721_1_12188_p30.jpeg         []  \n",
       "1721_1_97289_p239.jpeg        []  \n",
       "1721_1_27399_p194.jpeg        []  \n",
       "1721_1_15820_p2.jpeg          []  \n",
       "1721_1_41319_p97.jpeg         []  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e8f4cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws = dfout.index\n",
    "# ws\n",
    "#dfout.index.values.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "73937ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save label file for annotations\n",
    "storeTmps = config.tmp_storage_dir + 'MakeSense/'\n",
    "if not os.path.exists(storeTmps):\n",
    "    os.mkdir(storeTmps)\n",
    "# remove, remake\n",
    "shutil.rmtree(storeTmps)\n",
    "os.mkdir(storeTmps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f4450",
   "metadata": {},
   "source": [
    "Copy over random images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c3dc21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start on empty\n",
    "if not os.path.exists(storeTmps+'images/'):\n",
    "    os.makedirs(storeTmps+'images/')\n",
    "# delete and remake\n",
    "shutil.rmtree(storeTmps+'images/')\n",
    "os.makedirs(storeTmps+'images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0018eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move files\n",
    "imgSizes = []; imgSizesOrig = []\n",
    "for iw,w in enumerate(dfout.index.values.astype('str')):\n",
    "    #print(w)\n",
    "    w = images_jpeg_dir + w\n",
    "    if not invert_colors:\n",
    "        shutil.copyfile(w, storeTmps+'images/'+ w.split('/')[-1])\n",
    "        imgSizes.append(Image.open(w).convert('RGB').size)\n",
    "    else: # invert B/W\n",
    "        print('not implemented!!')\n",
    "        import sys; sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0cf92189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write label file\n",
    "with open(storeTmps + 'labels.txt','w') as f:\n",
    "    for l in labels:\n",
    "        f.write(l.replace(' ', '_') + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e807c8b",
   "metadata": {},
   "source": [
    "For annotations, try to predict with our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "343b9e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model to run on pages\n",
    "# read in anchors\n",
    "saveFileAnchors = weightsFileDir + 'anchors.pickle'\n",
    "with open(saveFileAnchors, 'rb') as f:\n",
    "    anchors = pickle.load(f) \n",
    "    anchors = anchors.astype('float32')\n",
    "\n",
    "    \n",
    "feature_dir = config.save_binary_dir + binary_dirs\n",
    "# how many features\n",
    "with open(feature_dir +'feature_list.pickle', 'rb') as ff:\n",
    "    feature_list = pickle.load(ff)[0]\n",
    "# HACK\n",
    "#feature_list = ['grayscale','fontsize','x_ascenders','x_decenders', 'word confidences', \n",
    "#                'fraction of numbers in a word','fraction of letters in a word','punctuation', \n",
    "#                'text angles','Spacy POS']\n",
    "\n",
    "n_features = len(feature_list)\n",
    "\n",
    "# labels file for originally trained\n",
    "LABELS=pd.read_csv(feature_dir + 'LABELS.csv',names=['labels'])['labels'].values.astype('str')\n",
    "CLASS = len(LABELS)\n",
    "\n",
    "# build the model\n",
    "weightsFileDownload = weightsFileDir + weightsFile\n",
    "anchorsFile = weightsFileDir + 'anchors.pickle'  # should this be changed....\n",
    "\n",
    "model = build_predict(weightsFileDownload, anchorsFile, \n",
    "                    feature_dir,LABELS,version=config.version, \n",
    "                      debug=False,n_features=n_features)\n",
    "model.load_weights(weightsFileDownload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "17a4be46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgSizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "84953395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(post_processing_utils)\n",
    "# from post_processing_utils import get_ocr_results,get_image_process_boxes, \\\n",
    "#     clean_merge_heurstic_captions, clean_overlapping_squares, clean_found_overlap_with_ocr, \\\n",
    "#     clean_merge_squares, clean_big_captions, clean_match_fig_cap, expand_found_boxes_fig_cap, \\\n",
    "#     expand_found_area_above_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b07ed8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# # for tfrecrords, get datasets\n",
    "# test_list = glob(feature_dir + 'test_*tfrecords')\n",
    "\n",
    "# #if not use_training:\n",
    "# test_raw_data = tf.data.TFRecordDataset(filenames=test_list, \n",
    "#                                          compression_type='GZIP', \n",
    "#                                          buffer_size=None, \n",
    "#                                         num_parallel_reads=tf.data.AUTOTUNE)\n",
    "# Create a dictionary describing the features.\n",
    "image_feature_description = {\n",
    "    'nbox': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'nfeatures': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'boxes': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_name': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function_test(example_proto,anchors,CLASS):\n",
    "    image_features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    # parse the data\n",
    "    nboxes = image_features['nbox']\n",
    "    nfeatures = image_features['nfeatures']\n",
    "    images_raw = image_features['image_raw']\n",
    "    image = tf.io.decode_raw(images_raw,tf.float32)\n",
    "    image = tf.reshape(image,[config.IMAGE_H,config.IMAGE_W,nfeatures])\n",
    "    img_name = tf.cast(image_features['image_name'],tf.string)\n",
    "    return image,img_name\n",
    "\n",
    "# test_dataset = test_raw_data.map(lambda example_proto:_parse_image_function_test(example_proto,\n",
    "#                                                                              anchors,CLASS))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    " \n",
    "# Create a dictionary with features that may be relevant.\n",
    "def image_example(image, boxes, img_name):\n",
    "    #image_shape = tf.io.decode_jpeg(image_string).shape\n",
    "    image_string = image.astype('float32')/255.0\n",
    "    image_string = image.reshape(image.shape[0]*image.shape[1]*image.shape[2])\n",
    "\n",
    "    nfeatures = image.shape[2]\n",
    "    nboxes = boxes.shape[0]\n",
    "    if nboxes>0:\n",
    "        boxout = boxes.reshape(boxes.shape[0]*boxes.shape[1])\n",
    "    else:\n",
    "        boxout = np.array([])\n",
    "\n",
    "    feature = {\n",
    "      'nbox': _float_feature(np.float32(nboxes)),\n",
    "      'nfeatures': _float_feature(np.float32(nfeatures)),\n",
    "      'boxes': _bytes_feature(boxout.astype('float32').tobytes()),\n",
    "      'image_raw': _bytes_feature(image_string.astype('float32').tobytes()),\n",
    "      'image_name': _bytes_feature(img_name.encode('utf-8')),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))      \n",
    "\n",
    "compress = 'GZIP'\n",
    "tf_record_options = tf.io.TFRecordOptions(compression_type = compress) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "806362d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make file into tf record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b75eef42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 1 of 100\n",
      "1721_1_12188_p30.jpeg something has happened with rotation -- page says angle = 180 words say angle = 0.0\n",
      "something bad has happened with image_to_osd on 1721_1_58489_p182.jpeg\n",
      "1721_1_58489_p182.jpeg something has happened with rotation -- page says angle = -1 words say angle = 0.0\n",
      "1721_1_72721_p1.jpeg something has happened with rotation -- page says angle = 0 words say angle = 270.0\n",
      "on 26 of 100\n",
      "on 51 of 100\n",
      "1721_1_15434_p46.jpeg something has happened with rotation -- page says angle = 180 words say angle = 0.0\n",
      "on 76 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jillnaiman/figure_and_caption_extraction/feature_generation_utils.py:453: RuntimeWarning: invalid value encountered in true_divide\n",
      "  scales_ascenders = (ascendershere-min_asc)/(max_asc-min_asc)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721_1_75550_p64.jpeg something has happened with rotation -- page says angle = 180 words say angle = 0\n",
      "something bad has happened with image_to_osd on 1721_1_100321_p8.jpeg\n",
      "1721_1_100321_p8.jpeg something has happened with rotation -- page says angle = -1 words say angle = 0\n",
      "1721_1_77514_p55.jpeg something has happened with rotation -- page says angle = 180 words say angle = 0.0\n",
      "something bad has happened with image_to_osd on 1721_1_16394_p35.jpeg\n",
      "1721_1_16394_p35.jpeg something has happened with rotation -- page says angle = -1 words say angle = 0\n",
      "all done!  go classify!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(storeTmps+'annotations/'):\n",
    "    os.makedirs(storeTmps+'annotations/')\n",
    "# delete and remake\n",
    "shutil.rmtree(storeTmps+'annotations/')\n",
    "os.makedirs(storeTmps+'annotations/')\n",
    "\n",
    "# save tmp binaries for this\n",
    "if not os.path.exists(storeTmps+'binaries/'):\n",
    "    os.makedirs(storeTmps+'binaries/')\n",
    "# delete and remake\n",
    "shutil.rmtree(storeTmps+'binaries/')\n",
    "os.makedirs(storeTmps+'binaries/')\n",
    "\n",
    "# just for counting\n",
    "maxboxes = 50 # I think this is actually a place holder...\n",
    "\n",
    "boxesout,labelsout = [],[]\n",
    "\n",
    "#for i in range(len(dfout)):\n",
    "#i = 6 #4\n",
    "#i=0\n",
    "#if True:\n",
    "#icount = 0\n",
    "#for image,images_name in test_dataset:\n",
    "    #imgs_name = images_name.numpy().decode('utf-8')\n",
    "for i in range(len(dfout)):\n",
    "    \n",
    "    if i%25 == 0: print('on', i+1, 'of', len(dfout))\n",
    "\n",
    "    dfsingle = dfout.iloc[i]\n",
    "    # if we've made it this far, let's generate features\n",
    "    img_name, font = generate_single_feature(dfsingle, LABELS, maxboxes, \n",
    "                                           feature_list = feature_list, \n",
    "                                           binary_dir = storeTmps+'binaries/',\n",
    "                                                images_jpeg_dir = images_jpeg_dir,\n",
    "                                                astype='npz', \n",
    "                                                 npzcompressed=True) \n",
    "    \n",
    "    image_np = np.load(img_name)['arr_0']\n",
    "    fakebox = np.random.random([20,5])\n",
    "    tf_example = image_example(image_np,fakebox,img_name)\n",
    "    # write temp\n",
    "    record_file = storeTmps+'binaries/tmpfile'\n",
    "    with tf.io.TFRecordWriter(record_file, options=tf_record_options) as writer:\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "        \n",
    "    test_raw_data = tf.data.TFRecordDataset(filenames=record_file, \n",
    "                                             compression_type='GZIP', \n",
    "                                             buffer_size=None, \n",
    "                                            num_parallel_reads=tf.data.AUTOTUNE)\n",
    "    test_dataset = test_raw_data.map(lambda example_proto:_parse_image_function_test(example_proto,\n",
    "                                                                                 anchors,CLASS))\n",
    "\n",
    "    for image,images_name in test_dataset:\n",
    "        imgs_name = images_name.numpy().decode('utf-8')\n",
    "    \n",
    "        # predict squares in 2 ways\n",
    "        # 1. MEGA YOLO\n",
    "        #image_np = np.load(img_name)['arr_0']\n",
    "        #image_np = image_np.astype(np.float32) / 255.0 \n",
    "        # backtorgb,image_np,rotatedImage,rotatedAngleOCR,bbox_hocr,\\\n",
    "        #   bboxes_words,bbsq,cbsq, rotation,bbox_par = get_ocr_results(img_name, None,dfout.iloc[[i]],\n",
    "        #                                                              image_np=image_np,\n",
    "        #                                                              width=imgSizes[i][0], \n",
    "        #                                                              height=imgSizes[i][1],\n",
    "        #                                                              images_jpeg_dir=images_jpeg_dir)\n",
    "        backtorgb,image_np,rotatedImage,rotatedAngleOCR,bbox_hocr,\\\n",
    "          bboxes_words,bbsq,cbsq, rotation,bbox_par = get_ocr_results(img_name, None,dfout.iloc[[i]],\n",
    "                                                                     image_np=image.numpy(),\n",
    "                                                                     width=imgSizes[i][0], \n",
    "                                                                     height=imgSizes[i][1],\n",
    "                                                                     images_jpeg_dir=images_jpeg_dir)\n",
    "\n",
    "        boxesh, scoresh, labelsh = model.predict(image_np[np.newaxis, ...])\n",
    "        #import sys; sys.exit()\n",
    "        boxes1, scores1, labels1 = np.squeeze(boxesh, 0), \\\n",
    "          np.squeeze(scoresh, 0), np.squeeze(labelsh, 0)\n",
    "        # only non -1 ones\n",
    "        boxes1 = boxes1[labels1>-1]\n",
    "        scores1 = scores1[labels1>-1]\n",
    "        labels1 = labels1[labels1>-1]    \n",
    "\n",
    "        # # post process the thing\n",
    "        # # get OCR results and parse them, open image for image processing\n",
    "        # image = \n",
    "\n",
    "\n",
    "        # get figures and captions from image processing\n",
    "        captionText_figcap, bbox_figcap_pars = get_image_process_boxes(backtorgb, \n",
    "                                                                       bbox_hocr, \n",
    "                                                                       rotatedImage)\n",
    "        # clean overlapping squares\n",
    "        # if squares are majorly overlapping, take the one with the highest score\n",
    "        sboxes_cleaned, slabels_cleaned, sscores_cleaned = clean_overlapping_squares(boxes1,\n",
    "                                                                                     scores1,\n",
    "                                                                                     labels1,\n",
    "                                                                                     img_name)\n",
    "        # combine figure caption boxes with heuristically found ones\n",
    "        # -- often the heurstically found boxes are more accurate, especially \n",
    "        # in the vertical direction\n",
    "        boxes_heur, labels_heur, scores_heur,\\\n",
    "          ibbOverlap, boxes_heur_tf = clean_merge_heurstic_captions(sboxes_cleaned, \n",
    "                                                     slabels_cleaned, \n",
    "                                                     sscores_cleaned, \n",
    "                                                bbox_figcap_pars, LABELS,None,\n",
    "                                                    width=imgSizes[i][0], \n",
    "                                                    height=imgSizes[i][1])\n",
    "        # NO PDF\n",
    "\n",
    "        # other way -- w/o adding more heursitic caps:\n",
    "        boxes_par_found, labels_par_found, \\\n",
    "          scores_par_found = clean_found_overlap_with_ocr(boxes_heur, labels_heur, \n",
    "                                                    scores_heur,bboxes_words,\n",
    "                                                          bbox_par,rotation,\n",
    "                                                          LABELS, None, boxes_heur_tf,\n",
    "                                                          width=imgSizes[i][0], \n",
    "                                                    height=imgSizes[i][1])\n",
    "\n",
    "        # if figure boxes are smaller than image-processing found boxes, merge them; \n",
    "        # also, do with colorbars as well if requested\n",
    "        boxes_sq1, labels_sq1, scores_sq1, bbsq = clean_merge_squares(bbsq, cbsq,\n",
    "                                                                boxes_par_found, \n",
    "                                                                labels_par_found, \n",
    "                                                                scores_par_found, \n",
    "                                                                LABELS, None, \n",
    "                                                                      width=imgSizes[i][0], \n",
    "                                                                      height=imgSizes[i][1])\n",
    "\n",
    "        # if there are any huge captions -- like 75% of the area of the page or more\n",
    "        #. these are wrong, so drop them\n",
    "        boxes_sq2, labels_sq2, scores_sq2 = clean_big_captions(boxes_sq1,\n",
    "                                                            labels_sq1,\n",
    "                                                            scores_sq1, \n",
    "                                                            LABELS)\n",
    "            \n",
    "        # sometimes captions are slightly overlapping with figures -- split the \n",
    "        # difference between those where they touch on the \"bottom\"\n",
    "        # Default to captions found with mega yolo, if there is a figure but \n",
    "        #. no caption found, then see if there is a heuristically found caption\n",
    "        boxes_sq3, labels_sq3, scores_sq3 = clean_match_fig_cap(boxes_sq2,\n",
    "                                                                 labels_sq2,\n",
    "                                                             scores_sq2, bbsq,\n",
    "                                                             LABELS.tolist(), \n",
    "                                                             rotatedImage, \n",
    "                                                             rotatedAngleOCR,\n",
    "                                                             None, \n",
    "                                                            width=imgSizes[i][0], \n",
    "                                                            height=imgSizes[i][1])\n",
    "        \n",
    "        # again for found boxes?  I feel like maybe not the one above?\n",
    "        boxes_sq4, labels_sq4, scores_sq4 = expand_found_boxes_fig_cap(boxes_sq3, \n",
    "                                                                    labels_sq3, \n",
    "                                                                    scores_sq3,\n",
    "                                                                       bbsq,\n",
    "                                                                    rotatedImage, \n",
    "                                                                    LABELS.tolist(), None, \n",
    "                                                            width=imgSizes[i][0], \n",
    "                                                            height=imgSizes[i][1])\n",
    "        \n",
    "        # same for found\n",
    "        boxes_sq5, labels_sq5, scores_sq5 = expand_found_area_above_cap(boxes_sq4, \n",
    "                                                                        labels_sq4, \n",
    "                                                                        scores_sq4, \n",
    "                                                                        bbsq,\n",
    "                                                                        rotatedImage, \n",
    "                                                                        LABELS.tolist(), None, \n",
    "                                                            width=imgSizes[i][0], \n",
    "                                                            height=imgSizes[i][1])\n",
    "        \n",
    "        # save it!\n",
    "        #boxesout.append(boxes_sq5); labelsout.append(labels_sq5)\n",
    "        \n",
    "    fn = imgs_name\n",
    "        \n",
    "    # write this out!\n",
    "    if os.path.exists(fn): \n",
    "        with open(storeTmps+'annotations/'+ fn.split('/')[-1].split('.npz')[0] + '.txt','w') as fsave:\n",
    "            for fb,ll in zip(boxes_sq5,labels_sq5):\n",
    "                xmin = fb[0]/config.IMAGE_W#*img.shape[1]\n",
    "                xmax = fb[2]/config.IMAGE_W#*img.shape[1]\n",
    "                ymin = fb[1]/config.IMAGE_H#*img.shape[0]\n",
    "                ymax = fb[3]/config.IMAGE_H#*img.shape[0]\n",
    "\n",
    "                #xmin = bb[0]*xfrac; ymin = bb[1]*yfrac; xmax = bb[2]*xfrac; ymax = bb[3]*yfrac\n",
    "                #x = xmin/imSize[1]; y = ymin/imSize[0]; \n",
    "                #w = (xmax-xmin)/imSize[1]; h = (ymax-ymin)/imSize[0]\n",
    "                x = xmin; y = ymin\n",
    "                w = xmax-xmin; h = ymax-ymin\n",
    "                # I think we want centers?\n",
    "                x = x+w*0.5; y = y+0.5*h\n",
    "                if ll > -1:\n",
    "                    lab = LABELS[int(ll)]\n",
    "                    if lab == 'multi-figure': lab = 'figure' # rename all to figure for now\n",
    "                    try: \n",
    "                        l = labels.index(lab)\n",
    "                    except:\n",
    "                        l = -1\n",
    "                    if l > -1: # found in these labels\n",
    "                        if w<0: w=0.5\n",
    "                        if h<0: h=0.5\n",
    "                        fsave.write(str(l) + ' ' + str(max([x,0])) + ' ' + str(max([y,0])) + ' ' + str(min([w,1])) + ' ' + str(min([h,1])) + '\\n')\n",
    "                        \n",
    "            # if no boxes -- no label labels\n",
    "            if len(boxes_sq5) == 0:\n",
    "                x = 0.90; y = 0.90; w = 0.05; h=0.05\n",
    "                fsave.write(str(labels.index('no label')) + ' ' + str(max([x,0])) + ' ' + str(max([y,0])) + ' ' + str(min([w,1])) + ' ' + str(min([h,1])) + '\\n')\n",
    "\n",
    "    else:\n",
    "        print('something has gone wrong')\n",
    "        import sys; sys.exit()\n",
    "\n",
    "\n",
    "#write label file with ALL labels\n",
    "with open(storeTmps + 'annotations/'  + 'labels.txt','w') as f:\n",
    "    for l in labels:\n",
    "        f.write(l.replace(' ', '_') + '\\n')\n",
    "\n",
    "print('all done!  go classify!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d61cacbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# import feature_generation_utils\n",
    "# reload(feature_generation_utils)\n",
    "# from feature_generation_utils import generate_single_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c987e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_name, font = generate_single_feature(dfsingle, LABELS, maxboxes, \n",
    "#                                        feature_list = feature_list, \n",
    "#                                        binary_dir = storeTmps+'binaries/',\n",
    "#                                             images_jpeg_dir = images_jpeg_dir,\n",
    "#                                             astype='npz', \n",
    "#                                              npzcompressed=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63997a5b",
   "metadata": {},
   "source": [
    "Take one just to check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afcd9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "510b4eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxes_sq5, labels_sq5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2714b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "246d8718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_np[:,:,0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5227692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(Image.open(images_jpeg_dir + img_name.split('/')[-1].split('.npz')[0]+'.jpeg').convert('RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6f3a46e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t5/9xgccmv92hnfvjwd62mk8zqh0000gn/T/ipykernel_45309/3982654581.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mll\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# caption\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmin1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mymin1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmax1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mymax1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'col' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(20,10))\n",
    "\n",
    "#wid,hei = imgsSize[i]\n",
    "\n",
    "# draw founds\n",
    "for ll,fb in zip(labels_sq5,boxes_sq5):\n",
    "    xmin1 = fb[0]/config.IMAGE_W*img.shape[1]\n",
    "    xmax1 = fb[2]/config.IMAGE_W*img.shape[1]\n",
    "    ymin1 = fb[1]/config.IMAGE_H*img.shape[0]\n",
    "    ymax1 = fb[3]/config.IMAGE_H*img.shape[0]\n",
    "    if ll == 0: # figure\n",
    "        col = (255, 0, 0)\n",
    "    elif ll == 1: # caption\n",
    "        col = (255,0,255)\n",
    "    cv.rectangle(img, (round(xmin1), round(ymin1)), (round(xmax1),round(ymax1)), col, 5)  \n",
    "\n",
    "ax.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93bed0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,4,figsize=(20,10))\n",
    "ax = ax.flatten()\n",
    "ax[0].imshow(image_np[:,:,0],cmap='gray')\n",
    "ax[1].imshow(image_np[:,:,1],cmap='gray')\n",
    "ax[2].imshow(image_np[:,:,2],cmap='gray')\n",
    "ax[3].imshow(image_np[:,:,3],cmap='gray')\n",
    "\n",
    "ax[4].imshow(image_np[:,:,4],cmap='gray')\n",
    "ax[5].imshow(image_np[:,:,5],cmap='gray')\n",
    "ax[6].imshow(image_np[:,:,6],cmap='gray')\n",
    "ax[7].imshow(image_np[:,:,7],cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3138c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac2d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfsingle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d876e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee38797b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49f9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf13dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69410b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c0157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75b26cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abae15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19f8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5280bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703c924f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cb4d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51201f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a805af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f27253b1",
   "metadata": {},
   "source": [
    "# ------------ IGNORE BELOW -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6678b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add another\n",
    "#ocrFiles.append('/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/OCR_processing/full_ocr_newPDFs_take2.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eca0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocrFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01421a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsout = []\n",
    "for cp in ocrFiles:\n",
    "    with open(cp, 'rb') as f:\n",
    "        wsout1, full_run_squares, full_run_ocr, full_run_rotations, \\\n",
    "             full_run_pdf, full_run_hocr, color_bars,\\\n",
    "              centers_in, centers_out = pickle.load(f) \n",
    "    wsout.extend(wsout1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bdb62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f3da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e5656e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a01be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798dc13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0fd87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f7d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we want to use a model to generate possible annotations for us?\n",
    "use_model_ann = True # redo, redo_makesense = False must be toggled!\n",
    "# finally, do we want to use a combo of OTHER pages AND scans from the downloaded PDFs?\n",
    "\n",
    "# reannotate some bad annoations? -- assume you wanna do this all in one go...\n",
    "bad_ann_file = None # if none, this is skipped\n",
    "#bad_ann_file = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/Annotations/MakeSenseAnnotations_old/more_bad_ann_redux.csv'\n",
    "\n",
    "# look for any particular tag?\n",
    "look_for = None #'table' # set to None for nothing\n",
    "\n",
    "donesDir = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/Annotations/MakeSenseAnnotations/' # this is redudent I think...\n",
    "\n",
    "# want to re-do a whole batch of annotations from a makesense annotations directory?\n",
    "redo_makesense = False\n",
    "redo_makesense_folder = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/Annotations/MakeSenseAnnotations_orig/'\n",
    "# what about dones from this?\n",
    "# new place\n",
    "redo_makesense_folder_new = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/Annotations/MakeSenseAnnotations/'\n",
    "\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "# where are scans stored?\n",
    "images_pulled_dir_orig = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/Pages/RandomSingleFromPDFIndexed/' ## what about Dropbox though????\n",
    "images_pulled_dir = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/Pages/RandomSingleFromPDFIndexed/' # unskewed, first run\n",
    "\n",
    "# if we want to copy annotations\n",
    "annotation_dir = '/Users/jillnaiman/tmpMegaYolo/binaries/yolo_512x512_cap_math_ann/'\n",
    "# what are the YOLO labels?\n",
    "labels_annotation = ['figure', 'figure caption', 'table', 'table caption', 'math formula', 'colorbar', 'sub fig caption', 'multi-figure']\n",
    "# what format are the annotations stored in?\n",
    "IMAGE_H, IMAGE_W = 512, 512\n",
    "\n",
    "# NOTE: with labels -- only add to END of list for new ones!!!\n",
    "# where to store the temp files? -- note, this erases what was there!\n",
    "storeTmps = '/Users/jillnaiman/Downloads/tmpMakeSense/'\n",
    "# where to store labels?\n",
    "labelFile = 'labels.txt' # in the storeTmps file\n",
    "\n",
    "# what labels for annotations?\n",
    "labels = ['figure', 'figure caption', 'table', 'math formula', 'sub fig caption', 'colorbar', 'NotSure', 'no label'] # no label is for nothing on the page\n",
    "# used in the already trained model model?\n",
    "LABELS = ['figure', 'figure caption', 'table']\n",
    "\n",
    "\n",
    "# how many to do at a time?\n",
    "nRandom = 100\n",
    "\n",
    "# invert colors for easier labeling?  Generally false -- hard to see some box boundaries\n",
    "invert_colors = False\n",
    "\n",
    "# copy over annotations?\n",
    "copy_annotations = True\n",
    "\n",
    "# other important directories\n",
    "weightsFile = '20210914/training_1_model_orig_training_setsl0.0059608044.h5' # model weights: figure/table, fig/table captions\n",
    "anchorsFile = '20210914/anchors.pickle'\n",
    "binariesDir = '/Users/jillnaiman/tmpMegaYolo/binaries/binaries/'\n",
    "origAnnDir = '/Users/jillnaiman/tmpMegaYolo/binaries/yolo_512x512_cap_ann/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dirs\n",
    "weightsFile = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/mega_yolo/saved_weights/'+weightsFile\n",
    "anchorsFile = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/mega_yolo/saved_weights/'+anchorsFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b41fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR results\n",
    "figCapMain = '/Users/jillnaiman/Dropbox/wwt_image_extraction/FigureLocalization/OCR_processing/'\n",
    "ocrFilesList = [figCapMain+'full_ocr_results_and_squares_REINDEXED_noOCRskew.pickle',\n",
    "            figCapMain+'full_ocr_newPDFs_take*.pickle'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897f5355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from PIL import Image, ImageOps\n",
    "import pickle\n",
    "#import tensorflow as tf\n",
    "import cv2 as cv\n",
    "\n",
    "from sys import path\n",
    "path.append('../../')\n",
    "from utils import stored_classifications, take_out_dones\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "\n",
    "# more mega-yolo specific libraries\n",
    "path.append('./')\n",
    "from mega_yolo_utils import parse_annotation, build_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ed770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write label file\n",
    "with open(storeTmps + labelFile,'w') as f:\n",
    "    for l in labels:\n",
    "        f.write(l.replace(' ', '_') + '\\n')\n",
    "        \n",
    "if bad_ann_file is not None: redo_makesense = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed9c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update all OCRfiles\n",
    "ocrFiles = []\n",
    "for f in ocrFilesList:\n",
    "    if '*' not in f:\n",
    "        ocrFiles.append(f)\n",
    "    else:\n",
    "        fs = glob(f)\n",
    "        for ff in fs:\n",
    "            ocrFiles.append(ff)\n",
    "#ocrFiles = ocrFiles2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555342f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ocrFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291cc33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model if we wanna use it!\n",
    "if use_model_ann and bad_ann_file is None and not redo_makesense:\n",
    "    model = build_predict(weightsFile, anchorsFile, \n",
    "                          binariesDir,LABELS,version='l', debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24967833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, \"yolo_v5.png\", show_shapes=True, \n",
    "#                                  show_layer_names=True, expand_nested=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(pdfLinks.split('classified_')) > 0:\n",
    "#     ffiles = glob(pdfLinks + '*')\n",
    "#     ffiles.sort()\n",
    "#     pdfLinks = ffiles[-1]\n",
    "# # get PDF links from file\n",
    "# with open(pdfLinks, 'rb') as f:\n",
    "#     wsLinks1, dlinks,pages = pickle.load(f)  \n",
    "# # format for later\n",
    "# wsLinks = []\n",
    "# for w in wsLinks1:\n",
    "#     wsLinks.append(w[:w.rfind('.')].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(ws), len(paragraphs), len(squares), len(html)\n",
    "#ws[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f880d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop and grab hocr\n",
    "ws = []; paragraphs = []; squares = []; html = []; #pdfwords = []\n",
    "for cp in ocrFiles:\n",
    "    # do a little test save here - locations of squares and figure caption boxes\n",
    "#     try: # mixed numbers of things\n",
    "#         with open(cp, 'rb') as f:\n",
    "#             wsout, full_run_squares, full_run_ocr, full_run_rotations, \\\n",
    "#                          full_run_lineNums, full_run_confidences, full_run_paragraphs, \\\n",
    "#                          full_run_links, full_run_gifLinkStorage, full_run_PDFlinkStorage, \\\n",
    "#                          full_run_pageNumStorage, full_run_downloadLinkStorage,\\\n",
    "#                          full_run_htmlText = pickle.load(f)\n",
    "#    except:\n",
    "    with open(cp, 'rb') as f:\n",
    "        #if os.path.getsize(target) > 0\n",
    "        wsout, full_run_squares, full_run_ocr, full_run_rotations, \\\n",
    "                     full_run_lineNums, full_run_confidences, full_run_paragraphs, \\\n",
    "                     full_run_links, full_run_gifLinkStorage, full_run_PDFlinkStorage, \\\n",
    "                     full_run_pageNumStorage, full_run_downloadLinkStorage,\\\n",
    "                     full_run_htmlText,_,_,_,_ = pickle.load(f)\n",
    "\n",
    "        # splits\n",
    "        for i,w in enumerate(wsout):\n",
    "            wsout[i] = w.split('/')[-1]\n",
    "\n",
    "        ws.extend(wsout); paragraphs.extend(full_run_paragraphs); squares.extend(full_run_squares);\n",
    "        html.extend(full_run_htmlText); #pdfwords.extend(full_run_pdfwords)\n",
    "    #if 'ff74bba9-22fc-4b10-81b1-4f0d706934a6_p15.jpeg' in wsout: print(cp)\n",
    "\n",
    "df = pd.DataFrame({'ws':ws, 'paragraphs':paragraphs, 'squares':squares, \n",
    "                   'hocr':html})#, 'pdfwords':pdfwords})\n",
    "df = df.drop_duplicates(subset='ws')\n",
    "df = df.set_index('ws')\n",
    "dfsave = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a18040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c2de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab dones\n",
    "if redo_makesense:\n",
    "    #donesFileMS = 'dones_makesense.csv' # temp storage file\n",
    "    if os.path.exists(redo_makesense_folder):\n",
    "        # generate donesfile from list\n",
    "        lfiles = glob(redo_makesense_folder+'labels*csv')\n",
    "        filenames = []; labelss = []; xmins = []; ymins=[]; xmaxs=[]; ymaxs=[]; widths=[]\n",
    "        fnameSave = []; heights = []\n",
    "        for il,l in enumerate(lfiles):\n",
    "            d = pd.read_csv(l, names = ['label','xmin','ymin','xmax','ymax', 'fname','x','y'])\n",
    "            #d = d.drop_duplicates(subset='fname')\n",
    "            for idd, dd in enumerate(d['fname'].values):\n",
    "                fn = dd[:dd.rfind('.')+1]\n",
    "                if fn[-1] == '.': fn = fn[:-1]\n",
    "                filenames.append(fn)\n",
    "                fnameSave.append(dd)\n",
    "            if il == 0:\n",
    "                dfTmp = d.copy()\n",
    "            else:\n",
    "                dfTmp = dfTmp.append(d)\n",
    "        # get unique\n",
    "        fnameSave,uind = np.unique(fnameSave,return_index=True)\n",
    "        # loop and grab\n",
    "        for idd, dd in enumerate(fnameSave):\n",
    "            mask = dfTmp['fname'] == dd\n",
    "            labelss.append(dfTmp.loc[mask]['label'].values); xmins.append(dfTmp.loc[mask]['xmin'].values)\n",
    "            ymins.append(dfTmp.loc[mask]['ymin'].values); \n",
    "            # widths and heights!!\n",
    "            xmaxs.append(dfTmp.loc[mask]['xmax'].values+dfTmp.loc[mask]['xmin'].values); \n",
    "            ymaxs.append(dfTmp.loc[mask]['ymax'].values+dfTmp.loc[mask]['ymin'].values)\n",
    "            widths.append(dfTmp.loc[mask]['x'].values[0]); heights.append(dfTmp.loc[mask]['y'].values[0])\n",
    "        dones = pd.DataFrame({'filename':np.array(filenames)[uind], 'labels':labelss, 'xmin':xmins, \n",
    "                              'ymin':ymins, 'xmax':xmaxs,'ymax':ymaxs, 'width':widths, 'height':heights})\n",
    "elif bad_ann_file is not None:\n",
    "    f = pd.read_csv(bad_ann_file, delimiter = '(')\n",
    "    ws = []\n",
    "    for ff in f.index.values:\n",
    "        ws.append(ff.split('.png')[0])\n",
    "    dones = pd.DataFrame({'filename':ws})\n",
    "    \n",
    "    if os.path.exists(redo_makesense_folder_new):\n",
    "        # generate donesfile from list\n",
    "        lfiles = glob(redo_makesense_folder_new+'labels*csv')\n",
    "        filenames = []; labelss = []; xmins = []; ymins=[]; xmaxs=[]; ymaxs=[]; widths=[]\n",
    "        fnameSave = []; heights = []\n",
    "        for il,l in enumerate(lfiles):\n",
    "            d = pd.read_csv(l, names = ['label','xmin','ymin','xmax','ymax', 'fname','x','y'])\n",
    "            #d = d.drop_duplicates(subset='fname')\n",
    "            for idd, dd in enumerate(d['fname'].values):\n",
    "                fn = dd[:dd.rfind('.')+1]\n",
    "                if fn[-1] == '.': fn = fn[:-1]\n",
    "                filenames.append(fn)\n",
    "                fnameSave.append(dd)\n",
    "            if il == 0:\n",
    "                dfTmp = d.copy()\n",
    "            else:\n",
    "                dfTmp = dfTmp.append(d)\n",
    "        # get unique\n",
    "        fnameSave,uind = np.unique(fnameSave,return_index=True)\n",
    "        # loop and grab\n",
    "        for idd, dd in enumerate(fnameSave):\n",
    "            mask = dfTmp['fname'] == dd\n",
    "            labelss.append(dfTmp.loc[mask]['label'].values); xmins.append(dfTmp.loc[mask]['xmin'].values)\n",
    "            ymins.append(dfTmp.loc[mask]['ymin'].values); \n",
    "            # widths and heights!!\n",
    "            xmaxs.append(dfTmp.loc[mask]['xmax'].values+dfTmp.loc[mask]['xmin'].values); \n",
    "            ymaxs.append(dfTmp.loc[mask]['ymax'].values+dfTmp.loc[mask]['ymin'].values)\n",
    "            widths.append(dfTmp.loc[mask]['x'].values[0]); heights.append(dfTmp.loc[mask]['y'].values[0])\n",
    "        donesMS = pd.DataFrame({'filename':np.array(filenames)[uind], 'labels':labelss, 'xmin':xmins, \n",
    "                              'ymin':ymins, 'xmax':xmaxs,'ymax':ymaxs, 'width':widths, 'height':heights})\n",
    "\n",
    "else: # let's grab a bunch!  Only from the OCR-processed files    \n",
    "    ws = []\n",
    "    # loop and grab\n",
    "    for cp in ocrFiles:\n",
    "        # do a little test save here - locations of squares and figure caption boxes\n",
    "        with open(cp, 'rb') as f:\n",
    "            wsout, full_run_squares, full_run_ocr, full_run_rotations, \\\n",
    "                         full_run_lineNums, full_run_confidences, full_run_paragraphs, \\\n",
    "                        full_run_pdfwords, full_run_pdftextBoxes, \\\n",
    "                         full_run_links, full_run_gifLinkStorage, full_run_PDFlinkStorage, \\\n",
    "                         full_run_pageNumStorage, full_run_downloadLinkStorage, full_run_PDFlayouts,\\\n",
    "                        full_run_htmlTextUS, full_run_htmlText = pickle.load(f)\n",
    "\n",
    "            # splits\n",
    "            for i,w in enumerate(wsout):\n",
    "                wsout[i] = w.split('/')[-1].split('.jpeg')[0]\n",
    "\n",
    "            ws.extend(wsout)\n",
    "\n",
    "    dones = pd.DataFrame({'filename':ws})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0298c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(fnameSave)\n",
    "#dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39daf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out duplicates\n",
    "dones = dones.drop_duplicates('filename')\n",
    "dones = dones.reset_index(drop=True)\n",
    "dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ba019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dones.iloc[0]\n",
    "#donesMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8420b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsOrig = []\n",
    "for f in dones['filename'].values:\n",
    "    # check for file\n",
    "    if os.path.isfile(images_pulled_dir+f+'.jpeg'):\n",
    "        ff = images_pulled_dir+f+'.jpeg'\n",
    "    elif os.path.isfile(images_pulled_dir+f+'.jpg'):\n",
    "        ff = images_pulled_dir+f+'.jpg'\n",
    "    else:\n",
    "        # find correct hocr index\n",
    "        ff = glob(images_pulled_dir+f + '*')\n",
    "        #if len(ff) == 0: # could be that these aren't re-processed yet\n",
    "        #    #print('have issue!')\n",
    "        #    #import sys; sys.exit()\n",
    "        #else:\n",
    "        if len(ff) > 0:\n",
    "            ff = ff[0]\n",
    "    if len(ff) > 0: # take this out for once everything is re-processed\n",
    "        wsOrig.append(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0cd03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wsOrig\n",
    "#labels_annotation\n",
    "#redo_makesense_folder_new\n",
    "# x = np.array(['sad','sad','bad'])\n",
    "# np.unique(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d389779",
   "metadata": {},
   "source": [
    "## Start here for re-running generally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3908f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redo_makesense\n",
    "#donesDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cae30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out dones\n",
    "if not redo_makesense:\n",
    "    donesFileMS = 'dones_makesense.csv' # temp storage file\n",
    "    if os.path.exists(donesDir):\n",
    "        # generate donesfile from list\n",
    "        lfiles = glob(donesDir+'labels*csv')\n",
    "        filenames = []; labelsTotal = []\n",
    "        for l in lfiles:\n",
    "            d = pd.read_csv(l, names = ['label','xmin','ymin','xmax','ymax', 'fname','x','y'])\n",
    "            #d = d.drop_duplicates(subset='fname')\n",
    "            for dd,ll in zip(d['fname'].values,d['label'].values):\n",
    "                fn = dd[:dd.rfind('.')+1]\n",
    "                if fn[-1] == '.': fn = fn[:-1]\n",
    "                filenames.append(fn)\n",
    "                labelsTotal.append(ll)\n",
    "            d = pd.DataFrame({'filename':filenames})\n",
    "            d = d.drop_duplicates(subset='filename')\n",
    "            # write donesfile\n",
    "            #d.to_csv(storeTmps+donesFileMS,index=False)\n",
    "        filenames = np.unique(filenames)\n",
    "        wsFull2, _, mask = take_out_dones(wsOrig, filenames, anotherFile = dones['filename'].values) # do we need another file here??\n",
    "        ws = wsFull2\n",
    "        # done\n",
    "        lendone = len(wsOrig)-len(ws)\n",
    "        print('left to classify:', len(ws), ', already classified = ', lendone)\n",
    "        # print classes\n",
    "        for ll in labels:\n",
    "            numl = np.count_nonzero(np.array(labelsTotal) == ll.replace(' ','_'))\n",
    "            print('   Total current labels for', ll, '=', numl)\n",
    "    else:\n",
    "        ws = wsOrig\n",
    "else:\n",
    "    #print('hi')\n",
    "    ws = wsOrig\n",
    "    donesFileMS = 'dones_makesense.csv' # temp storage file\n",
    "    if os.path.exists(redo_makesense_folder_new):\n",
    "        # generate donesfile from list\n",
    "        lfiles = glob(redo_makesense_folder_new+'labels*csv')\n",
    "        filenames = []; labelsTotal = []\n",
    "        for l in lfiles:\n",
    "            d = pd.read_csv(l, names = ['label','xmin','ymin','xmax','ymax', 'fname','x','y'])\n",
    "            #d = d.drop_duplicates(subset='fname')\n",
    "            for dd in d['fname'].values:\n",
    "                fn = dd[:dd.rfind('.')+1]\n",
    "                if fn[-1] == '.': fn = fn[:-1]\n",
    "                filenames.append(fn)\n",
    "                labelsTotal.append(d['label'])\n",
    "            d = pd.DataFrame({'filename':filenames})\n",
    "            d = d.drop_duplicates(subset='filename')\n",
    "            # write donesfile\n",
    "            #filenames = d['fn'].values\n",
    "            d.to_csv(storeTmps+donesFileMS,index=False)\n",
    "        #wsFull2, _, mask = take_out_dones(wsOrig, storeTmps+donesFileMS, anotherFile = wsOrig) # do we need another file here??\n",
    "        wsFull2, _, mask = take_out_dones(wsOrig, filenames, anotherFile = wsOrig) # do we need another file here??\n",
    "        # delete the storeTmps+donesFileMS for starting over!\n",
    "        ws = wsFull2\n",
    "        # done\n",
    "        lendone = len(wsOrig)-len(ws)\n",
    "        print('pages left to classify:', len(ws), ', already classified = ', lendone)\n",
    "    else:\n",
    "        ws = wsOrig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0dc365",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### HERE IS WHERE WE COULD LOOK FOR TABLES SPECIFICALLY ###\n",
    "#len(wsOrig), len(ws), len(wsFull2)\n",
    "icountStart = 0 # change if you want to look further down\n",
    "boxesSave = []; scoresSave = []; labelsSave = []\n",
    "if look_for is not None:\n",
    "    ws = []\n",
    "    icount = icountStart\n",
    "    while len(ws) < nRandom and icount<len(wsFull2):\n",
    "        if icount%100 == 0: print('on icount',icount,'of', len(wsFull2), 'len(ws)=',len(ws))\n",
    "        w = binariesDir + '../'+  wsFull2[icount].split('/')[-1].split('.jpeg')[0]+'.npz'\n",
    "        image_np = np.load(w)['arr_0']\n",
    "        image_np = image_np.astype(np.float32) / 255.0\n",
    "        boxes, scores, labelsout = model.predict(image_np[np.newaxis, ...])\n",
    "        boxes, scores, labelsout = np.squeeze(boxes, 0), np.squeeze(scores, 0), np.squeeze(labelsout, 0)\n",
    "        # any tag of a table\n",
    "        ii = labels.index(look_for)\n",
    "        if ii in labelsout: ws.append(wsFull2[icount]) # found it!\n",
    "            \n",
    "        icount += 1\n",
    "    \n",
    "# while len(tables)<X ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7081526",
   "metadata": {},
   "outputs": [],
   "source": [
    "if look_for is None:\n",
    "    if nRandom < len(ws):\n",
    "        # grab randomly\n",
    "        ind = np.random.choice(range(len(ws)),nRandom,replace=False)\n",
    "        ws = np.array(ws)[ind]\n",
    "    else:\n",
    "        ws = np.array(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eb5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a6f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put in the random directory\n",
    "\n",
    "# start on empty\n",
    "if not os.path.exists(storeTmps+'images/'):\n",
    "    os.makedirs(storeTmps+'images/')\n",
    "# delete and remake\n",
    "shutil.rmtree(storeTmps+'images/')\n",
    "os.makedirs(storeTmps+'images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a9569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move files\n",
    "imgSizes = []; imgSizesOrig = []\n",
    "for iw,w in enumerate(ws):\n",
    "    #print(w)\n",
    "    if not invert_colors:\n",
    "        shutil.copyfile(w, storeTmps+'images/'+ w.split('/')[-1])\n",
    "        imgSizes.append(Image.open(w).convert('RGB').size)\n",
    "    else: # invert B/W\n",
    "        im = Image.open(w).convert('RGB')\n",
    "        imgSizes.append(im.size)\n",
    "        \n",
    "        if redo_makesense:\n",
    "            # get orig sizes\n",
    "            #ff = w.split('/')[-1].split('_p')[0]\n",
    "            ff = w.split('/')[-1]\n",
    "            # check for file\n",
    "            if os.path.isfile(images_pulled_dir_orig+ff):\n",
    "                indh = ff\n",
    "            elif os.path.isfile(images_pulled_dir_orig+ff):\n",
    "                indh = ff\n",
    "            else:\n",
    "                # find correct hocr index\n",
    "                ff = glob(images_pulled_dir_orig+ff.split('.')[0] + '*')\n",
    "                if len(ff) == 0 or len(ff)>1:\n",
    "                    print('have issue!')\n",
    "                    import sys; sys.exit()\n",
    "                else:\n",
    "                    indh = ff[0].split('/')[-1]     \n",
    "            with Image.open(images_pulled_dir_orig+indh).convert('L') as f:\n",
    "                imgSizesOrig.append(f.size)\n",
    "        else:\n",
    "            imgSizesOrig.append(im.size)\n",
    "        \n",
    "        im_invert = ImageOps.invert(im)\n",
    "        imgdata = np.array(im_invert)\n",
    "        # overplot paragraphs\n",
    "        plotPar = True\n",
    "        try:\n",
    "            dp = dfsave.loc[w.split('/')[-1]]\n",
    "        except:\n",
    "            plotPar = False\n",
    "            #import sys; sys.exit()\n",
    "            print('no info for:', w)\n",
    "        #dp = dfsave.loc[w.split('/')[-1]]\n",
    "        if plotPar:\n",
    "            hocr = dp['hocr']\n",
    "            # also, get paragraphs\n",
    "            # paragraphs from OCR\n",
    "            bbox_par = []\n",
    "            nameSpace = ''\n",
    "            for l in hocr.split('\\n'):\n",
    "                if 'xmlns' in l:\n",
    "                    nameSpace = l.split('xmlns=\"')[1].split('\"')[0]\n",
    "                    break\n",
    "            ns = {'tei': nameSpace}\n",
    "            tree = etree.fromstring(hocr.encode())\n",
    "            # get paragraphs\n",
    "            lines = tree.xpath(\"//tei:p[@class='ocr_par']/@title\", namespaces=ns)\n",
    "            langs = tree.xpath(\"//tei:p[@class='ocr_par']/@lang\", namespaces=ns)\n",
    "            for l,la in zip(lines,langs):\n",
    "                x = l.split(' ')\n",
    "                b = np.array(x[1:]).astype('int')\n",
    "                area = (b[3]-b[1])*(b[2]-b[0])\n",
    "                bbox_par.append((b,area,la))\n",
    "\n",
    "            fn = w.split('/')[-1]\n",
    "            fn2 = fn[:fn.rfind('.')+1]\n",
    "            if fn2[-1] == '.': fn2 = fn2[:-1]\n",
    "            #fn = w.split('/')[-1].split('_p')[0]\n",
    "            d = dones.loc[dones['filename'] == fn2]\n",
    "            widthOrig = imgSizesOrig[iw][0]*1.0; heightOrig = imgSizesOrig[iw][1]*1.0\n",
    "            width = imgSizes[iw][0]*1.0; height = imgSizes[iw][1]*1.0\n",
    "            # create fig caption bounding boxs\n",
    "            boxesOut = []; labelsOut = []; bb = []\n",
    "            if len(d) > 0 and not use_model_ann: # otherwise skip\n",
    "                for lab,xmin,ymin,xmax,ymax in zip(d['labels'].values[0], d['xmin'].values[0], \n",
    "                                                   d['ymin'].values[0],d['xmax'].values[0],d['ymax'].values[0]):\n",
    "                    b = [xmin/widthOrig*width,ymin/heightOrig*height,xmax/widthOrig*width,ymax/heightOrig*height]\n",
    "                    if 'caption' in lab.lower():\n",
    "                        iouMax = -10; \n",
    "                        indIou = []\n",
    "                        for ibb, bp in enumerate(bbox_par): # these are also xmin,ymin,xmax,ymax -- found w/OCR, original page size\n",
    "                            bb,aa,ll = bp\n",
    "                            x1min = b[0]; y1min = b[1]; x1max = b[2]; y1max = b[3]\n",
    "                            x2min, y2min, x2max, y2max = bb\n",
    "                            isOverlapping = (x1min <= x2max and x2min <= x1max and y1min <= y2max and y2min <= y1max)\n",
    "                            if isOverlapping:\n",
    "                            #if True:\n",
    "                                coords = np.array(np.round(bb), dtype=np.int32)\n",
    "                                c1 = (coords[0],coords[1]); c2 = (coords[2], coords[3])\n",
    "                                cv.rectangle(imgdata, c1, c2, (0, 255, 255), 4)  \n",
    "            elif use_model_ann and len(d) == 0:\n",
    "                print('no d!')\n",
    "                print(fn)\n",
    "\n",
    "        im_invert = Image.fromarray(imgdata)\n",
    "        im_invert.save(storeTmps+'images/'+ w.split('/')[-1], quality=100) \n",
    "        im.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9df9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ff\n",
    "#d\n",
    "#copy_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df29bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(storeTmps+'annotations/'):\n",
    "    os.makedirs(storeTmps+'annotations/')\n",
    "# delete and remake\n",
    "shutil.rmtree(storeTmps+'annotations/')\n",
    "os.makedirs(storeTmps+'annotations/')\n",
    "\n",
    "if (copy_annotations) and bad_ann_file is None:\n",
    "    # copy\n",
    "    for iw,w in enumerate(ws):\n",
    "        fn = w.split('/')[-1]\n",
    "        fn = fn[:fn.rfind('.')+1]\n",
    "        if fn[-1] == '.': fn = fn[:-1]\n",
    "        fn = annotation_dir + fn + '.xml'\n",
    "        # open and parse -- ASSUMES LABELS ARE AS LISTED\n",
    "        #labels_annotation\n",
    "        if os.path.exists(fn): \n",
    "            img_name, bbox = parse_annotation([fn],labels_annotation) \n",
    "            # bbox is in xmin, ymin, xmax,ymax\n",
    "            xfrac = imgSizes[iw][1]*1.0/IMAGE_W; yfrac = imgSizes[iw][0]*1.0/IMAGE_H\n",
    "            with open(storeTmps+'annotations/'+ fn.split('/')[-1].split('.xml')[0] + '.txt','w') as fsave:\n",
    "                if len(bbox) > 0:\n",
    "                    for bb in bbox[0]:\n",
    "                        xmin = bb[0]*xfrac; ymin = bb[1]*yfrac; xmax = bb[2]*xfrac; ymax = bb[3]*yfrac\n",
    "                        #x = int(round(xmin/imgSizes[iw][1])); y = int(round(ymin/imgSizes[iw][0])); \n",
    "                        #w = int(round((xmax-xmin)/imgSizes[iw][1])); h = int(round((ymax-ymin)/imgSizes[iw][0]))\n",
    "                        x = xmin/imgSizes[iw][1]; y = ymin/imgSizes[iw][0]; \n",
    "                        w = (xmax-xmin)/imgSizes[iw][1]; h = (ymax-ymin)/imgSizes[iw][0]\n",
    "                        # I think we want centers?\n",
    "                        x = x+w*0.5; y = y+0.5*h\n",
    "                        lab = labels_annotation[int(bb[4])-1]\n",
    "                        if lab == 'multi-figure': lab = 'figure' # rename all to figure for now\n",
    "                        try: \n",
    "                            l = labels.index(lab)\n",
    "                        except:\n",
    "                            l = -1\n",
    "                        if l > -1: # found in these labels\n",
    "                            fsave.write(str(l) + ' ' + str(x) + ' ' + str(y) + ' ' + str(w) + ' ' + str(h) + '\\n')\n",
    "            \n",
    "    #write label file\n",
    "    with open(storeTmps + 'annotations/' + labelFile,'w') as f:\n",
    "        for l in labels:\n",
    "            f.write(l.replace(' ', '_') + '\\n')\n",
    "\n",
    "elif bad_ann_file is not None:\n",
    "    for iw,w in enumerate(ws):\n",
    "        fn = w.split('/')[-1]\n",
    "        fn = fn[:fn.rfind('.')+1]\n",
    "        if fn[-1] == '.': fn = fn[:-1]\n",
    "        fn = annotation_dir + fn + '.xml'\n",
    "        # open and parse -- ASSUMES LABELS ARE AS LISTED\n",
    "        #labels_annotation\n",
    "        if os.path.exists(fn): \n",
    "            img_name, bbox = parse_annotation([fn],labels_annotation) \n",
    "            # bbox is in xmin, ymin, xmax,ymax\n",
    "            xfrac = imgSizes[iw][1]*1.0/IMAGE_W; yfrac = imgSizes[iw][0]*1.0/IMAGE_H\n",
    "            with open(storeTmps+'annotations/'+ fn.split('/')[-1].split('.xml')[0] + '.txt','w') as fsave:\n",
    "                if len(bbox) > 0:\n",
    "                    for bb in bbox[0]:\n",
    "                        xmin = bb[0]*xfrac; ymin = bb[1]*yfrac; xmax = bb[2]*xfrac; ymax = bb[3]*yfrac\n",
    "                        #x = int(round(xmin/imgSizes[iw][1])); y = int(round(ymin/imgSizes[iw][0])); \n",
    "                        #w = int(round((xmax-xmin)/imgSizes[iw][1])); h = int(round((ymax-ymin)/imgSizes[iw][0]))\n",
    "                        x = xmin/imgSizes[iw][1]; y = ymin/imgSizes[iw][0]; \n",
    "                        w = (xmax-xmin)/imgSizes[iw][1]; h = (ymax-ymin)/imgSizes[iw][0]\n",
    "                        # I think we want centers?\n",
    "                        x = x+w*0.5; y = y+0.5*h\n",
    "                        lab = labels_annotation[int(bb[4])-1]\n",
    "                        if lab == 'multi-figure': lab = 'figure' # rename all to figure for now\n",
    "                        try: \n",
    "                            l = labels.index(lab)\n",
    "                        except:\n",
    "                            l = -1\n",
    "                        if l > -1: # found in these labels\n",
    "                            fsave.write(str(l) + ' ' + str(x) + ' ' + str(y) + ' ' + str(w) + ' ' + str(h) + '\\n')\n",
    "                # other ones\n",
    "                dMS = donesMS.loc[donesMS['filename']==fn.split('/')[-1].split('.xml')[0]]\n",
    "                ww,hh = dMS['width'].values,dMS['height'].values\n",
    "                for ls,xmins,xmaxs,ymins,ymaxs in zip(dMS['labels'].values, \n",
    "                                                            dMS['xmin'].values,\n",
    "                                                            dMS['xmax'].values,dMS['ymin'].values,\n",
    "                                                            dMS['ymax'].values):\n",
    "                    for l,xmin,xmax,ymin,ymax in zip(ls,xmins,xmaxs,ymins,ymaxs):\n",
    "                        if 'figure' != l and 'figure_caption' != l and 'table' != l:\n",
    "                            w = xmax-xmin; h = ymax-ymin\n",
    "                            fsave.write(str(labels.index(l.replace('_',' '))) + ' ' + \\\n",
    "                                        str((xmin+0.5*w)/ww[0]) + ' ' + str((ymin+0.5*h)/hh[0]) + ' ' + str(w/ww[0]) + ' ' + str(h/hh[0]) + '\\n')\n",
    "                    \n",
    "                #import sys; sys.exit()\n",
    "            \n",
    "    #write label file\n",
    "    with open(storeTmps + 'annotations/' + labelFile,'w') as f:\n",
    "        for l in labels:\n",
    "            f.write(l.replace(' ', '_') + '\\n')\n",
    "\n",
    "elif redo_makesense: # grab old annotations\n",
    "    for iw, ww in enumerate(ws):\n",
    "        if '_p' in ww:\n",
    "            fn = ww.split('/')[-1]\n",
    "            fn2 = fn[:fn.rfind('.')+1]\n",
    "            if fn2[-1] == '.': fn2 = fn2[:-1]\n",
    "            #fn = ww.split('/')[-1].split('_p')[0]\n",
    "\n",
    "            d = dones.loc[dones['filename'] == fn2]\n",
    "            w = d['width'].values[0]*1.0; h = d['height'].values[0]*1.0\n",
    "            #w = imgSizesOrig[iw][0]*1.0; h = imgSizesOrig[iw][1]*1.0\n",
    "            \n",
    "            # check ratios -- scanned pages can be subsets of full PDFs\n",
    "            rDPI = imgSizes[iw][0]/imgSizes[iw][1]; rImg = imgSizesOrig[iw][0]/imgSizesOrig[iw][1]\n",
    "            if rDPI == rImg:\n",
    "                xc = 0\n",
    "            else: # we have a border that has been cut and need to re-size\n",
    "                dX = rDPI*imgSizesOrig[iw][1] # dX1/dY1 * dY2\n",
    "                xc = (dX-imgSizesOrig[iw][0])*0.5\n",
    "            \n",
    "            #if xc != 0: import sys; sys.exit()\n",
    "            # for translation\n",
    "            fracy = imgSizes[iw][1]*1.0/imgSizesOrig[iw][1]\n",
    "            with open(storeTmps+'annotations/'+ fn2 + '.txt','w') as fsave:\n",
    "                for lab,xmin,ymin,xmax,ymax in zip(d['labels'].values[0], d['xmin'].values[0], \n",
    "                                                   d['ymin'].values[0],d['xmax'].values[0],d['ymax'].values[0]):\n",
    "                #for lab,(xmin,ymin,xmax,ymax) in zip(labelsOut,boxesOut):\n",
    "                    try: \n",
    "                        l = labels.index(lab.replace('_',' '))\n",
    "                    except:\n",
    "                        l = -1\n",
    "                    if l > -1: # found in these labels\n",
    "                        #x = xmin + 0.5*(xmax-xmin); y = ymin + 0.5*(ymax-ymin)\n",
    "                        #fsave.write(str(l) + ' ' + str(x/w) + ' ' + str(y/h) + \\\n",
    "                        #            ' ' + str((xmax-xmin)/w) + ' ' + str((ymax-ymin)/h) + '\\n')\n",
    "                        if abs(fracy-1.0) < 0.05:\n",
    "                            x1 = (xmin+xc)/fracy; y1 = ymin*fracy; x2 = (xmax-xc)*fracy; y2 = ymax*fracy\n",
    "                            xc1 = x1 + 0.5*(x2-x1); yc1 = y1 + 0.5*(y2-y1)\n",
    "                            if x1>0 and (x2-x1)> 0:\n",
    "                                fsave.write(str(l) + ' ' + str(xc1/w) + ' ' + str(min([yc1/h,1.0])) + \\\n",
    "                                        ' ' + str(min([(x2-x1)/w,1.0-x1/w])) + ' ' + str(min([(y2-y1)/h,1.0-y1/h])) + '\\n')\n",
    "                        else:\n",
    "                            xc1 = xmin + 0.5*(xmax-xmin); yc1 = ymin + 0.5*(ymax-ymin)\n",
    "                            fsave.write(str(l) + ' ' + str(xc1/w) + ' ' + str(min([yc1/h,1.0])) + \\\n",
    "                                        ' ' + str(min([(xmax-xmin)/w,1.0])) + ' ' + str(min([(ymax-ymin)/h,1.0])) + '\\n')\n",
    "                            \n",
    "\n",
    "        else:\n",
    "            print('nope for', ww)\n",
    "            \n",
    "    #write label file\n",
    "    with open(storeTmps + 'annotations/' + labelFile,'w') as f:\n",
    "        for l in labels:\n",
    "            f.write(l.replace(' ', '_') + '\\n')    \n",
    "    \n",
    "            \n",
    "if (use_model_ann) and (not redo_makesense) and bad_ann_file is None:\n",
    "    # should already be in main binaries folder\n",
    "    for w,imSize in zip(ws,imgSizes):\n",
    "        fn = w.split('/')[-1]\n",
    "        fn = fn[:fn.rfind('.')+1]\n",
    "        if fn[-1] == '.': fn = fn[:-1]\n",
    "        fn = binariesDir + '../' + fn + '.npz'\n",
    "\n",
    "        image_np = np.load(fn)['arr_0']\n",
    "        image_np = image_np.astype(np.float32) / 255.0\n",
    "        \n",
    "        boxes, scores, labelsout = model.predict(image_np[np.newaxis, ...])\n",
    "        boxes, scores, labelsout = np.squeeze(boxes, 0), np.squeeze(scores, 0), np.squeeze(labelsout, 0)\n",
    "        #print(labelsout)\n",
    "        # resize boxes\n",
    "        xfrac = imSize[1]*1.0/IMAGE_W; yfrac = imSize[0]*1.0/IMAGE_H\n",
    "        if os.path.exists(fn): \n",
    "            with open(storeTmps+'annotations/'+ fn.split('/')[-1].split('.npz')[0] + '.txt','w') as fsave:\n",
    "                for bb,ll in zip(boxes,labelsout):\n",
    "                    xmin = bb[0]*xfrac; ymin = bb[1]*yfrac; xmax = bb[2]*xfrac; ymax = bb[3]*yfrac\n",
    "                    x = xmin/imSize[1]; y = ymin/imSize[0]; \n",
    "                    w = (xmax-xmin)/imSize[1]; h = (ymax-ymin)/imSize[0]\n",
    "                    # I think we want centers?\n",
    "                    x = x+w*0.5; y = y+0.5*h\n",
    "                    #lab = labels_annotation[int(bb[4])-1]\n",
    "                    if ll > -1:\n",
    "                        #lab = LABELS[int(ll)-1]\n",
    "                        lab = LABELS[int(ll)]\n",
    "                        #print(ll,lab)\n",
    "                        if lab == 'multi-figure': lab = 'figure' # rename all to figure for now\n",
    "                        try: \n",
    "                            #l = labels.index(lab)\n",
    "                            l = labels.index(lab)\n",
    "                            #print(l)\n",
    "                        except:\n",
    "                            l = -1\n",
    "                        if l > -1: # found in these labels\n",
    "                            fsave.write(str(l) + ' ' + str(max([x,0])) + ' ' + str(max([y,0])) + ' ' + str(min([w,1])) + ' ' + str(min([h,1])) + '\\n')\n",
    "                        #import sys; sys.exit()\n",
    "        else:\n",
    "            print('something has gone wrong')\n",
    "            import sys; sys.exit()\n",
    "\n",
    "        #import sys; sys.exit()\n",
    "        \n",
    "    #write label file with ALL labels\n",
    "    with open(storeTmps + 'annotations/' + labelFile,'w') as f:\n",
    "        for l in labels:\n",
    "            f.write(l.replace(' ', '_') + '\\n')\n",
    "\n",
    "\n",
    "print('all done!  go classify!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90609215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecaca5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72619c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915223bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43abd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
