{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b71e1c93",
   "metadata": {},
   "source": [
    "# Explore Postprocessing\n",
    "\n",
    "This notebook looks at the post processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8667baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary_dirs = 'binaries_model12_tfrecordz_pmcnoncom/'\n",
    "#binary_dirs = 'binaries_model12_tfrecordz/'\n",
    "binary_dirs = 'binaries_model1_tfrecordz/'\n",
    "#binary_dirs = 'binaries_model11_tfrecordz/'\n",
    "#binary_dirs = 'binaries_model2_tfrecordz/'\n",
    "\n",
    "ocr_results_dir = None\n",
    "make_sense_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8e6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "\n",
    "#import time\n",
    "#from lxml import etree\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "#import spacy\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "from annotation_utils import get_all_ocr_files, collect_ocr_process_results, \\\n",
    "   get_makesense_info_and_years\n",
    "\n",
    "from general_utils import parse_annotation, create_destroy_dirs\n",
    "\n",
    "from post_processing_utils import get_ocr_results, get_true_boxes, \\\n",
    "  get_image_process_boxes\n",
    "\n",
    "from feature_generation_utils import generate_single_feature\n",
    "\n",
    "from metric_utils import calc_base_metrics_allboxes_cv, calc_prec_rec_f1_cv,print_metrics_table, calc_base_metrics_allboxes_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4128a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one-on-one\n",
    "annotation_dir = config.save_binary_dir + config.ann_name + str(config.IMAGE_H) + 'x' + str(config.IMAGE_W) + '_ann/'\n",
    "# get feature list\n",
    "with open(config.save_binary_dir+binary_dirs + 'feature_list.pickle','rb') as f:\n",
    "    feature_list = pickle.load(f)[0]\n",
    "#feature_list\n",
    "\n",
    "if not os.path.exists(config.tmp_storage_dir+'TMPTFRECORD/'):\n",
    "    os.makedirs(config.tmp_storage_dir+'TMPTFRECORD/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81a8c4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build up filename\n",
    "pp = config.metric_results_dir\n",
    "pp += binary_dirs.split('/')[0]\n",
    "#pp += adder\n",
    "pp += '.pickle'\n",
    "with open(pp, 'rb') as ff:\n",
    "    icombo,imgs_name, truebox, pdfboxes, pdfrawboxes, captionText_figcap,\\\n",
    "                 bbox_figcap_pars,\\\n",
    "                 sboxes_cleaned, slabels_cleaned, sscores_cleaned,\\\n",
    "                 boxes_pdf, labels_pdf, scores_pdf,\\\n",
    "                 boxes_heur, labels_heur, scores_heur,\\\n",
    "                 boxes_heur2, labels_heur2, scores_heur2,\\\n",
    "                 boxes_par_found, labels_par_found, scores_par_found,\\\n",
    "                 boxes_sq1, labels_sq1, scores_sq1,\\\n",
    "                 boxes_sq2, labels_sq2, scores_sq2,\\\n",
    "                 boxes_sq3, labels_sq3, scores_sq3,\\\n",
    "                 boxes_sq4, labels_sq4, scores_sq4,\\\n",
    "                 boxes_sq5, labels_sq5, scores_sq5,\\\n",
    "                 truebox1,truebox2,truebox3,rotatedImage,\\\n",
    "                 LABELS,boxes1, scores1, labels1 = pickle.load(ff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c8a8cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retreiving OCR data, this can take a moment...\n",
      "##### OCR retrieval FILE: on 1 of 2  ##### \n",
      "--- OCR retrieval: on 0 of 5515 ---\n",
      "--- OCR retrieval: on 1000 of 5515 ---\n",
      "--- OCR retrieval: on 2000 of 5515 ---\n",
      "--- OCR retrieval: on 3000 of 5515 ---\n",
      "--- OCR retrieval: on 4000 of 5515 ---\n",
      "--- OCR retrieval: on 5000 of 5515 ---\n",
      "##### OCR retrieval FILE: on 2 of 2  ##### \n",
      "--- OCR retrieval: on 0 of 1500 ---\n",
      "--- OCR retrieval: on 1000 of 1500 ---\n"
     ]
    }
   ],
   "source": [
    "# let's get all of the ocr files\n",
    "ocrFiles = get_all_ocr_files(ocr_results_dir=ocr_results_dir)\n",
    "# get important quantities from these files\n",
    "print('retreiving OCR data, this can take a moment...')\n",
    "ws, paragraphs, squares, html, rotations,colorbars = collect_ocr_process_results(ocrFiles)\n",
    "# create dataframe\n",
    "df = pd.DataFrame({'ws':ws, 'paragraphs':paragraphs, 'squares':squares, \n",
    "                   'hocr':html, 'rotation':rotations, 'colorbars':colorbars})#, 'pdfwords':pdfwords})\n",
    "df = df.drop_duplicates(subset='ws')\n",
    "df = df.set_index('ws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c3ffc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- for some reason 1901ApJ____14__269C_p7 is not in this list -----\n",
      "---- for some reason 1996ApJ___466_1087P_p8 is not in this list -----\n",
      "---- for some reason 1979AJ_____84__910B_p10 is not in this list -----\n",
      "---- for some reason 1989AJ_____98_1398H_p5 is not in this list -----\n",
      "---- for some reason 1994ApJS___95__457W_p15 is not in this list -----\n",
      "---- for some reason 1990ApJ___351__443U_p6 is not in this list -----\n",
      "---- for some reason 1963ApJ___137__280W_p8 is not in this list -----\n",
      "---- for some reason 1990ApJ___365__510C_p2 is not in this list -----\n",
      "---- for some reason 1991ApJS___76__455E_p6 is not in this list -----\n",
      "---- for some reason 1992AJ____103_1151C_p9 is not in this list -----\n",
      "---- for some reason 1982ApJS___50____1W_p18 is not in this list -----\n",
      "unique = 5515 pages\n"
     ]
    }
   ],
   "source": [
    "dfMakeSense = get_makesense_info_and_years(df,make_sense_dir=make_sense_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81acecc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['figure', 'figure caption', 'math formula', 'table']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get labels list too\n",
    "LABELS = pd.read_csv(config.save_binary_dir + binary_dirs + 'LABELS.csv', names=['l'])['l'].values.astype('str').tolist()\n",
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c37b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save tmp binaries for this\n",
    "# def create_destroy_dirs(dirs):\n",
    "#     if not os.path.exists(dirs):\n",
    "#         os.makedirs(dirs)\n",
    "#     # delete and remake\n",
    "#     shutil.rmtree(dirs)\n",
    "#     os.makedirs(dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9c10af",
   "metadata": {},
   "source": [
    " * Step 1 (truebox, boxes1): \"raw\" found boxes are compared to true boxes after non-maximum suppression is applied\n",
    " * Step 2 (truebox, sboxes_cleaned): if two found boxes overlap with an IOU $\\ge$ 0.25 we remove the box with the lowest score.  This decreases the FP rate for captions at all IOU thresholds and for figures predominately at the high IOU thresholds.\n",
    " * Step 3 (truebox, boxes_pdf): if a raw or figure caption box is found through PDF mining and overlaps with a mega-yolo found box, use the PDF-mining results, which increases figure caption TP rate and decreases FP and FN at large IOU thresholds.  PDF-mining figure boxes are ignored.\n",
    " * Step 4 (truebox, boxes_heur): if a heuristically-found caption box overlaps with a mega-yolo-found box, take the top of the heuristic box (which tends to be more accurate) and the minimum (maximum) of the left (right, bottom) of the two boxes.  This results in an overall increase in FP while FN and FP drop.\n",
    " * Step 5 (truebox, boxes_par_found): grow found captions by their overlap with OCR word and paragraph boxes, allowing for multiple \"grow\" iterations in the horizontal direction.  For found boxes, only grow if centers of paragraph and word boxes overlap with the found box ~~(isn't this already done in the annotation step though?)~~\n",
    " * Step 6 (truebox, boxes_sq1): if found figure boxes overlap with image-processing squares, the found box is expanded to include the square.  This extends the TP rate at larger IOU thresholds.\n",
    " * Step 7 (truebox, boxes_sq2): any captions that have areas larger than 75% of the page area are discarded leading to a slight drop in FP for captions.\n",
    " * Step 8 (truebox, boxes_sq3): figure captions are matched to figures.  Any captions without an associated figure are dropped, leading to a drop in FP.\n",
    " * Step 9 (truebox2, boxes_sq4): both true and found figure boxes are extended down to the tops of their associated captions increasing TP for figures (and to a lesser extentent, captions) at high IOU thresholds.\n",
    " * Step 10 (truebox3, boxes_sq5): if a figure caption extends horizontally further than its associated figure, the figure is extended horizontally to the edges of the figure caption for both true and found boxes.  This leads to an increase in TP rates for figures at high IOU thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "583cd08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory structure for all of this\n",
    "save_dir = config.tmp_storage_dir + binary_dirs\n",
    "\n",
    "create_destroy_dirs(save_dir)\n",
    "\n",
    "# make steps directories\n",
    "for i in range(11):\n",
    "    os.mkdir(config.tmp_storage_dir + binary_dirs + 'Step' + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c50b1e",
   "metadata": {},
   "source": [
    "**Step 0:** Preliminary parsed annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "270d27f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jnaiman/Dropbox/wwt_image_extraction/FigureLocalization/StoredFeatures/MegaYolo/yolo_512x512_ann/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgDirAnn = config.save_binary_dir + config.ann_name + str(int(config.IMAGE_H)) + 'x' + str(int(config.IMAGE_W))  + '_ann/'\n",
    "imgDirAnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d4c2b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get make sense info\n",
    "dY = 10; dX = 10\n",
    "larger_inds = []\n",
    "dYs = []; dXs = []\n",
    "inds_weird = []\n",
    "for iw in range(len(dfMakeSense)):\n",
    "    d = dfMakeSense.loc[dfMakeSense['filename']==dfMakeSense['filename'].values[iw]]\n",
    "    noLabel = True\n",
    "    if len(d['squares'].values) > 1:\n",
    "        print('NOPE')\n",
    "        import sys; sys.exit()\n",
    "    for s in d['squares'].values[0]:\n",
    "        if 'no label' not in s[-1]: noLabel = False\n",
    "    # open\n",
    "    ina, true_boxes, pdfboxes, \\\n",
    "       pdfrawboxes = parse_annotation([imgDirAnn + d['filename'].values[0]+'.xml'], \n",
    "                                      LABELS,\n",
    "                                      feature_dir = config.save_binary_dir + binary_dirs,\n",
    "                     annotation_dir = imgDirAnn, parse_pdf=True,\n",
    "                                     check_for_file=False)   \n",
    "    # sort\n",
    "    if len(true_boxes) > 0:\n",
    "        true_boxes1 = true_boxes[0] # formatted\n",
    "        # take out others\n",
    "        true_boxes = []\n",
    "        for t in true_boxes1:\n",
    "            if t[-1] != 0:\n",
    "                true_boxes.append(t)\n",
    "        true_boxes = np.array(true_boxes)\n",
    "        #inds1 = np.lexsort( (true_boxes[:,0], true_boxes[:,1]) )\n",
    "        #true_boxes = true_boxes[inds1]\n",
    "        true_boxes = np.sort(true_boxes,axis=0)\n",
    "        for i in range(len(true_boxes)):\n",
    "            true_boxes[i,0] = true_boxes[i,0]/config.IMAGE_W*d['w'].values[0]\n",
    "            true_boxes[i,2] = true_boxes[i,2]/config.IMAGE_W*d['w'].values[0]\n",
    "            true_boxes[i,1] = true_boxes[i,1]/config.IMAGE_H*d['h'].values[0]\n",
    "            true_boxes[i,3] = true_boxes[i,3]/config.IMAGE_H*d['h'].values[0]\n",
    "    if not noLabel and len(true_boxes)>0:\n",
    "        found_boxes = [] # original\n",
    "        for s in d['squares'].values[0]:\n",
    "            if 'no label' not in s[-1]:\n",
    "                try:\n",
    "                    found_boxes.append([s[0],s[1],s[0]+s[2],s[1]+s[3],\n",
    "                                        LABELS.index(s[-1])+1])\n",
    "                except:\n",
    "                    f = 0\n",
    "                    \n",
    "        # sort\n",
    "        found_boxes = np.array(found_boxes)\n",
    "        #inds = np.lexsort( (found_boxes[:,0], found_boxes[:,1]) )\n",
    "        #found_boxes = found_boxes[inds]\n",
    "        found_boxes = np.sort(found_boxes,axis=0)\n",
    "        # round trues!\n",
    "        true_boxes = np.round(true_boxes).astype('int')\n",
    "        # found boxes should be smaller than true boxes\n",
    "        for t,f in zip(true_boxes,found_boxes):\n",
    "            #if f[0]<t[0] or f[1]<t[1] or f[2]>t[2] or f[3]>t[3]:\n",
    "            if t[0]<f[0]-dX or t[1]<f[1]-dY or t[2]>f[2]+dX or t[3]>f[3]+dY:\n",
    "                larger_inds.append(iw)\n",
    "                dXs.append([t[0]-f[0],f[2]-t[2]])\n",
    "                dYs.append([t[1]-f[1],f[3]-t[3]])\n",
    "                if t[-1] != LABELS.index('figure caption')+1 or f[-1] != LABELS.index('figure caption')+1:\n",
    "                    inds_weird.append((iw,t[-1],f[-1]))\n",
    "                    #print('open tmp',ina[0].split('/')[-1].split('.npz')[0])\n",
    "                    #import sys; sys.exit()\n",
    "                #import sys; sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ff38915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 269)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LABELS.index('figure caption')\n",
    "len(inds_weird), len(np.unique(larger_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2066d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min([iweird+10,len(inds_weird)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35f7b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inds_weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "739a0f26",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jnaiman/Downloads/tmp/tmpAnnDiags/1994ApJ___427__656M_p3.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iweird,\u001b[38;5;28mmin\u001b[39m([iweird\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m10\u001b[39m,\u001b[38;5;28mlen\u001b[39m(inds_weird)])):\n\u001b[1;32m      7\u001b[0m     fname \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtmp_storage_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmpAnnDiags/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m dfMakeSense\u001b[38;5;241m.\u001b[39miloc[inds_weird[i][\u001b[38;5;241m0\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m     img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      9\u001b[0m     ax[i\u001b[38;5;241m-\u001b[39miweird]\u001b[38;5;241m.\u001b[39mimshow(img)\n\u001b[1;32m     10\u001b[0m     ax[i\u001b[38;5;241m-\u001b[39miweird]\u001b[38;5;241m.\u001b[39mset_title(dfMakeSense\u001b[38;5;241m.\u001b[39miloc[inds_weird[i][\u001b[38;5;241m0\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, orig=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mLABELS[inds_weird[i][\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, mod=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mLABELS[inds_weird[i][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wwtProject/lib/python3.8/site-packages/PIL/Image.py:2953\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2950\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   2952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 2953\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2954\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2956\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jnaiman/Downloads/tmp/tmpAnnDiags/1994ApJ___427__656M_p3.png'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x3600 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iweird = 20\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(5,2,figsize=(20,50))\n",
    "ax = ax.flatten()\n",
    "for i in range(iweird,min([iweird+10,len(inds_weird)])):\n",
    "    fname = config.tmp_storage_dir + 'tmpAnnDiags/' + dfMakeSense.iloc[inds_weird[i][0]]['filename'] + '.png'\n",
    "    img = np.array(Image.open(fname).convert('RGB'))\n",
    "    ax[i-iweird].imshow(img)\n",
    "    ax[i-iweird].set_title(dfMakeSense.iloc[inds_weird[i][0]]['filename']+', orig='+LABELS[inds_weird[i][2]-1]+', mod='+LABELS[inds_weird[i][1]-1])\n",
    "    print(dfMakeSense.iloc[inds_weird[i][0]]['filename'])\n",
    "    del img\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee325772",
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_inds = np.unique(larger_inds)\n",
    "len(larger_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b2ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "iweird = 100\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(5,2,figsize=(20,50))\n",
    "ax = ax.flatten()\n",
    "for i in range(iweird,min([iweird+10,len(larger_inds)])):\n",
    "    fname = config.tmp_storage_dir + 'tmpAnnDiags/' + dfMakeSense.iloc[larger_inds[i]]['filename'] + '.png'\n",
    "    img = np.array(Image.open(fname).convert('RGB'))\n",
    "    ax[i-iweird].imshow(img)\n",
    "    ax[i-iweird].set_title(dfMakeSense.iloc[larger_inds[i]]['filename'])\n",
    "    #print(dfMakeSense.iloc[larger_inds[i]]['filename'])\n",
    "    del img\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4be508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2,2,figsize=(10*2,5*2))\n",
    "\n",
    "# nbin = 500\n",
    "# ax[0][0].hist(dXs[:,0],bins=nbin)\n",
    "# #ax[0][0].set_title('\n",
    "# ax[0][1].hist(dXs[:,1],bins=nbin)\n",
    "\n",
    "# ax[1][0].hist(dYs[:,0],bins=nbin)\n",
    "# ax[1][1].hist(dYs[:,1],bins=nbin)\n",
    "\n",
    "# for k in range(2):\n",
    "#     for m in range(2):\n",
    "#         ax[k][m].set_xlim(-100,100)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7367bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "colfig_true = (0,0,255) # true fig is blue\n",
    "colcap_true = (0,255,255) # true cap is cyan\n",
    "coltable_true = (0,255,0) # true table is green\n",
    "\n",
    "colfig_found = (255,0,0) # found fig is red\n",
    "colcap_found = (255,0,255) # found cap is magenta\n",
    "coltable_found = (255,255,0) # found table is yellow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0dad10",
   "metadata": {},
   "source": [
    "**Step 1 (truebox, boxes1):** \"raw\" found boxes are compared to true boxes after non-maximum suppression is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86375b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 549\n",
      "100 of 549\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# save\u001b[39;00m\n\u001b[1;32m     31\u001b[0m inameout \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtmp_storage_dir \u001b[38;5;241m+\u001b[39m binary_dirs \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStep1/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m imn\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43minameout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m img\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wwtProject/lib/python3.8/site-packages/PIL/Image.py:2212\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2209\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2211\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2212\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# do what we can to clean up\u001b[39;00m\n\u001b[1;32m   2215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wwtProject/lib/python3.8/site-packages/PIL/JpegImagePlugin.py:783\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;66;03m# The EXIF info needs to be written as one block, + APP1, + one spare byte.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;66;03m# Ensure that our buffer is big enough. Same with the icc_profile block.\u001b[39;00m\n\u001b[1;32m    781\u001b[0m bufsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(ImageFile\u001b[38;5;241m.\u001b[39mMAXBLOCK, bufsize, \u001b[38;5;28mlen\u001b[39m(exif) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;28mlen\u001b[39m(extra) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 783\u001b[0m \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wwtProject/lib/python3.8/site-packages/PIL/ImageFile.py:527\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    525\u001b[0m     l, s \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mencode_to_pyfd()\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 527\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder error \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m when writing image file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 1 -- make images to save\n",
    "for iloop,(tb,fb,l,imn) in enumerate(zip(truebox, boxes1, labels1,imgs_name)):\n",
    "    if iloop%100 == 0: print(iloop,'of',len(imgs_name))\n",
    "    if len(tb) > 0 or len(fb) > 0:\n",
    "        #import sys; sys.exit()\n",
    "        iname = config.images_jpeg_dir + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        img = np.array(Image.open(iname).convert('RGB'))\n",
    "        # draw figures\n",
    "        for t in tb:\n",
    "            xmin = t[0]/config.IMAGE_W*img.shape[1]; xmax = t[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = t[1]/config.IMAGE_H*img.shape[0]; ymax = t[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[int(t[-1]-1)]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_true, 7)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_true, 7)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_true, 7)\n",
    "        for f,ll in zip(fb,l):\n",
    "            xmin = f[0]/config.IMAGE_W*img.shape[1]; xmax = f[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = f[1]/config.IMAGE_H*img.shape[0]; ymax = f[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[ll]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_found, 4)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_found, 4)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_found, 4)\n",
    "                \n",
    "        # save\n",
    "        inameout = config.tmp_storage_dir + binary_dirs + 'Step1/' + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        Image.fromarray(img).save(inameout)\n",
    "        del img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46922a1d",
   "metadata": {},
   "source": [
    "**Step 2 (truebox, sboxes_cleaned):** if two found boxes overlap with an IOU $\\ge$ 0.25 we remove the box with the lowest score.  This decreases the FP rate for captions at all IOU thresholds and for figures predominately at the high IOU thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b6f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 -- only save if different from before\n",
    "# Step 2 (truebox, sboxes_cleaned)\n",
    "for iloop,(tb,fb1,lab1,fb2,lab2,imn) in enumerate(zip(truebox, boxes1, labels1,sboxes_cleaned, slabels_cleaned, imgs_name)):\n",
    "    if iloop%100 == 0: print(iloop,'of',len(imgs_name))\n",
    "    dontPlot = True\n",
    "    if len(tb) > 0 or len(fb) > 0: # do we have something?\n",
    "        if len(lab1) != len(lab2): # different number of labels\n",
    "            dontPlot = False # gotta plot it!\n",
    "        else:\n",
    "            # check to see if any of them have changed, box-wise\n",
    "            newBox = []\n",
    "            for b1 in fb1:\n",
    "                # look for index\n",
    "                try:\n",
    "                    fb2.tolist().index(b1.tolist())\n",
    "                    newBox.append(False)\n",
    "                except: # not in there\n",
    "                    newBox.append(True)\n",
    "            if np.array(newBox).any(): # do we have at least one new box?\n",
    "                dontPlot = False\n",
    "            else:\n",
    "                dontPlot = True\n",
    "                \n",
    "    if not dontPlot: # if anything has happened, plot!\n",
    "        iname = config.images_jpeg_dir + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        img = np.array(Image.open(iname).convert('RGB'))\n",
    "        # draw figures\n",
    "        for t in tb:\n",
    "            xmin = t[0]/config.IMAGE_W*img.shape[1]; xmax = t[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = t[1]/config.IMAGE_H*img.shape[0]; ymax = t[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[int(t[-1]-1)]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_true, 7)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_true, 7)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_true, 7)\n",
    "        for f,ll in zip(fb2,lab2): # only plot new boxes!\n",
    "            xmin = f[0]/config.IMAGE_W*img.shape[1]; xmax = f[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = f[1]/config.IMAGE_H*img.shape[0]; ymax = f[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[ll]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_found, 4)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_found, 4)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_found, 4)\n",
    "                \n",
    "        # save\n",
    "        inameout = config.tmp_storage_dir + binary_dirs + 'Step2/' + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        Image.fromarray(img).save(inameout)\n",
    "        del img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38106821",
   "metadata": {},
   "source": [
    "**Step 3 (truebox, boxes_pdf):** if a raw or figure caption box is found through PDF mining and overlaps with a mega-yolo found box, use the PDF-mining results, which increases figure caption TP rate and decreases FP and FN at large IOU thresholds.  PDF-mining figure boxes are ignored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f192eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#abase = '1994ApJS___90__833M_p1'\n",
    "#abase = '1988ApJ___335__552T_p35'\n",
    "abase = '1996ApJ___462__339W_p2'\n",
    "#abase = '1942ApJ____95__461K_p4'\n",
    "#abase = '1981ApJ___243L_137H_p1'\n",
    "#abase = '1982ApJ___257L__77J_p6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac08a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a particular one\n",
    "a = annotation_dir+abase+'.xml'\n",
    "feature_dir = config.save_binary_dir + binary_dirs\n",
    "\n",
    "imgs_nameh, pdfboxesh, pdfrawboxesh,years_indh, trueboxh = get_true_boxes(a,LABELS,\n",
    "                                                   [],[],\n",
    "                                                   annotation_dir=annotation_dir,\n",
    "                                                  feature_dir=feature_dir,\n",
    "                                                    check_for_file=False)\n",
    "dfsingle = df.loc[abase+'.jpeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "isave = -1\n",
    "for iiname,iname in enumerate(imgs_name):\n",
    "    if abase in iname:\n",
    "        isave=iiname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_name[isave]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f7e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import post_processing_utils\n",
    "reload(post_processing_utils)\n",
    "from post_processing_utils import clean_overlapping_squares, clean_merge_pdfsquares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec2a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sboxes_cleanedh, slabels_cleanedh, sscores_cleanedh = clean_overlapping_squares(boxes1[isave],\n",
    "#                                                                              scores1[isave],\n",
    "#                                                                              labels1[isave],\n",
    "#                                                                              imgs_name[isave])\n",
    "\n",
    "ff = imgs_name[isave].split('/')[-1].split('.npz')[0]\n",
    "dfMS = dfMakeSense.loc[dfMakeSense['filename']==ff]\n",
    "\n",
    "\n",
    "# merge with any boxes that have been found with PDF mining\n",
    "# found figures are generally not accurate, so ignore these, but do \n",
    "# assume any tables or figure captions are more accurate from PDF mining\n",
    "boxes_pdfh, labels_pdfh, scores_pdfh = clean_merge_pdfsquares(pdfboxesh,\n",
    "                                                           pdfrawboxesh,\n",
    "                                                           sboxes_cleaned[isave], \n",
    "                                                           slabels_cleaned[isave], \n",
    "                                                           sscores_cleaned[isave], \n",
    "                                                           LABELS, dfMS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and show\n",
    "img = np.array(Image.open(config.images_jpeg_dir+imgs_name[isave].split('/')[-1].split('.npz')[0]+'.jpeg').convert('RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0c450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fracx = img.shape[1]/config.IMAGE_W; fracy = img.shape[0]/config.IMAGE_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367603d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw orig\n",
    "imgPlot1 = img.copy()\n",
    "for b,s,l in zip(boxes1[isave],scores1[isave],labels1[isave]):\n",
    "    xmin,ymin,xmax,ymax = b\n",
    "    xmin=xmin*fracx; xmax*=fracx\n",
    "    ymin*=fracy; ymax*=fracy\n",
    "    if LABELS[l] == 'figure':\n",
    "        cv.rectangle(imgPlot1, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_found, 5)\n",
    "    elif LABELS[l] == 'figure caption':\n",
    "        cv.rectangle(imgPlot1, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_found, 5)\n",
    "    elif LABELS[l] == 'table':\n",
    "        cv.rectangle(imgPlot1, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_found, 5)\n",
    "    else:\n",
    "        cv.rectangle(imgPlot1, (round(xmin), round(ymin)), (round(xmax),round(ymax)), (125,125,125), 5)    \n",
    "# draw new\n",
    "imgPlot2 = img.copy()\n",
    "for b,l,s in zip(boxes_pdfh, labels_pdfh, scores_pdfh):\n",
    "    xmin,ymin,xmax,ymax = b\n",
    "    xmin=xmin*fracx; xmax*=fracx\n",
    "    ymin*=fracy; ymax*=fracy\n",
    "    if LABELS[l] == 'figure':\n",
    "        cv.rectangle(imgPlot2, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_found, 7)\n",
    "    if LABELS[l] == 'figure caption':\n",
    "        cv.rectangle(imgPlot2, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_found, 7)\n",
    "    if LABELS[l] == 'table':\n",
    "        cv.rectangle(imgPlot2, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_found, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3707cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(20,10))\n",
    "ax[0].imshow(imgPlot1)\n",
    "ax[0].set_title('Step1')\n",
    "\n",
    "ax[1].imshow(imgPlot2)\n",
    "ax[1].set_title('Step3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2bd14",
   "metadata": {},
   "source": [
    "Full Step 3 run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sname='Step3/'\n",
    "for iloop,(tb,fb1,lab1,fb2,lab2,imn) in enumerate(zip(truebox, boxes1, labels1,boxes_pdf, labels_pdf, imgs_name)):\n",
    "    if iloop%100 == 0: print(iloop,'of',len(imgs_name))\n",
    "    dontPlot = True\n",
    "    if len(tb) > 0 or len(fb) > 0: # do we have something?\n",
    "        if len(lab1) != len(lab2): # different number of labels\n",
    "            dontPlot = False # gotta plot it!\n",
    "        else:\n",
    "            # check to see if any of them have changed, box-wise\n",
    "            newBox = []\n",
    "            for b1 in fb1:\n",
    "                # look for index\n",
    "                try:\n",
    "                    fb2.tolist().index(b1.tolist())\n",
    "                    newBox.append(False)\n",
    "                except: # not in there\n",
    "                    newBox.append(True)\n",
    "            if np.array(newBox).any(): # do we have at least one new box?\n",
    "                dontPlot = False\n",
    "            else:\n",
    "                dontPlot = True\n",
    "                \n",
    "    if not dontPlot: # if anything has happened, plot!\n",
    "        iname = config.images_jpeg_dir + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        img = np.array(Image.open(iname).convert('RGB'))\n",
    "        # draw figures\n",
    "        for t in tb:\n",
    "            xmin = t[0]/config.IMAGE_W*img.shape[1]; xmax = t[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = t[1]/config.IMAGE_H*img.shape[0]; ymax = t[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[int(t[-1]-1)]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_true, 7)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_true, 7)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_true, 7)\n",
    "        for f,ll in zip(fb2,lab2): # only plot new boxes!\n",
    "            xmin = f[0]/config.IMAGE_W*img.shape[1]; xmax = f[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = f[1]/config.IMAGE_H*img.shape[0]; ymax = f[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[ll]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_found, 4)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_found, 4)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_found, 4)\n",
    "                \n",
    "        # save\n",
    "        inameout = config.tmp_storage_dir + binary_dirs + sname + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        Image.fromarray(img).save(inameout)\n",
    "        del img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a565c43",
   "metadata": {},
   "source": [
    "**Step 4 (truebox, boxes_heur):** if a heuristically-found caption box overlaps with a mega-yolo-found box, take the top of the heuristic box (which tends to be more accurate) and the minimum (maximum) of the left (right, bottom) of the two boxes.  This results in an overall increase in FP while FN and FP drop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9356758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "abase = '1942ApJ____95__461K_p4'\n",
    "abase = '1981ApJ___243L_137H_p1'\n",
    "abase = '1982ApJ___257L__77J_p6'\n",
    "abase = '1996ApJ___462__339W_p2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a single one\n",
    "\n",
    "create_destroy_dirs(config.tmp_storage_dir+'TMPTFRECORD/')\n",
    "\n",
    "a = annotation_dir+abase+'.xml'\n",
    "feature_dir = config.save_binary_dir + binary_dirs\n",
    "\n",
    "imgs_nameh, pdfboxesh, pdfrawboxesh,years_ind, trueboxh = get_true_boxes(a,LABELS,\n",
    "                                                   [],[],\n",
    "                                                   annotation_dir=annotation_dir,\n",
    "                                                  feature_dir=feature_dir,\n",
    "                                                    check_for_file=False)\n",
    "dfsingle = df.loc[abase+'.jpeg']\n",
    "\n",
    "# if we've made it this far, let's generate features\n",
    "feature_name, font = generate_single_feature(dfsingle, LABELS,\n",
    "                                             maxboxes=20, \n",
    "                                       feature_list = feature_list, \n",
    "                                       binary_dir = config.tmp_storage_dir)\n",
    "\n",
    "image = np.load(feature_name)['arr_0']\n",
    "backtorgb,image_np,rotatedImage,rotatedAngleOCR,bbox_hocr,\\\n",
    "  bboxes_words,bbsq,cbsq, rotation,bbox_par = get_ocr_results(imgs_nameh, \n",
    "                                                              dfMakeSense,df,\n",
    "                                                             image_np=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d1b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "captionText_figcap, bbox_figcap_pars = get_image_process_boxes(backtorgb, \n",
    "                                                               bbox_hocr, \n",
    "                                                               rotatedImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d66fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "isave = -1\n",
    "for iiname,iname in enumerate(imgs_name):\n",
    "    if abase in iname:\n",
    "        isave=iiname\n",
    "imgs_name[isave]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24869ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import post_processing_utils\n",
    "reload(post_processing_utils)\n",
    "from post_processing_utils import clean_merge_heurstic_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b0e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = imgs_name[isave].split('/')[-1].split('.npz')[0]\n",
    "dfMS = dfMakeSense.loc[dfMakeSense['filename']==ff]\n",
    "\n",
    "boxes_heurh, labels_heurh, scores_heurh,\\\n",
    "  ibbOverlaph, boxes_heur_tfh  = clean_merge_heurstic_captions(boxes_pdf[isave], \n",
    "                                        labels_pdf[isave], scores_pdf[isave], \n",
    "                                        bbox_figcap_pars, LABELS,dfMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48d5168",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(Image.open(config.images_jpeg_dir+imgs_nameh[0].split('/')[-1].split('.npz')[0]+'.jpeg').convert('RGB'))\n",
    "fracx = img.shape[1]/config.IMAGE_W; fracy = img.shape[0]/config.IMAGE_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca443bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overplot\n",
    "imgPlot1 = img.copy()\n",
    "for b in bbox_figcap_pars:\n",
    "    xmin = b[0]; ymin=b[1]\n",
    "    xmax = b[2]; ymax = b[3]\n",
    "    cv.rectangle(imgPlot1, (round(xmin), round(ymin)), \n",
    "                 (round(xmax),round(ymax)), (255,0,0), 5)\n",
    "    \n",
    "# imgPlot3 = img.copy()\n",
    "# for bb in bbox_hocr:\n",
    "#     b = bb[0] \n",
    "#     xmin = b[0]; ymin=b[1]\n",
    "#     xmax = b[2]+b[0]; ymax = b[3]+b[1]\n",
    "#     cv.rectangle(imgPlot2, (round(xmin), round(ymin)), \n",
    "#                  (round(xmax),round(ymax)), (255,0,0), 5)\n",
    "    \n",
    "imgPlot2 = img.copy()\n",
    "for b in boxes_heurh:\n",
    "    xmin = b[0]*fracx; ymin=b[1]*fracy\n",
    "    xmax = b[2]*fracx; ymax = b[3]*fracy\n",
    "    cv.rectangle(imgPlot2, (round(xmin), round(ymin)), \n",
    "                 (round(xmax),round(ymax)), (255,0,0), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf00094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bbox_hocr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdb42df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,10))\n",
    "ax[0].imshow(imgPlot1)\n",
    "\n",
    "ax[1].imshow(imgPlot2)\n",
    "\n",
    "#ax[2].imshow(imgPlot3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35daf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdbb7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sname='Step4/'\n",
    "for iloop,(tb,fb1,lab1,fb2,lab2,imn) in enumerate(zip(truebox, boxes1, labels1,boxes_heur, labels_heur, imgs_name)):\n",
    "    if iloop%100 == 0: print(iloop,'of',len(imgs_name))\n",
    "    dontPlot = True\n",
    "    if len(tb) > 0 or len(fb) > 0: # do we have something?\n",
    "        if len(lab1) != len(lab2): # different number of labels\n",
    "            dontPlot = False # gotta plot it!\n",
    "        else:\n",
    "            # check to see if any of them have changed, box-wise\n",
    "            newBox = []\n",
    "            for b1 in fb1:\n",
    "                # look for index\n",
    "                try:\n",
    "                    fb2.tolist().index(b1.tolist())\n",
    "                    newBox.append(False)\n",
    "                except: # not in there\n",
    "                    newBox.append(True)\n",
    "            if np.array(newBox).any(): # do we have at least one new box?\n",
    "                dontPlot = False\n",
    "            else:\n",
    "                dontPlot = True\n",
    "                \n",
    "    if not dontPlot: # if anything has happened, plot!\n",
    "        iname = config.images_jpeg_dir + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        img = np.array(Image.open(iname).convert('RGB'))\n",
    "        # draw figures\n",
    "        for t in tb:\n",
    "            xmin = t[0]/config.IMAGE_W*img.shape[1]; xmax = t[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = t[1]/config.IMAGE_H*img.shape[0]; ymax = t[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[int(t[-1]-1)]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_true, 7)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_true, 7)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_true, 7)\n",
    "        for f,ll in zip(fb2,lab2): # only plot new boxes!\n",
    "            xmin = f[0]/config.IMAGE_W*img.shape[1]; xmax = f[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = f[1]/config.IMAGE_H*img.shape[0]; ymax = f[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[ll]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_found, 4)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_found, 4)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_found, 4)\n",
    "                \n",
    "        # save\n",
    "        inameout = config.tmp_storage_dir + binary_dirs + sname + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        Image.fromarray(img).save(inameout)\n",
    "        del img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c39666",
   "metadata": {},
   "source": [
    "**Step 5 (~~truebox1~~ truebox, boxes_par_found)**: grow found captions by their overlap with OCR word and paragraph boxes, allowing for multiple \"grow\" iterations in the horizontal direction.  For found boxes, only grow if centers of paragraph and word boxes overlap with the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f763ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sname='Step5/'\n",
    "for iloop,(tb,fb1,lab1,fb2,lab2,imn) in enumerate(zip(truebox,boxes_heur, labels_heur, \n",
    "                                                      boxes_par_found, labels_par_found,\n",
    "                                                      imgs_name)):\n",
    "    if iloop%100 == 0: print(iloop,'of',len(imgs_name))\n",
    "    dontPlot = True\n",
    "    if len(tb) > 0 or len(fb) > 0: # do we have something?\n",
    "        if len(lab1) != len(lab2): # different number of labels\n",
    "            dontPlot = False # gotta plot it!\n",
    "        else:\n",
    "            # check to see if any of them have changed, box-wise\n",
    "            newBox = []\n",
    "            for b1 in fb1:\n",
    "                # look for index\n",
    "                try:\n",
    "                    fb2.tolist().index(b1.tolist())\n",
    "                    newBox.append(False)\n",
    "                except: # not in there\n",
    "                    newBox.append(True)\n",
    "            if np.array(newBox).any(): # do we have at least one new box?\n",
    "                dontPlot = False\n",
    "            else:\n",
    "                dontPlot = True\n",
    "                \n",
    "    if not dontPlot: # if anything has happened, plot!\n",
    "        iname = config.images_jpeg_dir + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        img = np.array(Image.open(iname).convert('RGB'))\n",
    "        # draw figures\n",
    "        for t in tb:\n",
    "            xmin = t[0]/config.IMAGE_W*img.shape[1]; xmax = t[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = t[1]/config.IMAGE_H*img.shape[0]; ymax = t[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[int(t[-1]-1)]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_true, 7)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_true, 7)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_true, 7)\n",
    "        for f,ll in zip(fb2,lab2): # only plot new boxes!\n",
    "            xmin = f[0]/config.IMAGE_W*img.shape[1]; xmax = f[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = f[1]/config.IMAGE_H*img.shape[0]; ymax = f[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[ll]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_found, 4)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_found, 4)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_found, 4)\n",
    "                \n",
    "        # save\n",
    "        inameout = config.tmp_storage_dir + binary_dirs + sname + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        Image.fromarray(img).save(inameout)\n",
    "        del img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65deebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(truebox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f32acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(metric_utils)\n",
    "from metric_utils import calc_base_metrics_allboxes_cv, calc_prec_rec_f1_cv, print_metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8cb24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = np.repeat(0.9,4)#[0.8,0.8,0.8,0.8]\n",
    "TPs, FPs, FNs, totalTrues = calc_base_metrics_allboxes_cv(LABELS,[0.1],ious,\n",
    "                                              truebox,boxes_par_found, labels_par_found, \n",
    "                                              scores_par_found,n_folds_cv=5)\n",
    "totalTrue = totalTrues.sum(axis=1).astype('int') # collapse onto 1 axis\n",
    "TP = np.diagonal(TPs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "FP = np.diagonal(FPs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "FN = np.diagonal(FNs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "\n",
    "precisions, precision_stds, recalls, \\\n",
    "  recall_stds, f1s, f1_stds = calc_prec_rec_f1_cv(TPs,FPs,FNs,\n",
    "                                               LABELS,[0.1],\n",
    "                                               ious)\n",
    "precision = np.diagonal(precisions[:,0,:]) \n",
    "precision_std = np.diagonal(precision_stds[:,0,:]) \n",
    "recall = np.diagonal(recalls[:,0,:]) \n",
    "recall_std = np.diagonal(recall_stds[:,0,:]) \n",
    "f1 = np.diagonal(f1s[:,0,:]) \n",
    "f1_std = np.diagonal(f1_stds[:,0,:]) \n",
    "\n",
    "print_metrics_table(totalTrue,TP,FP,FN,\n",
    "                        precision, precision_std, recall, recall_std,f1,f1_std,\n",
    "                        LABELS, 0.1, 5, ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c69bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_par_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a31ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stepName = 'Step5_FP_cap/'\n",
    "# create_destroy_dirs(save_dir + stepName)\n",
    "\n",
    "# iou_FP = 0.9\n",
    "# for i in range(len(truebox)):\n",
    "#     if i%100 == 0: print(i,'of',len(imgs_name))\n",
    "#     TPs, FPs, FNs, totalTrues = calc_base_metrics_allboxes_cv(LABELS,[0.1],[iou_FP],\n",
    "#                                               [truebox[i]],[np.round(boxes_par_found[i])], \n",
    "#                                                               [labels_par_found[i]], \n",
    "#                                               [scores_par_found[i]],n_folds_cv=1)\n",
    "    \n",
    "#     FPs = FPs[:,0,0,0]; FNs = FNs[:,0,0,0]; TPs = TPs[:,0,0,0]\n",
    "#     imn = imgs_name[i]\n",
    "#     tb = truebox[i]; fb = boxes_par_found[i]; l=labels_par_found[i]\n",
    "#     #if (FPs[0] == 1) or (FPs[1]==1): # fig or caption FP\n",
    "#     if (FPs[LABELS.index('figure caption')]==1): # fig or caption FP\n",
    "#         if len(tb) > 0 or len(fb) > 0:\n",
    "#             #import sys; sys.exit()\n",
    "#             iname = config.images_jpeg_dir + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "#             img = np.array(Image.open(iname).convert('RGB'))\n",
    "#             # draw figures\n",
    "#             for t in tb:\n",
    "#                 xmin = t[0]/config.IMAGE_W*img.shape[1]; \n",
    "#                 xmax = t[2]/config.IMAGE_W*img.shape[1]\n",
    "#                 ymin = t[1]/config.IMAGE_H*img.shape[0]; \n",
    "#                 ymax = t[3]/config.IMAGE_H*img.shape[0]\n",
    "#                 l2 = LABELS[int(t[-1]-1)]\n",
    "#                 if l2 == 'figure':\n",
    "#                     cv.rectangle(img, (round(xmin), round(ymin)), \n",
    "#                                  (round(xmax),round(ymax)), colfig_true, 7)\n",
    "#                 if l2 == 'figure caption':\n",
    "#                     cv.rectangle(img, (round(xmin), round(ymin)), \n",
    "#                                  (round(xmax),round(ymax)), colcap_true, 7)\n",
    "#                 if l2 == 'table':\n",
    "#                     cv.rectangle(img, (round(xmin), round(ymin)), \n",
    "#                                  (round(xmax),round(ymax)), coltable_true, 7)\n",
    "#             for f,ll in zip(fb,l):\n",
    "#                 xmin = f[0]/config.IMAGE_W*img.shape[1]; \n",
    "#                 xmax = f[2]/config.IMAGE_W*img.shape[1]\n",
    "#                 ymin = f[1]/config.IMAGE_H*img.shape[0]; \n",
    "#                 ymax = f[3]/config.IMAGE_H*img.shape[0]\n",
    "#                 l2 = LABELS[ll]\n",
    "#                 if l2 == 'figure':\n",
    "#                     cv.rectangle(img, (round(xmin), round(ymin)), \n",
    "#                                  (round(xmax),round(ymax)), colfig_found, 4)\n",
    "#                 if l2 == 'figure caption':\n",
    "#                     cv.rectangle(img, (round(xmin), round(ymin)), \n",
    "#                                  (round(xmax),round(ymax)), colcap_found, 4)\n",
    "#                 if l2 == 'table':\n",
    "#                     cv.rectangle(img, (round(xmin), round(ymin)), \n",
    "#                                  (round(xmax),round(ymax)), coltable_found, 4)\n",
    "\n",
    "#             # save\n",
    "#             inameout = config.tmp_storage_dir + binary_dirs + stepName + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "#             Image.fromarray(img).save(inameout)\n",
    "#             del img    \n",
    "#             #import sys; sys.exit()\n",
    "#             #if '1906ApJ____23__255P_p1' in inameout: import sys; sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b9fdb3",
   "metadata": {},
   "source": [
    "**Step 6 (truebox, boxes_sq1):** if found figure boxes overlap with image-processing squares, the found box is expanded to include the square.  This extends the TP rate at larger IOU thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e8329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sname='Step6/'\n",
    "for iloop,(tb,fb1,lab1,fb2,lab2,imn) in enumerate(zip(truebox,boxes_par_found, \n",
    "                                                      labels_par_found, \n",
    "                                                      boxes_sq1, labels_sq1,\n",
    "                                                      imgs_name)):\n",
    "    if iloop%100 == 0: print(iloop,'of',len(imgs_name))\n",
    "    dontPlot = True\n",
    "    if len(tb) > 0 or len(fb) > 0: # do we have something?\n",
    "        if len(lab1) != len(lab2): # different number of labels\n",
    "            dontPlot = False # gotta plot it!\n",
    "        else:\n",
    "            # check to see if any of them have changed, box-wise\n",
    "            newBox = []\n",
    "            for b1 in fb1:\n",
    "                # look for index\n",
    "                try:\n",
    "                    fb2.tolist().index(b1.tolist())\n",
    "                    newBox.append(False)\n",
    "                except: # not in there\n",
    "                    newBox.append(True)\n",
    "            if np.array(newBox).any(): # do we have at least one new box?\n",
    "                dontPlot = False\n",
    "            else:\n",
    "                dontPlot = True\n",
    "                \n",
    "    if not dontPlot: # if anything has happened, plot!\n",
    "        iname = config.images_jpeg_dir + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        img = np.array(Image.open(iname).convert('RGB'))\n",
    "        # draw figures\n",
    "        for t in tb:\n",
    "            xmin = t[0]/config.IMAGE_W*img.shape[1]; xmax = t[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = t[1]/config.IMAGE_H*img.shape[0]; ymax = t[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[int(t[-1]-1)]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_true, 7)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_true, 7)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_true, 7)\n",
    "        for f,ll in zip(fb2,lab2): # only plot new boxes!\n",
    "            xmin = f[0]/config.IMAGE_W*img.shape[1]; xmax = f[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = f[1]/config.IMAGE_H*img.shape[0]; ymax = f[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[ll]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_found, 4)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_found, 4)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_found, 4)\n",
    "                \n",
    "        # save\n",
    "        inameout = config.tmp_storage_dir + binary_dirs + sname + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        Image.fromarray(img).save(inameout)\n",
    "        del img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = np.repeat(0.9,4)#[0.8,0.8,0.8,0.8]\n",
    "TPs, FPs, FNs, totalTrues = calc_base_metrics_allboxes_cv(LABELS,[0.1],ious,\n",
    "                                              truebox,boxes_sq1, labels_sq1, \n",
    "                                              scores_sq1,n_folds_cv=5)\n",
    "totalTrue = totalTrues.sum(axis=1).astype('int') # collapse onto 1 axis\n",
    "TP = np.diagonal(TPs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "FP = np.diagonal(FPs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "FN = np.diagonal(FNs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "\n",
    "precisions, precision_stds, recalls, \\\n",
    "  recall_stds, f1s, f1_stds = calc_prec_rec_f1_cv(TPs,FPs,FNs,\n",
    "                                               LABELS,[0.1],\n",
    "                                               ious)\n",
    "precision = np.diagonal(precisions[:,0,:]) \n",
    "precision_std = np.diagonal(precision_stds[:,0,:]) \n",
    "recall = np.diagonal(recalls[:,0,:]) \n",
    "recall_std = np.diagonal(recall_stds[:,0,:]) \n",
    "f1 = np.diagonal(f1s[:,0,:]) \n",
    "f1_std = np.diagonal(f1_stds[:,0,:]) \n",
    "\n",
    "print_metrics_table(totalTrue,TP,FP,FN,\n",
    "                        precision, precision_std, recall, recall_std,f1,f1_std,\n",
    "                        LABELS, 0.1, 5, ious)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00da2f9",
   "metadata": {},
   "source": [
    "**Step 7 (truebox, boxes_sq2):** any captions that have areas larger than 75% of the page area are discarded leading to a slight drop in FP for captions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2bead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sname='Step7/'\n",
    "for iloop,(tb,fb1,lab1,fb2,lab2,imn) in enumerate(zip(truebox,boxes_sq1, labels_sq1, \n",
    "                                                      boxes_sq2, labels_sq2,\n",
    "                                                      imgs_name)):\n",
    "    if iloop%100 == 0: print(iloop,'of',len(imgs_name))\n",
    "    dontPlot = True\n",
    "    if len(tb) > 0 or len(fb) > 0: # do we have something?\n",
    "        if len(lab1) != len(lab2): # different number of labels\n",
    "            dontPlot = False # gotta plot it!\n",
    "        else:\n",
    "            # check to see if any of them have changed, box-wise\n",
    "            newBox = []\n",
    "            for b1 in fb1:\n",
    "                # look for index\n",
    "                try:\n",
    "                    fb2.tolist().index(b1.tolist())\n",
    "                    newBox.append(False)\n",
    "                except: # not in there\n",
    "                    newBox.append(True)\n",
    "            if np.array(newBox).any(): # do we have at least one new box?\n",
    "                dontPlot = False\n",
    "            else:\n",
    "                dontPlot = True\n",
    "                \n",
    "    if not dontPlot: # if anything has happened, plot!\n",
    "        iname = config.images_jpeg_dir + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        img = np.array(Image.open(iname).convert('RGB'))\n",
    "        # draw figures\n",
    "        for t in tb:\n",
    "            xmin = t[0]/config.IMAGE_W*img.shape[1]; xmax = t[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = t[1]/config.IMAGE_H*img.shape[0]; ymax = t[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[int(t[-1]-1)]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_true, 7)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_true, 7)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_true, 7)\n",
    "        for f,ll in zip(fb2,lab2): # only plot new boxes!\n",
    "            xmin = f[0]/config.IMAGE_W*img.shape[1]; xmax = f[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = f[1]/config.IMAGE_H*img.shape[0]; ymax = f[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[ll]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_found, 4)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_found, 4)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_found, 4)\n",
    "                \n",
    "        # save\n",
    "        inameout = config.tmp_storage_dir + binary_dirs + sname + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        Image.fromarray(img).save(inameout)\n",
    "        del img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bef98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = np.repeat(0.9,4)#[0.8,0.8,0.8,0.8]\n",
    "TPs, FPs, FNs, totalTrues = calc_base_metrics_allboxes_cv(LABELS,[0.1],ious,\n",
    "                                              truebox,boxes_sq2, labels_sq2, \n",
    "                                              scores_sq2,n_folds_cv=5)\n",
    "totalTrue = totalTrues.sum(axis=1).astype('int') # collapse onto 1 axis\n",
    "TP = np.diagonal(TPs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "FP = np.diagonal(FPs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "FN = np.diagonal(FNs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "\n",
    "precisions, precision_stds, recalls, \\\n",
    "  recall_stds, f1s, f1_stds = calc_prec_rec_f1_cv(TPs,FPs,FNs,\n",
    "                                               LABELS,[0.1],\n",
    "                                               ious)\n",
    "precision = np.diagonal(precisions[:,0,:]) \n",
    "precision_std = np.diagonal(precision_stds[:,0,:]) \n",
    "recall = np.diagonal(recalls[:,0,:]) \n",
    "recall_std = np.diagonal(recall_stds[:,0,:]) \n",
    "f1 = np.diagonal(f1s[:,0,:]) \n",
    "f1_std = np.diagonal(f1_stds[:,0,:]) \n",
    "\n",
    "print_metrics_table(totalTrue,TP,FP,FN,\n",
    "                        precision, precision_std, recall, recall_std,f1,f1_std,\n",
    "                        LABELS, 0.1, 5, ious)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91943913",
   "metadata": {},
   "source": [
    "**Step 8 (truebox, boxes_sq3):** figure captions are matched to figures.  Any captions without an associated figure are dropped, leading to a drop in FP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742acd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sname='Step8/'\n",
    "for iloop,(tb,fb1,lab1,fb2,lab2,imn) in enumerate(zip(truebox,boxes_sq2, labels_sq2, \n",
    "                                                      boxes_sq3, labels_sq3,\n",
    "                                                      imgs_name)):\n",
    "    if iloop%100 == 0: print(iloop,'of',len(imgs_name))\n",
    "    dontPlot = True\n",
    "    if len(tb) > 0 or len(fb) > 0: # do we have something?\n",
    "        if len(lab1) != len(lab2): # different number of labels\n",
    "            dontPlot = False # gotta plot it!\n",
    "        else:\n",
    "            # check to see if any of them have changed, box-wise\n",
    "            newBox = []\n",
    "            for b1 in fb1:\n",
    "                # look for index\n",
    "                try:\n",
    "                    fb2.tolist().index(b1.tolist())\n",
    "                    newBox.append(False)\n",
    "                except: # not in there\n",
    "                    newBox.append(True)\n",
    "            if np.array(newBox).any(): # do we have at least one new box?\n",
    "                dontPlot = False\n",
    "            else:\n",
    "                dontPlot = True\n",
    "                \n",
    "    if not dontPlot: # if anything has happened, plot!\n",
    "        iname = config.images_jpeg_dir + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        img = np.array(Image.open(iname).convert('RGB'))\n",
    "        # draw figures\n",
    "        for t in tb:\n",
    "            xmin = t[0]/config.IMAGE_W*img.shape[1]; xmax = t[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = t[1]/config.IMAGE_H*img.shape[0]; ymax = t[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[int(t[-1]-1)]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_true, 7)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_true, 7)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_true, 7)\n",
    "        for f,ll in zip(fb2,lab2): # only plot new boxes!\n",
    "            xmin = f[0]/config.IMAGE_W*img.shape[1]; xmax = f[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = f[1]/config.IMAGE_H*img.shape[0]; ymax = f[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[ll]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_found, 4)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_found, 4)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_found, 4)\n",
    "                \n",
    "        # save\n",
    "        inameout = config.tmp_storage_dir + binary_dirs + sname + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        Image.fromarray(img).save(inameout)\n",
    "        del img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d977a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = np.repeat(0.9,4)\n",
    "TPs, FPs, FNs, totalTrues = calc_base_metrics_allboxes_cv(LABELS,[0.1],ious,\n",
    "                                              truebox,boxes_sq3, labels_sq3, \n",
    "                                              scores_sq3,n_folds_cv=5)\n",
    "totalTrue = totalTrues.sum(axis=1).astype('int') # collapse onto 1 axis\n",
    "TP = np.diagonal(TPs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "FP = np.diagonal(FPs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "FN = np.diagonal(FNs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "\n",
    "precisions, precision_stds, recalls, \\\n",
    "  recall_stds, f1s, f1_stds = calc_prec_rec_f1_cv(TPs,FPs,FNs,\n",
    "                                               LABELS,[0.1],\n",
    "                                               ious)\n",
    "precision = np.diagonal(precisions[:,0,:]) \n",
    "precision_std = np.diagonal(precision_stds[:,0,:]) \n",
    "recall = np.diagonal(recalls[:,0,:]) \n",
    "recall_std = np.diagonal(recall_stds[:,0,:]) \n",
    "f1 = np.diagonal(f1s[:,0,:]) \n",
    "f1_std = np.diagonal(f1_stds[:,0,:]) \n",
    "\n",
    "print_metrics_table(totalTrue,TP,FP,FN,\n",
    "                        precision, precision_std, recall, recall_std,f1,f1_std,\n",
    "                        LABELS, 0.1, 5, ious)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cedcfa",
   "metadata": {},
   "source": [
    "**Step 9 (truebox2, boxes_sq4):** both true and found figure boxes are extended down to the tops of their associated captions increasing TP for figures (and to a lesser extentent, captions) at high IOU thresholds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2b908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sname='Step9/'\n",
    "for iloop,(tb,fb1,lab1,fb2,lab2,imn) in enumerate(zip(truebox2,boxes_sq3, labels_sq3, \n",
    "                                                      boxes_sq4, labels_sq4,\n",
    "                                                      imgs_name)):\n",
    "    if iloop%100 == 0: print(iloop,'of',len(imgs_name))\n",
    "    dontPlot = True\n",
    "    if len(tb) > 0 or len(fb) > 0: # do we have something?\n",
    "        if len(lab1) != len(lab2): # different number of labels\n",
    "            dontPlot = False # gotta plot it!\n",
    "        else:\n",
    "            # check to see if any of them have changed, box-wise\n",
    "            newBox = []\n",
    "            for b1 in fb1:\n",
    "                # look for index\n",
    "                try:\n",
    "                    fb2.tolist().index(b1.tolist())\n",
    "                    newBox.append(False)\n",
    "                except: # not in there\n",
    "                    newBox.append(True)\n",
    "            if np.array(newBox).any(): # do we have at least one new box?\n",
    "                dontPlot = False\n",
    "            else:\n",
    "                dontPlot = True\n",
    "                \n",
    "    if not dontPlot: # if anything has happened, plot!\n",
    "        iname = config.images_jpeg_dir + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        img = np.array(Image.open(iname).convert('RGB'))\n",
    "        # draw figures\n",
    "        for t in tb:\n",
    "            xmin = t[0]/config.IMAGE_W*img.shape[1]; xmax = t[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = t[1]/config.IMAGE_H*img.shape[0]; ymax = t[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[int(t[-1]-1)]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_true, 7)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_true, 7)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_true, 7)\n",
    "        for f,ll in zip(fb2,lab2): # only plot new boxes!\n",
    "            xmin = f[0]/config.IMAGE_W*img.shape[1]; xmax = f[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = f[1]/config.IMAGE_H*img.shape[0]; ymax = f[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[ll]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_found, 4)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_found, 4)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_found, 4)\n",
    "                \n",
    "        # save\n",
    "        inameout = config.tmp_storage_dir + binary_dirs + sname + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        Image.fromarray(img).save(inameout)\n",
    "        del img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72991584",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = np.repeat(0.9,4)\n",
    "TPs, FPs, FNs, totalTrues = calc_base_metrics_allboxes_cv(LABELS,[0.1],ious,\n",
    "                                              truebox2,boxes_sq4, labels_sq4, \n",
    "                                              scores_sq4,n_folds_cv=5)\n",
    "totalTrue = totalTrues.sum(axis=1).astype('int') # collapse onto 1 axis\n",
    "TP = np.diagonal(TPs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "FP = np.diagonal(FPs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "FN = np.diagonal(FNs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "\n",
    "precisions, precision_stds, recalls, \\\n",
    "  recall_stds, f1s, f1_stds = calc_prec_rec_f1_cv(TPs,FPs,FNs,\n",
    "                                               LABELS,[0.1],\n",
    "                                               ious)\n",
    "precision = np.diagonal(precisions[:,0,:]) \n",
    "precision_std = np.diagonal(precision_stds[:,0,:]) \n",
    "recall = np.diagonal(recalls[:,0,:]) \n",
    "recall_std = np.diagonal(recall_stds[:,0,:]) \n",
    "f1 = np.diagonal(f1s[:,0,:]) \n",
    "f1_std = np.diagonal(f1_stds[:,0,:]) \n",
    "\n",
    "print_metrics_table(totalTrue,TP,FP,FN,\n",
    "                        precision, precision_std, recall, recall_std,f1,f1_std,\n",
    "                        LABELS, 0.1, 5, ious)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f513307",
   "metadata": {},
   "source": [
    "**Step 10 (truebox3, boxes_sq5):** if a figure caption extends horizontally further than its associated figure, the figure is extended horizontally to the edges of the figure caption for both true and found boxes.  This leads to an increase in TP rates for figures at high IOU thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e02be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sname='Step10/'\n",
    "for iloop,(tb,fb1,lab1,fb2,lab2,imn) in enumerate(zip(truebox2,boxes_sq3, labels_sq3, \n",
    "                                                      boxes_sq4, labels_sq4,\n",
    "                                                      imgs_name)):\n",
    "    if iloop%100 == 0: print(iloop,'of',len(imgs_name))\n",
    "    dontPlot = True\n",
    "    if len(tb) > 0 or len(fb) > 0: # do we have something?\n",
    "        if len(lab1) != len(lab2): # different number of labels\n",
    "            dontPlot = False # gotta plot it!\n",
    "        else:\n",
    "            # check to see if any of them have changed, box-wise\n",
    "            newBox = []\n",
    "            for b1 in fb1:\n",
    "                # look for index\n",
    "                try:\n",
    "                    fb2.tolist().index(b1.tolist())\n",
    "                    newBox.append(False)\n",
    "                except: # not in there\n",
    "                    newBox.append(True)\n",
    "            if np.array(newBox).any(): # do we have at least one new box?\n",
    "                dontPlot = False\n",
    "            else:\n",
    "                dontPlot = True\n",
    "                \n",
    "    if not dontPlot: # if anything has happened, plot!\n",
    "        iname = config.images_jpeg_dir + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        img = np.array(Image.open(iname).convert('RGB'))\n",
    "        # draw figures\n",
    "        for t in tb:\n",
    "            xmin = t[0]/config.IMAGE_W*img.shape[1]; xmax = t[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = t[1]/config.IMAGE_H*img.shape[0]; ymax = t[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[int(t[-1]-1)]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_true, 7)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_true, 7)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_true, 7)\n",
    "        for f,ll in zip(fb2,lab2): # only plot new boxes!\n",
    "            xmin = f[0]/config.IMAGE_W*img.shape[1]; xmax = f[2]/config.IMAGE_W*img.shape[1]\n",
    "            ymin = f[1]/config.IMAGE_H*img.shape[0]; ymax = f[3]/config.IMAGE_H*img.shape[0]\n",
    "            l2 = LABELS[ll]\n",
    "            if l2 == 'figure':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colfig_found, 4)\n",
    "            if l2 == 'figure caption':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), colcap_found, 4)\n",
    "            if l2 == 'table':\n",
    "                cv.rectangle(img, (round(xmin), round(ymin)), (round(xmax),round(ymax)), coltable_found, 4)\n",
    "                \n",
    "        # save\n",
    "        inameout = config.tmp_storage_dir + binary_dirs + sname + imn.split('/')[-1].split('.npz')[0]+'.jpeg'\n",
    "        Image.fromarray(img).save(inameout)\n",
    "        del img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06019ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = np.repeat(0.9,4)\n",
    "TPs, FPs, FNs, totalTrues = calc_base_metrics_allboxes_cv(LABELS,[0.1],ious,\n",
    "                                              truebox3,boxes_sq5, labels_sq5, \n",
    "                                              scores_sq4,n_folds_cv=5)\n",
    "totalTrue = totalTrues.sum(axis=1).astype('int') # collapse onto 1 axis\n",
    "TP = np.diagonal(TPs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "FP = np.diagonal(FPs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "FN = np.diagonal(FNs[:,0,:,:].sum(axis=2)) # sum across all CV, then for the right IOU\n",
    "\n",
    "precisions, precision_stds, recalls, \\\n",
    "  recall_stds, f1s, f1_stds = calc_prec_rec_f1_cv(TPs,FPs,FNs,\n",
    "                                               LABELS,[0.1],\n",
    "                                               ious)\n",
    "precision = np.diagonal(precisions[:,0,:]) \n",
    "precision_std = np.diagonal(precision_stds[:,0,:]) \n",
    "recall = np.diagonal(recalls[:,0,:]) \n",
    "recall_std = np.diagonal(recall_stds[:,0,:]) \n",
    "f1 = np.diagonal(f1s[:,0,:]) \n",
    "f1_std = np.diagonal(f1_stds[:,0,:]) \n",
    "\n",
    "print_metrics_table(totalTrue,TP,FP,FN,\n",
    "                        precision, precision_std, recall, recall_std,f1,f1_std,\n",
    "                        LABELS, 0.1, 5, ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f66b1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
